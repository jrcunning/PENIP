---
title: "Port Everglades Coral Survey Data Analysis"
author: "R. Cunning"
date: "2025-04-21"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2      
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Setup
```{r libraries}
# Load packages
library(sf)
library(xml2)
library(tidyverse)
library(tidybayes)
library(brms)
```

```{r custom}
# Define genus level taxon groups (plus one family FAVI)
taxon_groups <- list(
  PORI = c("PPOR", "PFUR", "PDIV", "PAST", "PORI"),
  ORBI = c("OFAV", "OANN", "OFRA", "ORBI"),
  FAVI = c("CNAT", "DLAB", "PSTR", "PCLI", "MARE", "FAVI"),
  AGAR = c("AFRA", "AAGA", "AHUM", "ALAM", "AGAR"),
  MADR = c("MAUR", "MSEN", "MDEC", "MPHA", "MADR"),
  SOLE = c("SHYA", "SBOU", "SOLE"),
  SCOL = c("SLAC", "SCUB", "SCOL"),
  SIDE = c("SSID", "SRAD", "SIDE"),
  MYCE = c("MFER", "MLAM", "MALI", "MYCE"),
  OCUL = c("OROB", "ODIF", "OCUL")
)

# Convert to lookup tibble
taxon_lookup <- enframe(taxon_groups, name = "taxon_group", value = "taxon") %>%
  unnest(taxon)



# Define juvenile family level taxon groups (following DRM survey convention)
taxon_groups_juv <- list(
  MUSS = c("ISIN", "ISOP", "MANG", "MYCE", "SCOL", "MUSS"),
  FAVI = c("FAVI", "FFRA", "MARE"),
  MEAN = c("MMEA", "MEAN", "DCYL", "DSTO", "EFAS")
)
# Convert to lookup tibble
taxon_lookup_juv <- enframe(taxon_groups_juv, name = "taxon_group", value = "taxon") %>%
  unnest(taxon)


# Order levels of Habitat Types
type_levels <- c("Nearshore Ridge Complex", "Inner Reef", "Middle Reef",
                 "Outer Reef", "Aggregated Patch Reef")
type_labels <- c("NRC", "IR", "MR", "OR", "APR")
names(type_labels) <- type_levels

# Order survey datasets
dataset_levels <- c("dca", "tt21", "tt23", "drm")
dataset_labels <- c("2017—DCA", "2021—TT", "2023—TT", "2024—Shedd")
names(dataset_labels) <- dataset_levels
```

# Import data

## 2011 (NSU) and 2017 (DCA) ESA Surveys

## 2017 Dial Cordy Recon Survey

DCA site metadata
```{r 2017_DCA_site_metadata}
# Site metadata
# Read in site coordinates
dca_sitemd0 <- readxl::read_xlsx("data/2017_dca_recon/Recon_Site_Coordinates_Extracted.xlsx") %>%
  janitor::clean_names()

# All sites have start and end coordinates...

# Tidy and Calculate midpoint per transect
dca_sitemd <- dca_sitemd0 %>%
  mutate(
    depth = abs(as.numeric(depth)),
    across(c(latitude, longitude), as.numeric)
  ) %>%
  group_by(site = transect) %>%
  summarize(
    latitude = mean(latitude, na.rm = TRUE),
    longitude = mean(longitude, na.rm = TRUE),
    depth = mean(depth, na.rm = TRUE),
    .groups = "drop"
  )
```

DCA coral data
```{r 2017_DCA_coral_data}
# Read in survey data
dca0 <- readxl::read_xlsx("data/2017_dca_recon/Compiled_DCA_RECON_Belt_data.xlsx") %>%
  janitor::clean_names()

dca <- dca0 %>%
  select(1:18) %>%
  rename(site = site_name) %>%
  mutate(site = factor(site)) %>%
  select(site, taxon = coral_species, max_width_cm = max_size_cm)

# Adjust/corrects species IDs
sort(unique(dca$taxon))
dca <- dca %>%
  mutate(taxon = case_when(
    taxon == "AGA SP" ~ "AGAR",
    taxon == "LCUC" ~ "HCUC",
    taxon %in% c("MYCSP", "Mycetophyllia spp.") ~ "MYCE",
    taxon == "OFAV\\" ~ "OFAV",
    taxon %in% c("MAD SP", "MADSP") ~ "MADR",
    taxon == "Scolymia Spp" ~ "SCOL",
    taxon %in% c("SIDSP", "Sid SP", "SID SP.", "SID SP") ~ "SIDE",
    TRUE ~ taxon
  ))
sort(unique(dca$taxon))

# Filter out unidentified corals
dca <- dca %>%
  filter(!taxon %in% c("CORAL", "Cup Coral"))

# Write long data to file
write_csv(dca, file = "data/processed/dca_2017_long.csv")


# Convert to count data
# Add explicit zeros for any taxon/size class missing at any site
dca_counts <- dca %>%
  mutate(class = ifelse(max_width_cm >= 4, ">4cm", "<4cm")) %>%
  count(site, taxon, class) %>%
  complete(site, taxon, class = c(">4cm", "<4cm"), fill = list(n = 0)) %>%
  # # Don't create zeros for MEAN/MUSS/FAVI adults, since these IDs only applied to juv
  filter(!(taxon %in% c("MEAN", "MUSS", "FAVI") & class == ">4cm" & n == 0))

write_csv(dca_counts, file = "data/processed/dca_2017_counts.csv")

# Aggregate count data based on taxonomic groups defined above
dca_counts_ag <- dca_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")



# Further aggregate juvenile counts to family (following DRM methods)
dca_counts_ag <- dca_counts_ag %>%
  left_join(taxon_lookup_juv, by = "taxon") %>%
  mutate(
    taxon = if_else(class == "<4cm" & !is.na(taxon_group), taxon_group, taxon)
  ) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")


write_csv(dca_counts_ag, file = "data/processed/dca_2017_counts_ag.csv")
```

## 2021 Tetra Tech Recon and ESA Surveys

2021 TT site metadata
```{r tt21_site_metadata}
# site metadata
tt21_sitemd0 <- read_csv("data/2021_tt_recon_esa/midpoints_latlon.csv") %>%
  janitor::clean_names()

tt21_sitemd <- tt21_sitemd0 %>%
  mutate(name = str_remove(name, "A$")) %>%
  select(site = name, longitude = lon, latitude = lat)
```

2021 TT coral data
```{r tt21_coral_data}
# coral data - recon belt transects
tt21recon0 <- readxl::read_xlsx("data/2021_tt_recon_esa/Recon 30x1m Coral Belt Transect.xlsx") %>%
  janitor::clean_names()

tt21recon <- tt21recon0 %>%
  select(site, taxon = id_abbrev, coral_length_cm, coral_width_cm) %>%
  mutate(taxon = toupper(taxon), site = factor(site)) %>%
  mutate(across(c(coral_length_cm, coral_width_cm), as.numeric)) %>%
  mutate(max_width_cm = pmax(coral_length_cm, coral_width_cm)) %>%
  select(site, taxon, max_width_cm)

# ESA survey data
tt21esa0 <- readxl::read_xlsx("data/2021_tt_recon_esa/ESA Coral Belt Transect.xlsx") %>%
  janitor::clean_names()

sort(unique(tt21esa0$esa_id))

tt21esa <- tt21esa0 %>%
  mutate(site = factor(site),
         taxon = case_when(
           esa_id == "Orbicella franksi" ~ "OFRA",
           esa_id == "Orbicella faveolata" ~ "OFAV",
           esa_id == "Acropora cervicornis" ~ "ACER")) %>%
  filter(!is.na(taxon)) %>%
  mutate(max_width_cm = pmax(coral_length_cm, coral_width_cm)) %>%
  select(site, taxon, max_width_cm)

# Combine Recon and ESA survey data
tt21 <- bind_rows(tt21recon, tt21esa)


# Check taxa names
sort(unique(tt21recon$taxon))

# Filter out unidentified OR NON-CORAL taxa
tt21 <- tt21 %>%
  filter(!taxon %in% c("0", "JUVENILE-UNIDENTIFIABLE", "XESTO", "MALC"))

# Adjust/corrects species IDs
tt21 <- tt21 %>%
  mutate(taxon = case_when(
    taxon == "AFRAG" ~ "AFRA",
    taxon == "FFRAG" ~ "FFRA",
    taxon == "MYALI" ~ "MALI",
    taxon == "MYFER" ~ "MFER",
    taxon == "MYLAM" ~ "MLAM",
    taxon == "ODIF/OROB" ~ "OCUL",
    taxon == "PDCLIV" ~ "PCLI",
    taxon == "PDSTR" ~ "PSTR",
    taxon == "PHYLLANGIA AMERICANA" ~ "PAME",
    taxon == "SCOLYMIA CUBENSIS" ~ "SCUB",
    taxon == "SCOLYMIA LACERA" ~ "SLAC",
    TRUE ~ taxon
  ))
sort(unique(tt21$taxon))

# Write long data to file
write_csv(tt21, file = "data/processed/tt_2021_long.csv")





# Count
# Add explicit zeros for any taxon/size class missing at any site
tt21_counts <- tt21 %>%
  mutate(class = ifelse(max_width_cm >= 4, ">4cm", "<4cm")) %>%
  count(site, taxon, class) %>%
  complete(site, taxon, class = c(">4cm", "<4cm"), fill = list(n = 0)) %>%
  # Don't create zeros for MEAN/MUSS/FAVI adults, since these IDs only applied to juv
  filter(!(taxon %in% c("MEAN", "MUSS", "FAVI") & class == ">4cm" & n == 0))

write_csv(tt21_counts, file = "data/processed/tt_2021_counts.csv")




# Aggregate count data based on taxonomic groups defined above
tt21_counts_ag <- tt21_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

# Further aggregate juvenile counts to family (following DRM methods)
tt21_counts_ag <- tt21_counts_ag %>%
  left_join(taxon_lookup_juv, by = "taxon") %>%
  mutate(
    taxon = if_else(class == "<4cm" & !is.na(taxon_group), taxon_group, taxon)
  ) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

write_csv(tt21_counts_ag, file = "data/processed/tt21_counts_ag.csv")
```

## 2023 Tetra Tech Impact Survey

TT site metadata
```{r 2023_tt_site_metadata}
# Site metadata
tt_sitemd <- readxl::read_xlsx("data/2023_tt_impact/Impact site tracking.xlsx", skip = 1) %>%
  janitor::clean_names()

tt_sitemd <- tt_sitemd %>%
  mutate(site = transect_name,
         latitude = as.numeric(actual_start_y),
         longitude = as.numeric(actual_start_x)) %>%
  select(site, latitude, longitude) 

# Many sites missing coords in sheet.... whats up with that
tt_sitemd <- drop_na(tt_sitemd, longitude)
```

TT coral data
```{r 2023_tt_coral_data}
tt0 <- readxl::read_xlsx("data/2023_tt_impact/Impact Raw Data 05 31 2024.xlsx") %>%
  janitor::clean_names() 

tt <- tt0 %>%
  select(site = transect_name, depth_ft_start,
         taxon = id_abbrev, coral_length_cm, coral_width_cm) %>%
  filter(taxon != "Xesto") %>%
  mutate(taxon = toupper(taxon)) %>%
  mutate(across(c(coral_length_cm, coral_width_cm), as.numeric)) %>%
  mutate(site = factor(site))

tt <- tt %>%
  mutate(max_width_cm = pmax(coral_length_cm, coral_width_cm)) %>%
  select(site, taxon, max_width_cm)

# Check taxa names
sort(unique(tt$taxon))

# Filter out unidentified taxa
tt <- tt %>%
  filter(!taxon %in% c("?", "ID-ABBREV", "NONE", "MHEARD"))

# Adjust/corrects species IDs
tt <- tt %>%
  mutate(taxon = case_when(
    taxon == "AFRAG" ~ "AFRA",
    taxon %in% c("ASP", "ASP.") ~ "AGAR",
    taxon == "MCAV?" ~ "MCAV",
    taxon == "MSP." ~ "MADR",
    taxon == "MUSSID" ~ "MUSS",
    taxon == "MYALI" ~ "MALI",
    taxon == "MYFER" ~ "MFER",
    taxon == "MYLAM" ~ "MLAM",
    taxon == "OFR" ~ "OFRA",
    taxon == "PCLI?" ~ "PCLI",
    taxon %in% c("PSP", "PSP.") ~ "PORI",
    taxon == "SSP." ~ "SIDE",
    taxon == "STOK" ~ "DSTO",
    TRUE ~ taxon
  ))
sort(unique(tt$taxon))

# Write long data to file
write_csv(tt, file = "data/processed/tt_2024_long.csv")





# Count
# Add explicit zeros for any taxon/size class missing at any site
tt_counts <- tt %>%
  mutate(class = ifelse(max_width_cm >= 4, ">4cm", "<4cm")) %>%
  count(site, taxon, class) %>%
  complete(site, taxon, class = c(">4cm", "<4cm"), fill = list(n = 0)) %>%
  # Don't create zeros for MEAN/MUSS/FAVI adults, since these IDs only applied to juv
  filter(!(taxon %in% c("MEAN", "MUSS", "FAVI") & class == ">4cm" & n == 0))

write_csv(tt_counts, file = "data/processed/tt_2024_counts.csv")




# Aggregate count data based on taxonomic groups defined above
tt_counts_ag <- tt_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

# Further aggregate juvenile counts to family (following DRM methods)
tt_counts_ag <- tt_counts_ag %>%
  left_join(taxon_lookup_juv, by = "taxon") %>%
  mutate(
    taxon = if_else(class == "<4cm" & !is.na(taxon_group), taxon_group, taxon)
  ) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

write_csv(tt_counts_ag, file = "data/processed/tt_counts_ag.csv")
```



## 2024 Shedd Survey

Shedd site metadata
```{r 2024_shedd_site_metadata}
# Site metadata
drm_sitemd <- readxl::read_xlsx("data/2024_shedd_drm/site_metadata.xlsx") %>%
  janitor::clean_names() %>%
  mutate(site = as.character(drm_site_id)) %>%
  select(site, latitude = lat, longitude = lon) %>%
  mutate(depth = NA)
```

Shedd coral data
```{r 2024_shedd_coral_data}
# Adult coral data from main DRM surveys
#adults0 <- read_csv("data/2024_shedd_drm/DRM_broward_corals.csv")
#adults0 %>% filter(team == "Shedd Aquarium")

# Most sites were included in main DRM database for 2024 -- Import these
adultst1t2 <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_RawCoralDataTransect1and2_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  filter(subregion == "Broward-Miami", team == "Shedd Aquarium") %>%
  select(site, transect_num, species, width, height)
adultst3t4 <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_RawCoralDataTransect3and4_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  filter(subregion == "Broward-Miami", team == "Shedd Aquarium") %>%
  select(site, transect_num, species, width, height)

# 9 of our PEV sites were removed from DRM database to avoid oversaturating the ares -- Import these separately
removedt1t2 <- readxl::read_xlsx(
  "data/2024_shedd_drm/2024_DRM_Broward_RemovedSites_T1-T4_Shedd.xlsx", sheet = "Removed Sites T1-T2") %>%
  janitor::clean_names() %>%
  select(site, transect_num, species, width, height)
removedt3t4 <- readxl::read_xlsx(
  "data/2024_shedd_drm/2024_DRM_Broward_RemovedSites_T1-T4_Shedd.xlsx", sheet = "Removed Sites T3-T4") %>%
  janitor::clean_names() %>%
  select(site, transect_num, species, width, height)

# Combine all adult coral data for Shedd DRM surveys at PEV
adults0 <- bind_rows(adultst1t2, adultst3t4, removedt1t2, removedt3t4)
# Convert adult data to long format
adults_long <- adults0 %>%
  mutate(max_width_cm = pmax(width, height, na.rm = TRUE)) %>%
  mutate(max_width_cm = as.character(max_width_cm)) %>%
  mutate(site = str_remove(site, "^AA")) %>%
  select(site, transect_num, taxon = species, max_width_cm) %>%
  drop_na(taxon)     # DROPS when taxon is blank, this is when no corals >4cm were observed

# Import juvenile counts from main DRM dataset
juv <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_JuvenileCoralData_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  filter(subregion == "Broward-Miami", team == "Shedd Aquarium")

# Import juvenile counts from sites that were removed from main DRM dataset
removed_juv <- readxl::read_xlsx("data/2024_shedd_drm/Shedd_removed_sites_Juveniles_2024.xlsx") %>%
  janitor::clean_names() %>%
  # Missing values in count data should be zero counts (unique to this datasheet from FWC)
  mutate(across(ends_with("_ct"), ~replace_na(., 0)))

# Combine juvenile data
juv0 <- bind_rows(juv, removed_juv) %>%
  mutate(site = str_remove(site, "^AA")) %>%
  select(site, transect_num, ends_with("ct")) %>%
  rename(MCAV = montastraea_ct, MUSS = mussinae_ct, FAVI = faviinae_ct, MEAN = meandrinidae_ct)

# Convert juvenile data to long format
juv_long <- juv0 %>%
  pivot_longer(c(MUSS, FAVI, MEAN, MCAV), names_to = "taxon", values_to = "n") %>%
  mutate(max_width_cm = "<4") %>%
  uncount(n)



# Other juvenile taxa counts from Transects 1 and 2 (DRM 'bonus data')
t1t2bonus <- read_csv("data/2024_shedd_drm/T1_T2_bonus_data.csv") %>%
  janitor::clean_names() %>%
  mutate(site = replace_na(site, "NA")) %>%    # Because one site is called "NA"
  mutate(transect_num = parse_number(transect))
t1t2juv <- t1t2bonus %>%
  select(site, transect_num, starts_with("small")) %>%
  rename_with(~ toupper(gsub("^small_", "", .x)), starts_with("small_"))
t1t2juv_long <- t1t2juv %>%
  pivot_longer(3:10, names_to = "taxon", values_to = "n") %>%
  mutate(max_width_cm = "<4") %>%
  uncount(n)
# Replace site names in t1t2 bonus data with the correct DRM site ID
penipsites <- readxl::read_xlsx("data/2024_shedd_drm/site_metadata.xlsx") %>%
  janitor::clean_names()
t1t2juv_long_updated <- t1t2juv_long %>%
  left_join(penipsites %>% select(site, drm_site_id), by = "site") %>%
  mutate(site = as.character(drm_site_id)) %>%
  select(-drm_site_id)


# Combine all data
drm_long <- bind_rows(adults_long, juv_long, t1t2juv_long_updated) %>%
  mutate(team = "Shedd Aquarium")

# Check species names
sort(unique(drm_long$taxon))

write_csv(drm_long, file = "data/processed/drm_2024_long.csv")


# COUNT based on rules
# ✅ Updated Rules Summary for counting from DRM/Shedd data:
# Juvenile taxa (searched for in <4cm size class only):
#    "MEAN", "MUSS", "FAVI"
#    → these should only ever appear in <4cm, never >4cm, and should not be zero-filled for adults.
# Other juvenile-capable taxa:
#    "MCAV", "SSID", "SRAD", "PAST", "PPOR", "SINT", "SBOU", "AAGA", "MAUR"
#    → these can be counted in both >4cm and <4cm, but only in <4cm if juveniles were searched on that transect and team.
# Transect-based search rules still apply:
# Transects 1 & 2: all adult taxa always searched. Juvenile search depends on team:
#    "Shedd Aquarium" → all juvenile taxa above searched
#    others → only MEAN, MUSS, FAVI, MCAV
# Transects 3 & 4:
#    only subset of adult taxa searched (adult_taxa_t3t4)
#    only juveniles: MEAN, MUSS, FAVI, MCAV

# Step 1: Define size classes
drm_classed <- drm_long %>%
  mutate(class = case_when(as.numeric(max_width_cm) >= 4 ~ ">4cm",
                           max_width_cm == "<4" ~ "<4cm"))

# Step 2: Define species sets
all_taxa <- unique(drm_classed$taxon)
adult_taxa_t3t4 <- c("CNAT", "DSTO", "DLAB", "MMEA", "MANG", "MALI", 
                     "MFER", "MLAM", "PCLI", "PSTR")
juv_only_taxa <- c("MEAN", "MUSS", "FAVI")
juv_both_taxa <- c("MCAV", "SSID", "SRAD", "PAST", "PPOR", "SINT", "SBOU", "AAGA", "MAUR")
all_juv_taxa <- c(juv_only_taxa, juv_both_taxa)

# Step 3: Build search grid per site × transect × team
search_grid <- drm_classed %>%
  distinct(site, transect_num, team) %>%    # if multiple teams in data, remove value for team
  mutate(
    searched_taxa_class = pmap(list(transect_num, team), function(transect, team) {
      # Helper: define juv taxa allowed for this transect/team
      juv_taxa <- if (transect %in% c(1, 2)) {
        if (team == "Shedd Aquarium") {      # Shedd searched for other juv taxa on T1 and T2, other DRM survey teams did not
          all_juv_taxa
        } else {
          c(juv_only_taxa, "MCAV")
        }
      } else {
        c(juv_only_taxa, "MCAV")
      }
      
      # Adults always searched in 1 & 2, subset in 3 & 4
      adult_taxa <- if (transect %in% c(1, 2)) {
        setdiff(all_taxa, juv_only_taxa)  # exclude juv-only taxa
      } else {
        adult_taxa_t3t4
      }

      # Build grid
      bind_rows(
        expand_grid(taxon = adult_taxa, class = ">4cm"),
        expand_grid(taxon = juv_taxa, class = "<4cm")
      )
    })
  ) %>%
  unnest(searched_taxa_class)

# Step 4: Count observations
counts <- drm_classed %>%
  group_by(site, transect_num, team, taxon, class) %>%
  summarize(n = n(), .groups = "drop")

# Step 5: Join with grid and fill in zeros where appropriate
final_counts <- search_grid %>%
  left_join(counts, by = c("site", "transect_num", "team", "taxon", "class")) %>%
  mutate(n = replace_na(n, 0))

write_csv(final_counts, file = "data/processed/drm_2024_counts.csv")




# AGGREGATE COUNT DATA
# Aggregate taxa
final_counts_ag <- final_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

write_csv(final_counts_ag, file = "data/processed/drm_2024_counts_ag.csv")
```





## Habitat classification polygons
```{r habitat_maps, fig.width = 10, fig.height = 10}
# --- STEP 1: Load KML Polygons ---
polygons <- st_read("data/Habitat classifications.kml")  # update path as needed

# --- STEP 2: Extract Attributes from HTML Description ---
extract_attrs <- function(desc) {
  if (is.na(desc) || desc == "") {
    return(tibble(Habitat = NA, Type = NA, Modifier = NA, Region = NA, Type2 = NA))
  }
  html <- read_html(desc)
  rows <- xml_find_all(html, "//table//table//tr")
  keys <- rows %>% xml_find_all(".//td[1]") %>% xml_text(trim = TRUE)
  vals <- rows %>% xml_find_all(".//td[2]") %>% xml_text(trim = TRUE)
  n <- min(length(keys), length(vals))
  named_vals <- set_names(vals[1:n], keys[1:n])
  tibble(
    Habitat  = named_vals[["Habitat"]],
    Type     = named_vals[["Type"]],
    Modifier = named_vals[["Modifier"]],
    Region   = named_vals[["Region"]],
    Type2    = named_vals[["Type2"]]
  )
}

# Apply function and combine with spatial geometries
attrs <- map_dfr(polygons$Description, extract_attrs)
polygons_clean <- bind_cols(polygons %>% select(-Description), attrs)

# --- STEP 3: Prepare Site Coordinate Data ---
# Get all site coordinates, and assign north and south
allsitemd <- bind_rows(.id = "dataset",
  drm = drm_sitemd,
  dca = dca_sitemd,
  tt23 = tt_sitemd,
  tt21 = tt21_sitemd
) %>%
  mutate(dir = if_else(latitude > 26.093570, "N", "S"))
points <- st_as_sf(allsitemd, coords = c("longitude", "latitude"), crs = 4326)

# --- STEP 4: Validate Geometry and Match CRS ---
polygons_clean <- polygons_clean %>%
  st_zm(drop = TRUE, what = "ZM") %>%
  st_make_valid() %>%
  st_transform(st_crs(points))

sf_use_s2(FALSE)  # prevent s2 geometry issues

# --- STEP 5: Spatial Join ---
joined <- st_join(points, polygons_clean, join = st_within)

joined_df <- joined %>%
  mutate(longitude = st_coordinates(.)[,1],
         latitude = st_coordinates(.)[,2]) %>%
  st_drop_geometry()

allsitemd <- joined_df

# Visualize habitat classifications
(polyplot <- polygons_clean %>% 
  #filter(Type != "Sand") %>%
  ggplot() +
  geom_sf(aes(fill = Type), color = "black", size = 0.2, alpha = 0.6) +
  scale_fill_brewer(palette = "Set3", na.value = "gray80") +
  theme_minimal() +
  labs(title = "Habitat Polygons Colored by Type", fill = "Type") +
  theme(legend.position = "right") +
  xlim(-80.11, -80.079) +
  ylim(26.0675, 26.11))

# 'Sand' overlaps some of the other polygons instead of just surrounding them...
# If a point is classified as Sand AND something else, remove Sand...
multiclass <- allsitemd %>%
  group_by(site) %>%
  filter(n() > 1)

allsitemd_clean <- allsitemd %>%
  group_by(site) %>%
  filter(!(Type == "Sand" & n() > 1)) %>%
  ungroup()
```

# Filter data

## By habitat type

```{r}
# Select sites in Nearshore Ridge Complex, Inner Reef, and Middle Reef, Outer Reef and Aggregated Patch Reef
selected <- allsitemd_clean %>%
  filter(Type %in% c("Nearshore Ridge Complex", "Inner Reef", "Middle Reef", 
                     "Artificial", "Outer Reef", "Aggregated Patch Reef"))

# Plot selected sites
polyplot + 
  geom_point(data = selected, 
             aes(x = longitude, y = latitude, shape = dataset), 
             inherit.aes = FALSE, alpha = 0.6) +
  scale_shape_manual(values = c(2, 3, 4, 5))

```

# Map datasets
```{r, fig.width = 10, fig.height = 10}
(dca_plot <- polyplot + 
  geom_point(
    data = filter(selected, dataset == "dca"),
    aes(x = longitude, y = latitude), pch = 13, inherit.aes = FALSE, alpha = 0.6) +
  labs(title = "2017 — DCA Survey"))

(tt21_plot <- polyplot + 
  geom_point(
    data = filter(selected, dataset == "tt21"),
    aes(x = longitude, y = latitude), pch = 13, inherit.aes = FALSE, alpha = 0.6) +
  labs(title = "2021 — Tetra Tech Survey"))

(tt23_plot <- polyplot + 
  geom_point(
    data = filter(selected, dataset == "tt23"),
    aes(x = longitude, y = latitude), pch = 13, inherit.aes = FALSE, alpha = 0.6) +
  labs(title = "2023 — Tetra Tech Survey"))

(drm_plot <- polyplot + 
  geom_point(
    data = filter(selected, dataset == "drm"),
    aes(x = longitude, y = latitude), pch = 13, inherit.aes = FALSE, alpha = 0.6) +
  labs(title = "2024 — Shedd Survey"))
```


```{r combine_selected_count_data}
# Combine all aggregated count data and filter for selected sites
df <- bind_rows(.id = "dataset",
  drm = final_counts_ag,
  dca = dca_counts_ag,
  tt23 = tt_counts_ag,
  tt21 = tt21_counts_ag
) %>%
  filter(site %in% selected$site) %>%
  select(dataset, site, transect_num, taxon, class, n) %>%
  droplevels() %>%
  left_join(allsitemd_clean)

# Add transect area information
df <- df %>%
  mutate(transect_num = if_else(is.na(transect_num), 1, transect_num)) %>%
  mutate(transect_area_m2 = case_when(
    dataset == "drm" ~ 10,    # DRM belt transects were 10m
    dataset == "tt23" ~ 20,     # TT23 belt transects were 20m
    dataset == "tt21" ~ 30,     # TT21 belt transects were 30m
    dataset == "dca" ~ 30     # DCA belt transects were 30m
  ))
```

Can 'Artificial' be aggregated with 'Nearshore Ridge Complex'?

'Artificial' is only present in DCA and minorly in TT -- but absent from Shedd.   

It is in close spatial proximity to Nearshore Ridge Complex -- can these be combined?

Test for differences in coral density in DCA survey
```{r}
# Subset DCA data
dcadf <- dca_counts_ag %>%
  left_join(allsitemd_clean) %>%
  filter(Type %in% c("Nearshore Ridge Complex", "Inner Reef", "Middle Reef", "Artificial"))

# Fit a Negative Binomial GLM
mod_nb <- MASS::glm.nb(n ~ Type, data = dcadf)

# Generate new data only for existing taxon-size class combinations
newdata_1 <- dcadf %>%
  distinct(Type)

# Get predicted values & standard errors (log scale)
preds_nb <- predict(mod_nb, newdata_1, type = "link", se.fit = TRUE)

# Compute both total coral density & taxon-size class-specific densities in one step
results_nb <- newdata_1 %>%
  mutate(
    fit = exp(preds_nb$fit),                    # Convert fitted values to response scale
    fit_se = exp(preds_nb$fit) * preds_nb$se.fit,   # Convert SE using the Delta Method
    fit_var = (fit * preds_nb$se.fit)^2,         # Variance propagation
    fit_lower = exp(preds_nb$fit - 1.96 * preds_nb$se.fit),  # Lower CI
    fit_upper = exp(preds_nb$fit + 1.96 * preds_nb$se.fit)   # Upper CI
  )

# Compute total coral density + confidence intervals
total_ci_nb <- results_nb %>%
  group_by(Type) %>%
  summarize(
    total_density = sum(fit),
    total_se = sqrt(sum(fit_var)),
    lower_95CI = exp(log(total_density) - 1.96 * (total_se / total_density)),
    upper_95CI = exp(log(total_density) + 1.96 * (total_se / total_density))
  )

knitr::kable(total_ci_nb)
```
Highly overlapping confidence intervals for Artifical and Nearshore Ridge Complex, so no difference in coral density.

Test for differences in community composition in DCA survey
```{r}
library(vegan)

# 1. Create a wide community matrix: rows = site x Type, columns = taxa
comm_matrix <- dcadf %>%
  group_by(site, Type, taxon) %>%
  summarize(total_n = sum(n), .groups = "drop") %>%
  pivot_wider(names_from = taxon, values_from = total_n, values_fill = 0)

# 2. Extract community matrix and metadata
comm_data <- comm_matrix %>% select(-site, -Type)
site_info <- comm_matrix %>% select(site, Type)

# 3. Run NMDS (k = 2 dimensions is standard)
set.seed(123)  # for reproducibility
nmds <- metaMDS(comm_data, distance = "bray", k = 2, trymax = 100)

# 4. Prepare data for plotting
scores_df <- scores(nmds)$sites %>%
  bind_cols(site_info)

# 5. Plot NMDS with ggplot2
ggplot(scores_df, aes(x = NMDS1, y = NMDS2, color = Type)) +
  geom_point(size = 3, alpha = 0.8) +
  theme_minimal() +
  labs(title = "NMDS of Coral Community Structure by Habitat Type",
       color = "Habitat Type")
```

High degree of similarity between Artificial and Nearshore Ridge Complex coral communities.

2.2.3. Combine 'Artificial' with 'Nearshore Ridge Complex'
```{r}
# Based on these results, combine "Artificial" with "Nearshore Ridge Complex"
df[df$Type == "Artificial", "Type"] <- "Nearshore Ridge Complex"
```

## By coral taxa

Remove lowest abundance coral taxa

These will be problematic for statistical models

```{r}
# Drop taxa with very few observations
sppcounts <- df %>%
  group_by(taxon) %>%
  summarize(total = sum(n), .groups = "drop") %>%
  arrange(total) 
sppcounts

dff <- df %>%
  filter(taxon %in% filter(sppcounts, total >= 5)$taxon) %>%
  mutate(Type = factor(Type, levels = type_levels))
```

Taxa with less than 5 total observations were filtered out, which included: HCUC, MANG, PAME, FFRA, OCUL, SCOL


# Analyze coral density 

## Fit Bayesian negative binomial model

Predictors: dataset, habitat Type, direction from channel, taxon

```{r}
# Get total counts for each taxon at each site
dfftaxon <- dff %>% 
  group_by(dataset, Type, dir, site, transect_num, transect_area_m2, taxon) %>%
  summarize(n = sum(n)) %>%
  ungroup()

# Remove any taxa not observed in a given dataset / habitat Type ?????
dfftaxon_trimmed <- dfftaxon %>%
  group_by(dataset, Type, dir, taxon) %>%
  filter(any(n > 0)) %>%
  ungroup()

# SUPER MODEL

# mod_nb <- brm(
#   bf(n ~ dataset * Type * dir * taxon + offset(log(transect_area_m2))),
#   family = negbinomial(),
#   data = dfftaxon_trimmed,
#   prior = c(prior(normal(0, 2), class = "b"),          # Weak prior on coefficients
#             prior(normal(0, 5), class = "Intercept"),  # Weak prior on intercept
#             prior(exponential(1), class = "shape")),     # Reasonable prior for NB dispersion
#   chains = 4,  
#   cores = 4,  
#   threads = threading(5),  
#   iter = 1000, warmup = 500,  
#   thin = 2,  
#   control = list(adapt_delta = 0.9, max_treedepth = 12),  
#   backend = "cmdstanr"
# )
# saveRDS(mod_nb, file = "data/processed/mod_nb.rds")
mod_nb <- readRDS("data/processed/mod_nb.rds")

# 1. Create newdata grid (1 m² for standardization)
newdata <- dfftaxon_trimmed %>%
  distinct(dataset, Type, dir, taxon) %>%
  mutate(transect_area_m2 = 1)

# 2. Get fitted values manually by computing summary statistics across all draws
posterior_draws <- add_epred_draws(mod_nb, newdata = newdata) %>%
  mutate(Type = factor(Type, levels = type_levels),
         dataset = factor(dataset, levels = dataset_levels))
```

## Totals by survey, habitat, direction

```{r}
# Compute and plot total coral abundance by dataset, habitat Type, and direction from channel
total_abund <- posterior_draws %>%
  group_by(.draw, dataset, Type, dir) %>%
  summarize(total_epred = sum(.epred), .groups = "drop") %>%
  group_by(dataset, Type, dir) %>%
  summarize(
    fit_mean = mean(total_epred),
    fit_sd = sd(total_epred),
    fit_lower = quantile(total_epred, 0.025),
    fit_upper = quantile(total_epred, 0.975),
    .groups = "drop"
  )

ggplot(total_abund, aes(x = dataset, y = fit_mean, color = dir)) +
  facet_grid(~ Type, labeller = as_labeller(type_labels)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = fit_lower, ymax = fit_upper), width = 0,
                position = position_dodge(width = 0.5)) +
  scale_x_discrete(labels = dataset_labels) +
  theme(axis.text.x = element_text(angle = 90))
```

### North-south differences?
```{r}
# Any N-S differences in total coral abundance?
total_NS_diff <- posterior_draws %>%
  ungroup() %>%
  group_by(.draw, dataset, Type, dir) %>%
  summarize(total_epred = sum(.epred), .groups = "drop") %>%
  pivot_wider(names_from = dir, values_from = total_epred) %>%
  filter(!is.na(N), !is.na(S)) %>%  # make sure both are present
  mutate(diff = N - S)  # or S - N depending on desired contrast

total_NS_summ <- total_NS_diff %>%
  group_by(dataset, Type) %>%
  summarize(
    mean_diff = mean(diff),
    lower_95 = quantile(diff, 0.025),
    upper_95 = quantile(diff, 0.975),
    p_gt_0 = mean(diff > 0),
    p_lt_0 = mean(diff < 0),
    sig = ifelse(lower_95 > 0 | upper_95 < 0, "yes", "no"),
    .groups = "drop"
  )

total_NS_summ
```

### Survey differences?
```{r}
# 1. Sum predicted values across taxa (total coral density per draw × dataset × Type × dir)
draws_total <- posterior_draws %>%
  mutate(dataset = as.character(dataset)) %>%
  group_by(.draw, dataset, Type, dir) %>%
  summarize(total_epred = sum(.epred), .groups = "drop")

# 2. Self-join to compare dataset pairs within each draw × Type × dir
pairwise_total <- draws_total %>%
  rename(dataset1 = dataset, epred1 = total_epred) %>%
  inner_join(
    draws_total %>% rename(dataset2 = dataset, epred2 = total_epred),
    by = c(".draw", "Type", "dir")
  ) %>%
  filter(dataset1 < dataset2) %>%
  mutate(diff = epred1 - epred2)

# 3. Summarize posterior contrasts
summary_total_contrasts <- pairwise_total %>%
  group_by(Type, dir, dataset1, dataset2) %>%
  summarize(
    mean_diff = mean(diff),
    lower = quantile(diff, 0.025),
    upper = quantile(diff, 0.975),
    prob_diff = mean(diff > 0),
    .groups = "drop"
  )

# 4. Optional: filter strong differences
summary_total_contrasts %>%
  filter(prob_diff < 0.01 | prob_diff > 0.99) %>%
  arrange(Type, dir)
```

## Taxon totals by survey, habitat, direction from channel
```{r, fig.width = 10, fig.height = 10}
fitted_taxon <- posterior_draws %>%
  group_by(dataset, Type, dir, taxon) %>%
  summarize(fit_mean = mean(.epred),  # Posterior mean (expected value)
            fit_sd = sd(.epred),  # Posterior standard deviation
            fit_lower = quantile(.epred, 0.025),        # 2.5% quantile (lower CI)
            fit_upper = quantile(.epred, 0.975))    # 97.5% quantile (upper CI)

# Plot
ggplot(fitted_taxon, aes(y = fit_mean, x = Type, color = dir, shape = dataset,
                          group = interaction(dataset, dir))) +
  facet_wrap(taxon ~ ., scales = "free_x") +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_line(position = position_dodge(width = 0.5), alpha = 0.5) +
  geom_errorbar(aes(ymin = fit_lower, ymax = fit_upper), width = 0,
                position = position_dodge(width = 0.5), lwd = 0.25) +
  scale_y_log10() +
  scale_x_discrete(labels = type_labels) +
  labs(x = "Habitat Type", y = "Density (per m2)")
```

### North-south differences?
```{r}
# Any N-S differences in taxon abundance within habitat Types/datasets?
#### Pivot wide so you can calculate N vs S difference per draw
taxon_NS_diff <- posterior_draws %>%
  ungroup() %>%
  select(.draw, dataset, Type, dir, taxon, .epred) %>%
  pivot_wider(names_from = dir, values_from = .epred) %>%
  filter(!is.na(N), !is.na(S)) %>%  # ensure both directions exist for the draw
  mutate(diff = S - N)  # or N - S depending on interpretation

taxon_NS_summ <- taxon_NS_diff %>%
  group_by(dataset, Type, taxon) %>%
  summarize(
    mean_diff = mean(diff),
    lower_95 = quantile(diff, 0.025),
    upper_95 = quantile(diff, 0.975),
    p_gt_0 = mean(diff > 0),
    p_lt_0 = mean(diff < 0),
    sig = ifelse(lower_95 > 0 | upper_95 < 0, "yes", "no"),
    .groups = "drop"
  )

taxon_NS_summ %>%
  filter(sig == "yes") %>%
  mutate(greater = if_else(mean_diff > 0, "N", "S")) %>%
  group_by(dataset, Type, greater) %>%
  summarize(taxa = paste(taxon, collapse = ",")) %>%
  arrange(Type, greater)
```

### Survey differences?
```{r}
# Ensure dataset is character so we can do < comparison
draws_clean <- posterior_draws %>%
  mutate(dataset = as.character(dataset))

# One self-join to get all unique dataset pairs
pairwise_contrasts <- draws_clean %>%
  rename(dataset1 = dataset, epred1 = .epred) %>%
  inner_join(
    draws_clean %>% rename(dataset2 = dataset, epred2 = .epred),
    by = c(".draw", "taxon", "dir", "Type")
  ) %>%
  filter(dataset1 < dataset2) %>%  # Avoid duplicates and self-pairs
  mutate(diff = epred1 - epred2)

# Step: summarize the posterior differences
summary_contrasts <- pairwise_contrasts %>%
  group_by(taxon, dir, Type, dataset1, dataset2) %>%
  summarize(mean_diff = mean(diff),
            lower = quantile(diff, 0.025),
            upper = quantile(diff, 0.975),
            prob_diff = mean(diff > 0),
            .groups = "drop")

out <- summary_contrasts %>% 
  filter(prob_diff < 0.01) %>%
  arrange(taxon, Type, dir)
out
```

# Overall taxon differences among surveys
```{r}
# Proportion of transect area per dataset × Type × dir
survey_weights <- dfftaxon %>%
  group_by(dataset, Type, dir) %>%
  summarize(area = sum(transect_area_m2), .groups = "drop") %>%
  group_by(dataset) %>%
  mutate(weight = area / sum(area)) %>%
  select(dataset, Type, dir, weight)


posterior_weighted <- posterior_draws %>%
  mutate(dataset = as.character(dataset)) %>%
  left_join(survey_weights, by = c("dataset", "Type", "dir")) %>%
  mutate(weighted_epred = .epred * weight)


posterior_totals <- posterior_weighted %>%
  group_by(.draw, dataset, taxon) %>%
  summarize(total_epred = sum(weighted_epred), .groups = "drop")


pairwise_overall <- posterior_totals %>%
  rename(dataset1 = dataset, epred1 = total_epred) %>%
  inner_join(
    posterior_totals %>% rename(dataset2 = dataset, epred2 = total_epred),
    by = c(".draw", "taxon")
  ) %>%
  filter(dataset1 < dataset2) %>%
  mutate(diff = epred1 - epred2)

summary_overall <- pairwise_overall %>%
  group_by(taxon, dataset1, dataset2) %>%
  summarize(mean_diff = mean(diff),
            lower = quantile(diff, 0.025),
            upper = quantile(diff, 0.975),
            prob_diff = mean(diff > 0),
            .groups = "drop")


summary_overall %>%
  filter(upper < 0 | lower > 0) %>%
  print(n = nrow(.))
```

# Total corals in impact zones 

## 4.1. Calculate area of each habitat type in each impact zone
```{r, fig.width = 10, fig.height = 10}
impact_zones <- st_read("data/Impact_zones.kml") %>%
  st_zm(drop = TRUE, what = "ZM") %>%
  st_make_valid() %>%
  st_transform(st_crs(polygons_clean))

impact_zones <- impact_zones %>%
  rename(ImpactZone = Name)  # or whatever column contains zone names

library(ggplot2)

impact_zones_plot <- impact_zones %>%
  mutate(linetype_group = "Impact Zone")

ggplot() +
  # Habitat polygons
  geom_sf(data = polygons_clean, aes(fill = Type), color = "black", size = 0.2, alpha = 0.6) +
  
  # Impact zones with dummy linetype for legend
  geom_sf(data = impact_zones_plot, aes(linetype = linetype_group), 
          fill = NA, color = "black", linewidth = 0.6, show.legend = TRUE) +
  
  # Color scales
  scale_fill_brewer(palette = "Set3", na.value = "gray80") +
  scale_linetype_manual(name = "", values = c("Impact Zone" = "dashed")) +
  
  # Theme and layout
  theme_minimal() +
  labs(title = "Habitat Polygons within Impact Zones", fill = "Type") +
  theme(legend.position = "right") +
  xlim(-80.11, -80.079) +
  ylim(26.08, 26.11)




# Spatial intersection of habitat polygons with impact zones
habitat_in_zones <- st_intersection(polygons_clean, impact_zones)


# Use a projected CRS for accurate area (e.g., UTM Zone 17N for South Florida)
habitat_in_zones_proj <- habitat_in_zones %>%
  st_transform(32617) %>%
  mutate(area_m2 = st_area(geometry))


# Adjust column names depending on your Impact Zones KML
area_summary <- habitat_in_zones_proj %>%
  st_drop_geometry() %>%
  group_by(Type, ImpactZone) %>%
  summarize(total_area_m2 = sum(as.numeric(area_m2)), .groups = "drop")


area_summary[area_summary$Type == "Artificial", "Type"] <- "Nearshore Ridge Complex"

area_summary <- area_summary %>%
  group_by(Type, ImpactZone) %>%
  summarize(total_area_m2 = sum(total_area_m2))
```

## 4.2. Calculate total corals in each impact zone
```{r}
area_summary <- area_summary %>%
  mutate(ImpactZone = factor(ImpactZone, 
    levels = c("Channel", "Side Slopes", "Scenario 2, > 10 cm", "Scenario 2, 5.1-10 cm",
               "Scenario 4, 1.1-5 cm", "Scenario 4, 0.51-1 cm", "Scenario 4, 0.1-0.5 cm")))

totals <- left_join(total_abund, area_summary, by = "Type") %>%
  mutate(tot_estimate = fit_mean * total_area_m2) %>%
  mutate(Type = factor(Type, levels = type_levels)) %>%
  select(dataset, Type, ImpactZone, tot_estimate)

# Define ordered impact zone levels
impact_levels <- c("Channel", "Side Slopes", "Scenario 2, > 10 cm", "Scenario 2, 5.1-10 cm",
                   "Scenario 4, 1.1-5 cm", "Scenario 4, 0.51-1 cm", "Scenario 4, 0.1-0.5 cm")

# Ensure correct factor order
totals <- totals %>%
  mutate(ImpactZone = factor(ImpactZone, levels = impact_levels))

# Cumulative summaries across increasing levels
cumulative_zones <- seq_along(impact_levels) %>%
  map_dfr(function(i) {
    zone_subset <- impact_levels[1:i]

    totals %>%
      drop_na(dataset) %>%
      filter(ImpactZone %in% zone_subset) %>%
      group_by(dataset, Type) %>%
      summarize(tot = sum(tot_estimate), .groups = "drop") %>%
      pivot_wider(names_from = dataset, values_from = tot) %>%
      mutate(zone_group = paste0("z", i))
  })



cumulative_zones %>%
  filter(zone_group == "z7") %>%
  pivot_longer(2:5, names_to = "dataset") %>%
  mutate(dataset = factor(dataset, levels = dataset_levels)) %>%
  ggplot(aes(x = Type, y = value, fill = dataset)) +
  geom_col(position = position_dodge()) +
  scale_fill_discrete(labels = dataset_labels) +
  labs(x = "", y = "Total corals", title = "Total corals in all impact zones, by habitat")

cumulative_zones %>%
  filter(zone_group == "z7") %>%
  pivot_longer(2:5, names_to = "dataset") %>%
  group_by(dataset) %>%
  summarize(value = sum(value, na.rm = T)) %>%
  mutate(dataset = factor(dataset, levels = dataset_levels)) %>%
  ggplot(aes(x = 1, y = value, fill = dataset)) +
  geom_col(position = position_dodge()) +
  scale_fill_discrete(labels = dataset_labels) +
  labs(x = "", y = "Total corals", title = "Total corals in all impact zones - all habitats")
```

