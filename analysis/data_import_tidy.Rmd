---
title: "Port Everglades Coral Survey Data Analysis"
author: "R. Cunning"
date: "2025-04-21"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2      
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r libraries}
# Load packages
library(sf)
library(xml2)
library(tidyverse)
```

```{r taxon_lookup_tables}
# Define genus level taxon groups (plus one family FAVI)
taxon_groups <- list(
  PORI = c("PPOR", "PFUR", "PDIV", "PAST", "PORI"),
  ORBI = c("OFAV", "OANN", "OFRA", "ORBI"),
  FAVI = c("CNAT", "DLAB", "PSTR", "PCLI", "MARE", "FAVI"),
  AGAR = c("AFRA", "AAGA", "AHUM", "ALAM", "AGAR"),
  MADR = c("MAUR", "MSEN", "MDEC", "MPHA", "MADR"),
  SOLE = c("SHYA", "SBOU", "SOLE"),
  SCOL = c("SLAC", "SCUB", "SCOL"),
  SIDE = c("SSID", "SRAD", "SIDE"),
  MYCE = c("MFER", "MLAM", "MALI", "MYCE"),
  OCUL = c("OROB", "ODIF", "OCUL")
)

# Convert to lookup tibble
taxon_lookup <- enframe(taxon_groups, name = "taxon_group", value = "taxon") %>%
  unnest(taxon)



# Define juvenile family level taxon groups (following DRM survey convention)
taxon_groups_juv <- list(
  MUSS = c("ISIN", "ISOP", "MANG", "MYCE", "SCOL", "MUSS"),
  FAVI = c("FAVI", "FFRA", "MARE"),
  MEAN = c("MMEA", "MEAN", "DCYL", "DSTO", "EFAS")
)
# Convert to lookup tibble
taxon_lookup_juv <- enframe(taxon_groups_juv, name = "taxon_group", value = "taxon") %>%
  unnest(taxon)
```

# 1. Import data

## 1.1. 2024 Shedd Survey

### 1.1.1. Shedd site metadata
```{r 2024_shedd_site_metadata}
# Site metadata
drm_sitemd <- readxl::read_xlsx("data/2024_shedd_drm/site_metadata.xlsx") %>%
  janitor::clean_names() %>%
  mutate(site = as.character(drm_site_id)) %>%
  select(site, latitude = lat, longitude = lon) %>%
  mutate(depth = NA)
```

### 1.1.2. Shedd coral data
```{r 2024_shedd_coral_data}
# Adult coral data from main DRM surveys
#adults0 <- read_csv("data/2024_shedd_drm/DRM_broward_corals.csv")
#adults0 %>% filter(team == "Shedd Aquarium")

# Most sites were included in main DRM database for 2024 -- Import these
adultst1t2 <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_RawCoralDataTransect1and2_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  filter(subregion == "Broward-Miami", team == "Shedd Aquarium") %>%
  select(site, transect_num, species, width, height)
adultst3t4 <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_RawCoralDataTransect3and4_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  filter(subregion == "Broward-Miami", team == "Shedd Aquarium") %>%
  select(site, transect_num, species, width, height)

# 9 of our PEV sites were removed from DRM database to avoid oversaturating the ares -- Import these separately
removedt1t2 <- readxl::read_xlsx(
  "data/2024_shedd_drm/2024_DRM_Broward_RemovedSites_T1-T4_Shedd.xlsx", sheet = "Removed Sites T1-T2") %>%
  janitor::clean_names() %>%
  select(site, transect_num, species, width, height)
removedt3t4 <- readxl::read_xlsx(
  "data/2024_shedd_drm/2024_DRM_Broward_RemovedSites_T1-T4_Shedd.xlsx", sheet = "Removed Sites T3-T4") %>%
  janitor::clean_names() %>%
  select(site, transect_num, species, width, height)

# Combine all adult coral data for Shedd DRM surveys at PEV
adults0 <- bind_rows(adultst1t2, adultst3t4, removedt1t2, removedt3t4)
# Convert adult data to long format
adults_long <- adults0 %>%
  mutate(max_width_cm = pmax(width, height, na.rm = TRUE)) %>%
  mutate(max_width_cm = as.character(max_width_cm)) %>%
  mutate(site = str_remove(site, "^AA")) %>%
  select(site, transect_num, taxon = species, max_width_cm) %>%
  drop_na(taxon)     # DROPS when taxon is blank, this is when no corals >4cm were observed

# Juveniles from main DRM surveys (family-level tallies)
# drmjuv <- read_csv("data/2024_shedd_drm/DRM_broward_juveniles.csv") %>%
#   filter(team == "Shedd Aquarium") %>%
#   mutate(site = str_remove(site, "^AA")) %>%
#   select(team, site, transect_num, ends_with("ct")) %>%
#   rename(MCAV = montastraea_ct, MUSS = mussinae_ct, FAVI = faviinae_ct, MEAN = meandrinidae_ct)

# Import juvenile counts from main DRM dataset
juv <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_JuvenileCoralData_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  filter(subregion == "Broward-Miami", team == "Shedd Aquarium")

# Import juvenile counts from sites that were removed from main DRM dataset
removed_juv <- readxl::read_xlsx("data/2024_shedd_drm/Shedd_removed_sites_Juveniles_2024.xlsx") %>%
  janitor::clean_names() %>%
  # Missing values in count data should be zero counts (unique to this datasheet from FWC)
  mutate(across(ends_with("_ct"), ~replace_na(., 0)))

# Combine juvenile data
juv0 <- bind_rows(juv, removed_juv) %>%
  mutate(site = str_remove(site, "^AA")) %>%
  select(site, transect_num, ends_with("ct")) %>%
  rename(MCAV = montastraea_ct, MUSS = mussinae_ct, FAVI = faviinae_ct, MEAN = meandrinidae_ct)

# Convert juvenile data to long format
juv_long <- juv0 %>%
  pivot_longer(c(MUSS, FAVI, MEAN, MCAV), names_to = "taxon", values_to = "n") %>%
  mutate(max_width_cm = "<4") %>%
  uncount(n)



# Other juvenile taxa counts from Transects 1 and 2 (DRM 'bonus data')
t1t2bonus <- read_csv("data/2024_shedd_drm/T1_T2_bonus_data.csv") %>%
  janitor::clean_names() %>%
  mutate(site = replace_na(site, "NA")) %>%    # Because one site is called "NA"
  mutate(transect_num = parse_number(transect))
t1t2juv <- t1t2bonus %>%
  select(site, transect_num, starts_with("small")) %>%
  rename_with(~ toupper(gsub("^small_", "", .x)), starts_with("small_"))
t1t2juv_long <- t1t2juv %>%
  pivot_longer(3:10, names_to = "taxon", values_to = "n") %>%
  mutate(max_width_cm = "<4") %>%
  uncount(n)
# Replace site names in t1t2 bonus data with the correct DRM site ID
penipsites <- readxl::read_xlsx("data/2024_shedd_drm/site_metadata.xlsx") %>%
  janitor::clean_names()
t1t2juv_long_updated <- t1t2juv_long %>%
  left_join(penipsites %>% select(site, drm_site_id), by = "site") %>%
  mutate(site = as.character(drm_site_id)) %>%
  select(-drm_site_id)


# Combine all data
drm_long <- bind_rows(adults_long, juv_long, t1t2juv_long_updated) %>%
  mutate(team = "Shedd Aquarium")

# Check species names
sort(unique(drm_long$taxon))

write_csv(drm_long, file = "data/processed/drm_2024_long.csv")


# COUNT based on rules
# ✅ Updated Rules Summary for counting from DRM/Shedd data:
# Juvenile taxa (searched for in <4cm size class only):
#    "MEAN", "MUSS", "FAVI"
#    → these should only ever appear in <4cm, never >4cm, and should not be zero-filled for adults.
# Other juvenile-capable taxa:
#    "MCAV", "SSID", "SRAD", "PAST", "PPOR", "SINT", "SBOU", "AAGA", "MAUR"
#    → these can be counted in both >4cm and <4cm, but only in <4cm if juveniles were searched on that transect and team.
# Transect-based search rules still apply:
# Transects 1 & 2: all adult taxa always searched. Juvenile search depends on team:
#    "Shedd Aquarium" → all juvenile taxa above searched
#    others → only MEAN, MUSS, FAVI, MCAV
# Transects 3 & 4:
#    only subset of adult taxa searched (adult_taxa_t3t4)
#    only juveniles: MEAN, MUSS, FAVI, MCAV

# Step 1: Define size classes
drm_classed <- drm_long %>%
  mutate(class = case_when(as.numeric(max_width_cm) >= 4 ~ ">4cm",
                           max_width_cm == "<4" ~ "<4cm"))

# Step 2: Define species sets
all_taxa <- unique(drm_classed$taxon)
adult_taxa_t3t4 <- c("CNAT", "DSTO", "DLAB", "MMEA", "MANG", "MALI", 
                     "MFER", "MLAM", "PCLI", "PSTR")
juv_only_taxa <- c("MEAN", "MUSS", "FAVI")
juv_both_taxa <- c("MCAV", "SSID", "SRAD", "PAST", "PPOR", "SINT", "SBOU", "AAGA", "MAUR")
all_juv_taxa <- c(juv_only_taxa, juv_both_taxa)

# Step 3: Build search grid per site × transect × team
search_grid <- drm_classed %>%
  distinct(site, transect_num, team) %>%    # if multiple teams in data, remove value for team
  mutate(
    searched_taxa_class = pmap(list(transect_num, team), function(transect, team) {
      # Helper: define juv taxa allowed for this transect/team
      juv_taxa <- if (transect %in% c(1, 2)) {
        if (team == "Shedd Aquarium") {      # Shedd searched for other juv taxa on T1 and T2, other DRM survey teams did not
          all_juv_taxa
        } else {
          c(juv_only_taxa, "MCAV")
        }
      } else {
        c(juv_only_taxa, "MCAV")
      }
      
      # Adults always searched in 1 & 2, subset in 3 & 4
      adult_taxa <- if (transect %in% c(1, 2)) {
        setdiff(all_taxa, juv_only_taxa)  # exclude juv-only taxa
      } else {
        adult_taxa_t3t4
      }

      # Build grid
      bind_rows(
        expand_grid(taxon = adult_taxa, class = ">4cm"),
        expand_grid(taxon = juv_taxa, class = "<4cm")
      )
    })
  ) %>%
  unnest(searched_taxa_class)

# Step 4: Count observations
counts <- drm_classed %>%
  group_by(site, transect_num, team, taxon, class) %>%
  summarize(n = n(), .groups = "drop")

# Step 5: Join with grid and fill in zeros where appropriate
final_counts <- search_grid %>%
  left_join(counts, by = c("site", "transect_num", "team", "taxon", "class")) %>%
  mutate(n = replace_na(n, 0))

write_csv(final_counts, file = "data/processed/drm_2024_counts.csv")




# AGGREGATE COUNT DATA
# Aggregate taxa
final_counts_ag <- final_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

write_csv(final_counts_ag, file = "data/processed/drm_2024_counts_ag.csv")
```

## 1.2. 2017 Dial Cordy Recon Survey

### 1.2.1. DCA site metadata
```{r 2017_DCA_site_metadata}
# Site metadata
# Read in site coordinates
dca_sitemd0 <- readxl::read_xlsx("data/2017_dca_recon/Recon_Site_Coordinates_Extracted.xlsx") %>%
  janitor::clean_names()

# All sites have start and end coordinates...

# Tidy and Calculate midpoint per transect
dca_sitemd <- dca_sitemd0 %>%
  mutate(
    depth = abs(as.numeric(depth)),
    across(c(latitude, longitude), as.numeric)
  ) %>%
  group_by(site = transect) %>%
  summarize(
    latitude = mean(latitude, na.rm = TRUE),
    longitude = mean(longitude, na.rm = TRUE),
    depth = mean(depth, na.rm = TRUE),
    .groups = "drop"
  )
```

### 1.2.2. DCA coral data
```{r 2017_DCA_coral_data}
# Read in survey data
dca0 <- readxl::read_xlsx("data/2017_dca_recon/Compiled_DCA_RECON_Belt_data.xlsx") %>%
  janitor::clean_names()

dca <- dca0 %>%
  select(1:18) %>%
  rename(site = site_name) %>%
  mutate(site = factor(site)) %>%
  select(site, taxon = coral_species, max_width_cm = max_size_cm)

# Adjust/corrects species IDs
sort(unique(dca$taxon))
dca <- dca %>%
  mutate(taxon = case_when(
    taxon == "AGA SP" ~ "AGAR",
    taxon == "LCUC" ~ "HCUC",
    taxon %in% c("MYCSP", "Mycetophyllia spp.") ~ "MYCE",
    taxon == "OFAV\\" ~ "OFAV",
    taxon %in% c("MAD SP", "MADSP") ~ "MADR",
    taxon == "Scolymia Spp" ~ "SCOL",
    taxon %in% c("SIDSP", "Sid SP", "SID SP.", "SID SP") ~ "SIDE",
    TRUE ~ taxon
  ))
sort(unique(dca$taxon))

# Filter out unidentified corals
dca <- dca %>%
  filter(!taxon %in% c("CORAL", "Cup Coral"))

# Write long data to file
write_csv(dca, file = "data/processed/dca_2017_long.csv")


# Convert to count data
# Add explicit zeros for any taxon/size class missing at any site
dca_counts <- dca %>%
  mutate(class = ifelse(max_width_cm >= 4, ">4cm", "<4cm")) %>%
  count(site, taxon, class) %>%
  complete(site, taxon, class = c(">4cm", "<4cm"), fill = list(n = 0)) %>%
  # # Don't create zeros for MEAN/MUSS/FAVI adults, since these IDs only applied to juv
  filter(!(taxon %in% c("MEAN", "MUSS", "FAVI") & class == ">4cm" & n == 0))

write_csv(dca_counts, file = "data/processed/dca_2017_counts.csv")

# Aggregate count data based on taxonomic groups defined above
dca_counts_ag <- dca_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")



# Further aggregate juvenile counts to family (following DRM methods)
dca_counts_ag <- dca_counts_ag %>%
  left_join(taxon_lookup_juv, by = "taxon") %>%
  mutate(
    taxon = if_else(class == "<4cm" & !is.na(taxon_group), taxon_group, taxon)
  ) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")


write_csv(dca_counts_ag, file = "data/processed/dca_2017_counts_ag.csv")
```


## 1.3. 2023 Tetra Tech Impact Survey

### 1.3.1. TT site metadata
```{r 2023_tt_site_metadata}
# Site metadata
tt_sitemd <- readxl::read_xlsx("data/2023_tt_impact/Impact site tracking.xlsx", skip = 1) %>%
  janitor::clean_names()

tt_sitemd <- tt_sitemd %>%
  mutate(site = transect_name,
         latitude = as.numeric(actual_start_y),
         longitude = as.numeric(actual_start_x)) %>%
  select(site, latitude, longitude) 

# Many sites missing coords in sheet.... whats up with that
tt_sitemd <- drop_na(tt_sitemd, longitude)
```

### 1.3.2. TT coral data
```{r 2023_tt_coral_data}
tt0 <- readxl::read_xlsx("data/2023_tt_impact/Impact Raw Data 05 31 2024.xlsx") %>%
  janitor::clean_names() 

tt <- tt0 %>%
  select(site = transect_name, depth_ft_start,
         taxon = id_abbrev, coral_length_cm, coral_width_cm) %>%
  filter(taxon != "Xesto") %>%
  mutate(taxon = toupper(taxon)) %>%
  mutate(across(c(coral_length_cm, coral_width_cm), as.numeric)) %>%
  mutate(site = factor(site))

tt <- tt %>%
  mutate(max_width_cm = pmax(coral_length_cm, coral_width_cm)) %>%
  select(site, taxon, max_width_cm)

# Check taxa names
sort(unique(tt$taxon))

# Filter out unidentified taxa
tt <- tt %>%
  filter(!taxon %in% c("?", "ID-ABBREV", "NONE", "MHEARD"))

# Adjust/corrects species IDs
tt <- tt %>%
  mutate(taxon = case_when(
    taxon == "AFRAG" ~ "AFRA",
    taxon %in% c("ASP", "ASP.") ~ "AGAR",
    taxon == "MCAV?" ~ "MCAV",
    taxon == "MSP." ~ "MADR",
    taxon == "MUSSID" ~ "MUSS",
    taxon == "MYALI" ~ "MALI",
    taxon == "MYFER" ~ "MFER",
    taxon == "MYLAM" ~ "MLAM",
    taxon == "OFR" ~ "OFRA",
    taxon == "PCLI?" ~ "PCLI",
    taxon %in% c("PSP", "PSP.") ~ "PORI",
    taxon == "SSP." ~ "SIDE",
    taxon == "STOK" ~ "DSTO",
    TRUE ~ taxon
  ))
sort(unique(tt$taxon))

# Write long data to file
write_csv(tt, file = "data/processed/tt_2024_long.csv")





# Count
# Add explicit zeros for any taxon/size class missing at any site
tt_counts <- tt %>%
  mutate(class = ifelse(max_width_cm >= 4, ">4cm", "<4cm")) %>%
  count(site, taxon, class) %>%
  complete(site, taxon, class = c(">4cm", "<4cm"), fill = list(n = 0)) %>%
  # Don't create zeros for MEAN/MUSS/FAVI adults, since these IDs only applied to juv
  filter(!(taxon %in% c("MEAN", "MUSS", "FAVI") & class == ">4cm" & n == 0))

write_csv(tt_counts, file = "data/processed/tt_2024_counts.csv")




# Aggregate count data based on taxonomic groups defined above
tt_counts_ag <- tt_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

# Further aggregate juvenile counts to family (following DRM methods)
tt_counts_ag <- tt_counts_ag %>%
  left_join(taxon_lookup_juv, by = "taxon") %>%
  mutate(
    taxon = if_else(class == "<4cm" & !is.na(taxon_group), taxon_group, taxon)
  ) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

write_csv(tt_counts_ag, file = "data/processed/tt_counts_ag.csv")
```

## 1.4. 2021 Tetra Tech Recon and ESA Surveys

### 1.4.1. 2021 TT site metadata
```{r}
# site metadata
tt21_sitemd0 <- read_csv("data/2021_tt_recon_esa/midpoints_latlon.csv") %>%
  janitor::clean_names()

tt21_sitemd <- tt21_sitemd0 %>%
  mutate(name = str_remove(name, "A$")) %>%
  select(site = name, longitude = lon, latitude = lat)
```

### 1.4.2. 2021 TT coral data
```{r}
# coral data - recon belt transects
tt21recon0 <- readxl::read_xlsx("data/2021_tt_recon_esa/Recon 30x1m Coral Belt Transect.xlsx") %>%
  janitor::clean_names()

tt21recon <- tt21recon0 %>%
  select(site, taxon = id_abbrev, coral_length_cm, coral_width_cm) %>%
  mutate(taxon = toupper(taxon), site = factor(site)) %>%
  mutate(across(c(coral_length_cm, coral_width_cm), as.numeric)) %>%
  mutate(max_width_cm = pmax(coral_length_cm, coral_width_cm)) %>%
  select(site, taxon, max_width_cm)

# ESA survey data
tt21esa0 <- readxl::read_xlsx("data/2021_tt_recon_esa/ESA Coral Belt Transect.xlsx") %>%
  janitor::clean_names()

sort(unique(tt21esa0$esa_id))

tt21esa <- tt21esa0 %>%
  mutate(site = factor(site),
         taxon = case_when(
           esa_id == "Orbicella franksi" ~ "OFRA",
           esa_id == "Orbicella faveolata" ~ "OFAV",
           esa_id == "Acropora cervicornis" ~ "ACER")) %>%
  filter(!is.na(taxon)) %>%
  mutate(max_width_cm = pmax(coral_length_cm, coral_width_cm)) %>%
  select(site, taxon, max_width_cm)

# Combine Recon and ESA survey data
tt21 <- bind_rows(tt21recon, tt21esa)


# Check taxa names
sort(unique(tt21recon$taxon))

# Filter out unidentified OR NON-CORAL taxa
tt21 <- tt21 %>%
  filter(!taxon %in% c("0", "JUVENILE-UNIDENTIFIABLE", "XESTO", "MALC"))

# Adjust/corrects species IDs
tt21 <- tt21 %>%
  mutate(taxon = case_when(
    taxon == "AFRAG" ~ "AFRA",
    taxon == "FFRAG" ~ "FFRA",
    taxon == "MYALI" ~ "MALI",
    taxon == "MYFER" ~ "MFER",
    taxon == "MYLAM" ~ "MLAM",
    taxon == "ODIF/OROB" ~ "OCUL",
    taxon == "PDCLIV" ~ "PCLI",
    taxon == "PDSTR" ~ "PSTR",
    taxon == "PHYLLANGIA AMERICANA" ~ "PAME",
    taxon == "SCOLYMIA CUBENSIS" ~ "SCUB",
    taxon == "SCOLYMIA LACERA" ~ "SLAC",
    TRUE ~ taxon
  ))
sort(unique(tt21$taxon))

# Write long data to file
write_csv(tt21, file = "data/processed/tt_2021_long.csv")





# Count
# Add explicit zeros for any taxon/size class missing at any site
tt21_counts <- tt21 %>%
  mutate(class = ifelse(max_width_cm >= 4, ">4cm", "<4cm")) %>%
  count(site, taxon, class) %>%
  complete(site, taxon, class = c(">4cm", "<4cm"), fill = list(n = 0)) %>%
  # Don't create zeros for MEAN/MUSS/FAVI adults, since these IDs only applied to juv
  filter(!(taxon %in% c("MEAN", "MUSS", "FAVI") & class == ">4cm" & n == 0))

write_csv(tt21_counts, file = "data/processed/tt_2021_counts.csv")




# Aggregate count data based on taxonomic groups defined above
tt21_counts_ag <- tt21_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

# Further aggregate juvenile counts to family (following DRM methods)
tt21_counts_ag <- tt21_counts_ag %>%
  left_join(taxon_lookup_juv, by = "taxon") %>%
  mutate(
    taxon = if_else(class == "<4cm" & !is.na(taxon_group), taxon_group, taxon)
  ) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

write_csv(tt21_counts_ag, file = "data/processed/tt21_counts_ag.csv")
```

## 1.5. 2011 (NSU) and 2017 (DCA) ESA Surveys

## 1.6. Habitat classification polygons
```{r habitat_maps, fig.width = 10, fig.height = 10}
# --- STEP 1: Load KML Polygons ---
polygons <- st_read("data/Habitat classifications.kml")  # update path as needed

# --- STEP 2: Extract Attributes from HTML Description ---
extract_attrs <- function(desc) {
  if (is.na(desc) || desc == "") {
    return(tibble(Habitat = NA, Type = NA, Modifier = NA, Region = NA, Type2 = NA))
  }
  html <- read_html(desc)
  rows <- xml_find_all(html, "//table//table//tr")
  keys <- rows %>% xml_find_all(".//td[1]") %>% xml_text(trim = TRUE)
  vals <- rows %>% xml_find_all(".//td[2]") %>% xml_text(trim = TRUE)
  n <- min(length(keys), length(vals))
  named_vals <- set_names(vals[1:n], keys[1:n])
  tibble(
    Habitat  = named_vals[["Habitat"]],
    Type     = named_vals[["Type"]],
    Modifier = named_vals[["Modifier"]],
    Region   = named_vals[["Region"]],
    Type2    = named_vals[["Type2"]]
  )
}

# Apply function and combine with spatial geometries
attrs <- map_dfr(polygons$Description, extract_attrs)
polygons_clean <- bind_cols(polygons %>% select(-Description), attrs)

# --- STEP 3: Prepare Site Coordinate Data ---
# Get all site coordinates, and assign north and south
allsitemd <- bind_rows(.id = "dataset",
  drm = drm_sitemd,
  dca = dca_sitemd,
  tt23 = tt_sitemd,
  tt21 = tt21_sitemd
) %>%
  mutate(dir = if_else(latitude > 26.093570, "N", "S"))
points <- st_as_sf(allsitemd, coords = c("longitude", "latitude"), crs = 4326)

# --- STEP 4: Validate Geometry and Match CRS ---
polygons_clean <- polygons_clean %>%
  st_zm(drop = TRUE, what = "ZM") %>%
  st_make_valid() %>%
  st_transform(st_crs(points))

sf_use_s2(FALSE)  # prevent s2 geometry issues

# --- STEP 5: Spatial Join ---
joined <- st_join(points, polygons_clean, join = st_within)

joined_df <- joined %>%
  mutate(longitude = st_coordinates(.)[,1],
         latitude = st_coordinates(.)[,2]) %>%
  st_drop_geometry()

allsitemd <- joined_df

# Visualize habitat classifications
(polyplot <- polygons_clean %>% 
  #filter(Type != "Sand") %>%
  ggplot() +
  geom_sf(aes(fill = Type), color = "black", size = 0.2, alpha = 0.6) +
  scale_fill_brewer(palette = "Set3", na.value = "gray80") +
  theme_minimal() +
  labs(title = "Habitat Polygons Colored by Type", fill = "Type") +
  theme(legend.position = "right") +
  xlim(-80.11, -80.079) +
  ylim(26.065, 26.11))

# 'Sand' overlaps some of the other polygons instead of just surrounding them...
# If a point is classified as Sand AND something else, remove Sand...
multiclass <- allsitemd %>%
  group_by(site) %>%
  filter(n() > 1)

# polyplot +
#   geom_point(data = multiclass, aes(x = longitude, y = latitude), 
#              pch = "X", inherit.aes = FALSE)

allsitemd_clean <- allsitemd %>%
  group_by(site) %>%
  filter(!(Type == "Sand" & n() > 1)) %>%
  ungroup()
```

# 2. Subset comparable survey data 

## 2.1. Find habitat and spatial overlap across surveys

```{r, fig.width = 10, fig.height = 10}
# Plot all sites and select subset based on overlap
polyplot + 
  geom_point(data = allsitemd_clean, 
             aes(x = longitude, y = latitude, shape = dataset), 
             inherit.aes = FALSE, alpha = 0.6) +
  #geom_text(data = allsitemd_clean, aes(x = longitude, y = latitude, label = site)) +
  scale_shape_manual(values = c(2, 3, 4, 5))

# Select just Nearshore Ridge Complex, Inner Reef, and Middle Reef, because 2024 surveys did not include outer reef
overlap_lat <- allsitemd_clean %>%
  filter(latitude > 26.08, latitude < 26.11,
         Type %in% c("Nearshore Ridge Complex", "Inner Reef", "Middle Reef", "Artificial"))
overlap_nolat <- allsitemd_clean %>%
  filter(Type %in% c("Nearshore Ridge Complex", "Inner Reef", "Middle Reef", "Artificial"))
#anti_join(overlap_nolat, overlap_lat)
# Choose whether to also apply a latitudinal filter since DRM has a few sites further south than DCA/TT
overlap <- overlap_nolat

# Plot overlap sites
polyplot + 
  geom_point(data = overlap, 
             aes(x = longitude, y = latitude, shape = dataset), 
             inherit.aes = FALSE, alpha = 0.6) +
  scale_shape_manual(values = c(2, 3, 4, 5))

# ggplot(overlap, aes(x = longitude, y = latitude)) +
#   geom_point(aes(shape = dataset, color = Type), alpha = 0.4) +
#   scale_shape_manual(values = c(2, 3, 4))


# Combine all aggregated count data and filter for sites in area of overlap
df <- bind_rows(.id = "dataset",
  drm = final_counts_ag,
  dca = dca_counts_ag,
  tt23 = tt_counts_ag,
  tt21 = tt21_counts_ag
) %>%
  filter(site %in% overlap$site) %>%
  select(dataset, site, transect_num, taxon, class, n) %>%
  droplevels() %>%
  left_join(allsitemd_clean)

write_csv(df, file = "data/processed/all_overlap.csv")
```

## 2.2. Can 'Artificial' be aggregated with 'Nearshore Ridge Complex'?

'Artificial' is only present in DCA and minorly in TT -- but bsent from Shedd.   

It is in close spatial proximity to Nearshore Ridge Complex -- can these be combined?

### 2.2.1. Test for differences in coral density in DCA survey
```{r}
# Subset DCA data
dcadf <- dca_counts_ag %>%
  left_join(allsitemd_clean) %>%
  filter(Type %in% c("Nearshore Ridge Complex", "Inner Reef", "Middle Reef", "Artificial"))

# Fit a Negative Binomial GLM
mod_nb <- MASS::glm.nb(n ~ Type, data = dcadf)

# Generate new data only for existing taxon-size class combinations
newdata_1 <- dcadf %>%
  distinct(Type)

# Get predicted values & standard errors (log scale)
preds_nb <- predict(mod_nb, newdata_1, type = "link", se.fit = TRUE)

# Compute both total coral density & taxon-size class-specific densities in one step
results_nb <- newdata_1 %>%
  mutate(
    fit = exp(preds_nb$fit),                    # Convert fitted values to response scale
    fit_se = exp(preds_nb$fit) * preds_nb$se.fit,   # Convert SE using the Delta Method
    fit_var = (fit * preds_nb$se.fit)^2,         # Variance propagation
    fit_lower = exp(preds_nb$fit - 1.96 * preds_nb$se.fit),  # Lower CI
    fit_upper = exp(preds_nb$fit + 1.96 * preds_nb$se.fit)   # Upper CI
  )

# Compute total coral density + confidence intervals
total_ci_nb <- results_nb %>%
  group_by(Type) %>%
  summarize(
    total_density = sum(fit),
    total_se = sqrt(sum(fit_var)),
    lower_95CI = exp(log(total_density) - 1.96 * (total_se / total_density)),
    upper_95CI = exp(log(total_density) + 1.96 * (total_se / total_density))
  )

knitr::kable(total_ci_nb)
```
Highly overlapping confidence intervals for Artifical and Nearshore Ridge Complex, so no difference in coral density.

### 2.2.2. Test for differences in community composition in DCA survey
```{r}
library(vegan)

# 1. Create a wide community matrix: rows = site x Type, columns = taxa
comm_matrix <- dcadf %>%
  group_by(site, Type, taxon) %>%
  summarize(total_n = sum(n), .groups = "drop") %>%
  pivot_wider(names_from = taxon, values_from = total_n, values_fill = 0)

# 2. Extract community matrix and metadata
comm_data <- comm_matrix %>% select(-site, -Type)
site_info <- comm_matrix %>% select(site, Type)

# 3. Run NMDS (k = 2 dimensions is standard)
set.seed(123)  # for reproducibility
nmds <- metaMDS(comm_data, distance = "bray", k = 2, trymax = 100)

# 4. Prepare data for plotting
scores_df <- scores(nmds)$sites %>%
  bind_cols(site_info)

# 5. Plot NMDS with ggplot2
ggplot(scores_df, aes(x = NMDS1, y = NMDS2, color = Type)) +
  geom_point(size = 3, alpha = 0.8) +
  theme_minimal() +
  labs(title = "NMDS of Coral Community Structure by Habitat Type",
       color = "Habitat Type")
```

High degree of similarity between Artificial and Nearshore Ridge Complex coral communities.

### 2.2.3. Combine 'Artificial' with 'Nearshore Ridge Complex'
```{r}
# Based on these results, combine "Artificial" with "Nearshore Ridge Complex"
df[df$Type == "Artificial", "Type"] <- "Nearshore Ridge Complex"
```

# 3. Analyze survey data

## 3.1. Total density 

### 3.1.2. Density per m2 by habitat across surveys
```{r}
# Compare total corals per square meter across all surveys
# (For DRM, can only include Transect 1 and 2, because 3 and 4 did not record all corals...)

# Add transect size information
df <- df %>%
  mutate(transect_num = if_else(is.na(transect_num), 1, transect_num)) %>%
  mutate(transect_area_m2 = case_when(
    dataset == "drm" ~ 10,    # DRM belt transects were 10m
    dataset == "tt23" ~ 20,     # TT23 belt transects were 20m
    dataset == "tt21" ~ 30,     # TT21 belt transects were 30m
    dataset == "dca" ~ 30     # DCA belt transects were 30m
  )) %>%
  mutate(n_per_m2 = n / transect_area_m2)

# Summarize total corals per square meter across all surveys (only T1 and T2 from DRM)
summ <- df %>%
  filter(transect_num %in% c(1, 2)) %>%
  distinct(dataset, site, transect_num, transect_area_m2) %>%  # avoid double-counting transects
  group_by(dataset, site) %>%
  summarize(
    n_transects = n(),
    area_per_transect = first(transect_area_m2),  # assume it's constant per transect
    total_area = n_transects * area_per_transect,
    .groups = "drop"
  ) %>%
  left_join(
    df %>% group_by(dataset, site, Type) %>% summarize(total_n = sum(n), .groups = "drop"),
    by = c("dataset", "site")
  ) %>%
  mutate(total_corals_per_m2 = total_n / total_area)

# Plot by habitat type
ggplot(summ, aes(x = total_corals_per_m2, fill = dataset)) +
  facet_grid(Type~.) +
  geom_histogram(position = "stack", alpha = 0.5, bins = 30)
```

### 3.1.2. Remove lowest density DCA and TT sites

To be extra conservative, filter out tt/dca surveys with total corals per m2 less than the lowest drm survey. In case these would have been considered unsuitable for drm survey, biasing results to higher coral densities in 2024 drm surveys.

```{r}
# summ %>% 
#   select(dataset, site, Type, total_corals_per_m2) %>%
#   arrange(total_corals_per_m2) %>% print(n = 20)
# lowsites <- summ %>% filter(total_corals_per_m2 < 0.45) %>% pull(site)
# dff <- df %>%
#   filter(!site %in% lowsites)
dff <- df
```

### 3.1.3. Remove lowest abundance coral taxa

These will be problematic for statistical models

```{r}
# Drop taxa with very few observations
sppcounts <- dff %>%
  group_by(taxon) %>%
  summarize(total = sum(n), .groups = "drop") %>%
  arrange(total) 
sppcounts

dff <- dff %>%
  filter(taxon %in% filter(sppcounts, total >= 5)$taxon)
```

Taxa with less than 5 total observations were filtered out, which included: HCUC, MANG, PAME, FFRA, ODIF, OROB, SCOL


## 3.2. Taxon/size class density

### 3.2.1. By survey (overall)
Negative binomial model with taxon-sizeclass
```{r}
dff <- dff %>% mutate(taxclass = interaction(taxon, class, sep = ""))
# Fit a Negative Binomial GLM
mod_nb <- MASS::glm.nb(n ~ dataset * taxclass + offset(log(transect_area_m2)), data = dff)

# Generate new data only for existing taxon-size class combinations
newdata_1 <- dff %>%
  distinct(dataset, taxon, class, taxclass) %>%  # Keep only observed taxon-class combinations
  mutate(transect_area_m2 = 1)  # Set area to 1 for density predictions on a per m2 basis

# Get predicted values & standard errors (log scale)
preds_nb <- predict(mod_nb, newdata_1, type = "link", se.fit = TRUE)

# Compute both total coral density & taxon-size class-specific densities in one step
results_nb <- newdata_1 %>%
  mutate(
    fit = exp(preds_nb$fit),                    # Convert fitted values to response scale
    fit_se = exp(preds_nb$fit) * preds_nb$se.fit,   # Convert SE using the Delta Method
    fit_var = (fit * preds_nb$se.fit)^2,         # Variance propagation
    fit_lower = exp(preds_nb$fit - 1.96 * preds_nb$se.fit),  # Lower CI
    fit_upper = exp(preds_nb$fit + 1.96 * preds_nb$se.fit)   # Upper CI
  )

# Compute total coral density + confidence intervals
total_ci_nb <- results_nb %>%
  group_by(dataset) %>%
  summarize(
    total_density = sum(fit),
    total_se = sqrt(sum(fit_var)),
    lower_95CI = exp(log(total_density) - 1.96 * (total_se / total_density)),
    upper_95CI = exp(log(total_density) + 1.96 * (total_se / total_density))
  )

knitr::kable(total_ci_nb)
# 2.66 total corals per m2 in drm (2.63 if you filter out the further south sites using 'overlap_lat')
# 1.69 in DCA
# 1.69 in TT23
# 1.99 in TT21

# Extract and plot taxon-size-class-specific densities
taxclass_ci_nb <- results_nb %>%
  dplyr::select(dataset, taxon, class, taxclass, fit, fit_se, fit_lower, fit_upper)

# Compute total density per taxon (summing over size classes)
fitted_taxon_nb <- taxclass_ci_nb %>%
  group_by(dataset, taxon) %>%
  summarize(
    fit = sum(fit),  # Sum densities across size classes
    fit_se = sqrt(sum(fit_se^2)),  # Correct SE propagation (variance summation)
    log_fit = log(fit),  # Log-transform fit for proper CI computation
    log_se = fit_se / fit,  # Approximate log-scale standard error
    fit_lower = exp(log_fit - 1.96 * log_se),  # Compute lower CI on log scale
    fit_upper = exp(log_fit + 1.96 * log_se)   # Compute upper CI on log scale
  ) %>%
  ungroup() %>%
  mutate(taxon = fct_reorder(taxon, fit), class = "Total")  # Reorder taxa by abundance


# fitted_combined_nb <- bind_rows(taxclass_ci_nb, fitted_taxon_nb) %>%
#   mutate(taxon = factor(taxon, levels = levels(fitted_taxon_nb$taxon)))

# Combine taxclass and taxon totals, and remove taxa/classes not observed in a dataset
fitted_combined_nb <- taxclass_ci_nb %>% right_join(dff %>% filter(n > 0) %>% distinct(dataset, taxon, class)) %>%
  bind_rows(fitted_taxon_nb %>% right_join(dff %>% filter(n > 0) %>% distinct(dataset, taxon))) %>%
  mutate(taxon = factor(taxon, levels = levels(fitted_taxon_nb$taxon)))

# Plot size classes and taxon totals
ggplot(fitted_combined_nb, aes(x = taxon, y = fit, color = dataset, shape = dataset)) +
  geom_point(aes(size = class), 
             position = position_dodge(width = 0.2), alpha = 0.6) +  
  geom_errorbar(aes(ymin = fit_lower, ymax = fit_upper), 
                width = 0, position = position_dodge(width = 0.2), alpha = 0.6) +  
  scale_y_log10(limits = c(1e-4, 5)) +  
  scale_size_manual(values = c("Total" = 3, ">4cm" = 2, "<4cm" = 1)) +  # Larger points for totals
  #scale_shape_manual(values = c("Total" = 15, ">4cm" = 16, "<4cm" = 16)) +  # Different shape for totals
  coord_flip() +  
  labs(y = "Estimated Coral Density (per m²)", x = "Taxon", 
       color = "Dataset", shape = "Size class", size = "Size class") +  
  theme_minimal() +  
  labs(title = "NB Model")


# Plot just taxon totals
fitted_combined_nb %>%
  filter(class == "Total") %>%
  ggplot(aes(x = taxon, y = fit, color = dataset)) + #, shape = dataset)) +
  geom_point(position = position_dodge(width = 0.2), alpha = 0.6) +  
  geom_errorbar(aes(ymin = fit_lower, ymax = fit_upper), 
                width = 0, position = position_dodge(width = 0.2), alpha = 0.6) +  
  scale_y_log10(limits = c(1e-4, 5)) +  
  #scale_shape_manual(values = c("Total" = 15, ">4cm" = 16, "<4cm" = 16)) +  # Different shape for totals
  coord_flip() +  
  labs(y = "Estimated Coral Density (per m²)", x = "Taxon", 
       color = "Dataset", shape = "Size class", size = "Size class") +  
  theme_minimal() +  
  labs(title = "NB Model")
```

### 3.2.2. Test for differences based on habitat and direction from channel (N vs. S)
Bec
```{r}
# Sum total coral counts per site in each dataset
total_df <- dff %>%
  filter(transect_num %in% c(1, 2)) %>%
  group_by(dataset, Type, dir, site) %>%
  summarize(n = sum(n),
    transect_area_m2 = sum(distinct(cur_data(), transect_num, transect_area_m2)$transect_area_m2),
    .groups = "drop")

# Fit a model with total n
mod_total <- MASS::glm.nb(n ~ dataset * Type * dir + offset(log(transect_area_m2)),
                          data = total_df)

# Use emmeans on this model
emm_total <- emmeans(mod_total, ~ dir | dataset * Type, offset = log(1))
rbind(contrast(emm_total, method = "pairwise", by = c("dataset", "Type")))
# only significant N-S difference in Nearshore Ridge Complex in tt21
# However, TT21 is not really set up to test for N-S diffs because sites were almost all S on NRC...
# polyplot + geom_point(data = tt21_sitemd, aes(x = longitude, y = latitude))

# We can also combine all surveys and test for differences between N and S within Habitats
mod_total2 <- MASS::glm.nb(n ~ Type * dir + offset(log(transect_area_m2)), data = total_df)
anova(mod_total2)
emm_total2 <- emmeans(mod_total2, ~ dir | Type, offset = log(1))
rbind(contrast(emm_total2, method = "pairwise", by = "Type"))
# No differences between N and S of the channel within habitat types

# Further test at the taxon-level for abundant taxa
# Get total counts for each taxon at each site
dfftaxon <- dff %>% 
  filter(transect_num %in% c(1, 2)) %>%
  group_by(dataset, Type, dir, site, transect_num, transect_area_m2, taxon) %>%
  summarize(n = sum(n)) %>%
  ungroup()

# Subset the most abundant taxa for testing N-S differences
dfftaxon_abund <- filter(dfftaxon, taxon %in% c("SIDE", "SINT", "PORI", "MCAV"))

# Fit model
mod_nb <- MASS::glm.nb(n ~ dataset * Type * dir * taxon + offset(log(transect_area_m2)), 
                       data = dfftaxon_abund)

# Test differences
emm <- emmeans(mod_nb, ~ dir | dataset * Type * taxon, type = "response")
contrast_results <- contrast(emm, method = "pairwise", by = c("dataset", "Type", "taxon"))
rbind(contrast_results) %>%
  as_tibble() %>%
  filter(p.value < 0.01)
#polyplot + geom_point(data = dca_sitemd, aes(x = longitude, y = latitude))

# In the DCA dataset NRC surveys, MCAV and SINT showed different abundance N and S of the channel. So, there could be some subtle differences. But no other surveys show any North-South differences within habitats for any species, or in overall total coral densities. Therefore, proceed with analysis that does NOT distinguish between North and South. 
```

### 3.2.2. By habitat and direction, by survey
Use most abundant taxa to test whether North vs. South of channel is different (within habitat Types)

```{r}
# Get total counts for each taxon at each site
dfftaxon <- dff %>% 
  group_by(dataset, Type, dir, site, transect_num, transect_area_m2, taxon) %>%
  summarize(n = sum(n)) %>%
  ungroup()

# Fit a Negative Binomial GLM     
# Note: also tried pscl::zeroinfl and was nearly identical to glm.nb results
mod_nb <- MASS::glm.nb(n ~ dataset * Type * taxon + offset(log(transect_area_m2)), data = dfftaxon)

# Generate new data only for existing taxon-size class combinations
newdata_1 <- dfftaxon %>%
  distinct(dataset, Type, taxon) %>%  
  mutate(transect_area_m2 = 1)  # Set area to 1 for density predictions on a per m2 basis

# Get predicted values & standard errors (log scale)
preds_nb <- predict(mod_nb, newdata_1, type = "link", se.fit = TRUE)
# newdata_1 <- bind_cols(newdata_1, preds_nb) %>% mutate(fit = exp(fit)) %>%
#   mutate(taxon = fct_reorder(taxon, fit), class = "Total")  # Reorder taxa by abundance

# Compute both total coral density & taxon-size class-specific densities in one step
results_nb <- newdata_1 %>%
  mutate(
    fit = exp(preds_nb$fit),                    # Convert fitted values to response scale
    fit_se = exp(preds_nb$fit) * preds_nb$se.fit,   # Convert SE using the Delta Method
    fit_var = (fit * preds_nb$se.fit)^2,         # Variance propagation
    fit_lower = exp(preds_nb$fit - 1.96 * preds_nb$se.fit),  # Lower CI
    fit_upper = exp(preds_nb$fit + 1.96 * preds_nb$se.fit)   # Upper CI
  )

# Compute total coral density + confidence intervals
total_ci_nb <- results_nb %>%
  group_by(dataset, Type) %>%
  summarize(
    total_density = sum(fit),
    total_se = sqrt(sum(fit_var)),
    lower_95CI = exp(log(total_density) - 1.96 * (total_se / total_density)),
    upper_95CI = exp(log(total_density) + 1.96 * (total_se / total_density))
  )

knitr::kable(total_ci_nb)

# Extract and plot taxon-size-class-specific densities
taxclass_ci_nb <- results_nb %>%
  dplyr::select(dataset, Type, taxon, fit, fit_se, fit_lower, fit_upper)

# Compute total density per taxon (summing over size classes)
fitted_taxon_nb <- taxclass_ci_nb %>%
  group_by(dataset, Type, taxon) %>%
  summarize(
    fit = sum(fit),  # Sum densities across size classes
    fit_se = sqrt(sum(fit_se^2)),  # Correct SE propagation (variance summation)
    log_fit = log(fit),  # Log-transform fit for proper CI computation
    log_se = fit_se / fit,  # Approximate log-scale standard error
    fit_lower = exp(log_fit - 1.96 * log_se),  # Compute lower CI on log scale
    fit_upper = exp(log_fit + 1.96 * log_se)   # Compute upper CI on log scale
  ) %>%
  ungroup() %>%
  mutate(taxon = fct_reorder(taxon, fit), class = "Total")  # Reorder taxa by abundance


fitted_combined_nb <- bind_rows(taxclass_ci_nb, fitted_taxon_nb) %>%
  mutate(taxon = factor(taxon, levels = levels(fitted_taxon_nb$taxon)))

# Combine taxclass and taxon totals, and remove taxa/classes not observed in a dataset
fitted_combined_nb <- taxclass_ci_nb %>% right_join(dff %>% filter(n > 0) %>% distinct(dataset, taxon, Type)) %>%
  bind_rows(fitted_taxon_nb %>% right_join(dff %>% filter(n > 0) %>% distinct(dataset, taxon, Type))) %>%
  mutate(taxon = factor(taxon, levels = levels(fitted_taxon_nb$taxon)))

ggplot(fitted_combined_nb, aes(x = taxon, y = fit, color = dataset)) +
  geom_point(aes(size = class), 
             position = position_dodge(width = 0.2), alpha = 0.6) +  
  geom_errorbar(aes(ymin = fit_lower, ymax = fit_upper), 
                width = 0, position = position_dodge(width = 0.2), alpha = 0.6) +  
  facet_wrap(~Type) +
  scale_y_log10(limits = c(1e-4, 5)) +  
  #scale_size_manual(values = c("Total" = 4, ">4cm" = 2.5, "<4cm" = 1)) +  # Larger points for totals
  #scale_shape_manual(values = c("Total" = 15, ">4cm" = 16, "<4cm" = 16)) +  # Different shape for totals
  coord_flip() +  
  labs(y = "Estimated Coral Density (per m²)", x = "Taxon", 
       color = "Dataset", shape = "Size class", size = "Size class") +  
  theme_minimal() +  
  labs(title = "NB Model")
```

# 4. Total corals in impact zones 

## 4.1. Calculate area of each habitat type in each impact zone
```{r, fig.width = 10, fig.height = 10}
impact_zones <- st_read("data/Impact_zones.kml") %>%
  st_zm(drop = TRUE, what = "ZM") %>%
  st_make_valid() %>%
  st_transform(st_crs(polygons_clean))

impact_zones <- impact_zones %>%
  rename(ImpactZone = Name)  # or whatever column contains zone names

library(ggplot2)

impact_zones_plot <- impact_zones %>%
  mutate(linetype_group = "Impact Zone")
ggplot() +
  # Habitat polygons
  geom_sf(data = polygons_clean, aes(fill = Type), color = "black", size = 0.2, alpha = 0.6) +
  
  # Impact zones with dummy linetype for legend
  geom_sf(data = impact_zones_plot, aes(linetype = linetype_group), 
          fill = NA, color = "black", linewidth = 0.6, show.legend = TRUE) +
  
  # Color scales
  scale_fill_brewer(palette = "Set3", na.value = "gray80") +
  scale_linetype_manual(name = "", values = c("Impact Zone" = "dashed")) +
  
  # Theme and layout
  theme_minimal() +
  labs(title = "Habitat Polygons within Impact Zones", fill = "Type") +
  theme(legend.position = "right") +
  xlim(-80.11, -80.079) +
  ylim(26.08, 26.11)




# Spatial intersection of habitat polygons with impact zones
habitat_in_zones <- st_intersection(polygons_clean, impact_zones)


# Use a projected CRS for accurate area (e.g., UTM Zone 17N for South Florida)
habitat_in_zones_proj <- habitat_in_zones %>%
  st_transform(32617) %>%
  mutate(area_m2 = st_area(geometry))


# Adjust column names depending on your Impact Zones KML
area_summary <- habitat_in_zones_proj %>%
  st_drop_geometry() %>%
  group_by(Type, ImpactZone) %>%
  summarize(total_area_m2 = sum(as.numeric(area_m2)), .groups = "drop")

area_summary2 <- area_summary %>%
  filter(Type %in% c("Nearshore Ridge Complex", "Artificial", "Inner Reef", "Middle Reef"))

area_summary2[area_summary2$Type == "Artificial", "Type"] <- "Nearshore Ridge Complex"

area_summary2 <- area_summary2 %>%
  group_by(Type, ImpactZone) %>%
  summarize(total_area_m2 = sum(total_area_m2))
```

## 4.2. Calculate total corals in each impact zone
```{r}
area_summary2
fitted_combined_nb

totals <- full_join(fitted_combined_nb, area_summary2, by = "Type") %>%
  mutate(tot_lower = fit_lower * total_area_m2,
         tot_upper = fit_upper * total_area_m2) %>%
  select(dataset, Type, taxon, ImpactZone, tot_lower, tot_upper)

res <- totals %>%
    drop_na(dataset) %>%
  group_by(dataset, ImpactZone) %>%
  summarize(totlow = sum(tot_lower),
            totup = sum(tot_upper)) %>%
  pivot_wider(names_from = dataset, values_from = c(totlow, totup))

res2 <- res %>%
  # Add totals
  add_row(ImpactZone = "Total",
    !!!res %>% summarise(across(where(is.numeric), sum, na.rm = TRUE)) %>% as.list()) %>%
  # Format ranges
  mutate(across(where(is.numeric), ~ sprintf("%.1e", .))) %>%
  unite(dca, totlow_dca, totup_dca, sep = " — ") %>%
  unite(tt21, totlow_tt21, totup_tt21, sep = " — ") %>%
  unite(tt23, totlow_tt23, totup_tt23, sep = " — ") %>%
  unite(drm, totlow_drm, totup_drm, sep = " — ")

knitr::kable(res2, caption = "Total number of corals in each Impact Zone for the Nearshore Ridge Complex, Inner, and Middle Reefs. Note: DOES NOT INCLUDE Outer Reef.")

```


```{r}
# What if we join all data across all studies?
# Fit a Negative Binomial GLM     
# Note: also tried pscl::zeroinfl and was nearly identical to glm.nb results
mod_nb <- MASS::glm.nb(n ~ Type * taxon + dataset + offset(log(transect_area_m2)), data = dfftaxon)

emm_taxon <- emmeans(mod_nb, ~ taxon | Type, offset = log(1), type = "response")  # per m²
# emmeans is acting weird relative to the predict method using earlier.
as_tibble(emm_taxon) %>%
  full_join(area_summary2) %>%
  mutate(total = asy)

total_density_df <- emm_taxon_df %>%
  group_by(Type) %>%
  summarize(
    total_density = sum(response),
    se_total = sqrt(sum(SE^2)),
    .groups = "drop"
  )

total_density_df %>%
  full_join(area_summary2, by = "Type") %>%
  mutate(total = total_density * total_area_m2) %>%
  group_by(ImpactZone) %>%
  summarize(total = sum(total, na.rm = T))
```

