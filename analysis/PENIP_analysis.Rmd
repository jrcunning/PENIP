---
title: "Port Everglades Coral Survey Data Analysis"
author: "R. Cunning"
date: "2025-09-05"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2      
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE)
```

# Setup
```{r libraries}
# Load packages
library(MASS)   # for fitdistr
library(stats)  # for qlogis
library(sf)
library(xml2)
library(brms)
library(vegan)
library(kableExtra)
library(treemapify)
library(ggrepel)
library(igraph)
library(cowplot)
library(tidyverse)
library(tidybayes)
library(ggtext)
library(patchwork)
library(moments)
library(colorspace)
```

```{r definitions}
# Define genus level taxon groups (plus one family FAVI)
taxon_groups <- list(
  PORI = c("PPOR", "PFUR", "PDIV", "PAST", "PORI"),
  ORBI = c("OFAV", "OANN", "OFRA", "ORBI"),
  AGAR = c("AFRA", "AAGA", "AHUM", "ALAM", "AGAR"),
  MADR = c("MAUR", "MSEN", "MDEC", "MPHA", "MADR"),
  SOLE = c("SHYA", "SBOU", "SOLE"),
  SCOL = c("SLAC", "SCUB", "SCOL"),
  SIDE = c("SSID", "SRAD", "SIDE"),
  MYCE = c("MFER", "MLAM", "MALI", "MYCE"),
  OCUL = c("OROB", "ODIF", "OCUL")
)
# Convert to lookup tibble
taxon_lookup <- enframe(taxon_groups, name = "taxon_group", value = "taxon") %>%
  unnest(taxon)


# Define juvenile family level taxon groups (following DRM survey convention)
taxon_groups_juv <- list(
  MUSS = c("ISIN", "ISOP", "MANG", "MYCE", "SCOL", "MUSS", "MALI", "MFER"),
  FAVI = c("FAVI", "FFRA", "MARE", "DLAB", "PSTR", "PCLI", "CNAT"),
  MEAN = c("MMEA", "MEAN", "DCYL", "DSTO", "EFAS")
)
taxon_group_df <- bind_rows(lapply(names(taxon_groups_juv), function(group) {
  tibble(taxon = taxon_groups_juv[[group]], group = group)
}))
taxon_group_df <- taxon_group_df %>% filter(taxon != group)
# Convert to lookup tibble
taxon_lookup_juv <- enframe(taxon_groups_juv, name = "taxon_group", value = "taxon") %>%
  unnest(taxon)


# Create taxon labels
taxon_labels <- c(
  ACER = 'italic("A. cervicornis")',
  AGAR = 'italic("Agaricia")~spp.',
  CNAT = 'italic("C. natans")',
  DLAB = 'italic("D. labyrinthiformis")',
  DSTO = 'italic("D. stokesii")',
  EFAS = 'italic("E. fastigiata")',
  FAVI = '"Faviinae"',
  MADR = 'italic("Madracis")~spp.',
  MCAV = 'italic("M. cavernosa")',
  MEAN = '"Meandrinidae"',
  MMEA = 'italic("M. meandrites")',
  MUSS = '"Mussinae"',
  MYCE = 'italic("Mycetophyllia")~spp.',
  ORBI = 'italic("Orbicella")~spp.',
  PCLI = 'italic("P. clivosa")',
  PORI = 'italic("Porites")~spp.',
  PSTR = 'italic("P. strigosa")',
  SIDE = 'italic("Siderastrea")~spp.',
  SINT = 'italic("S. intersepta")',
  SOLE = 'italic("Solenastrea")~spp.',
   All = '"All taxa"'
)


# Define SCTLD susceptibility groups (following Papke et al. 2024)
group_definitions <- tibble(
  taxon = names(taxon_labels),
  sus_group = case_when(
    taxon %in% c("FAVI", "MUSS", "MEAN", "DSTO", "EFAS", "MMEA", "DLAB", "CNAT", "PSTR", "PCLI") ~ "high_sus",
    taxon %in% c("MCAV", "ORBI", "SIDE", "SINT", "SOLE") ~ "mod_sus",
    taxon %in% c("ACER", "PORI", "AGAR", "MYCE", "MADR") ~ "low_sus",
    TRUE ~ NA_character_
  )
) %>%
  mutate(sus_group = factor(sus_group, levels = c("low_sus", "mod_sus", "high_sus")))


# Order levels of Habitat Types
type_levels <- c("Nearshore Ridge Complex", "Inner Reef", "Middle Reef",
                 "Outer Reef")
type_labels <- c("NRC", "IR", "MR", "OR")
names(type_labels) <- type_levels
type_labels2 <- c("Nearshore\nRidge Complex", "Inner\nReef", "Middle\nReef", "Outer\nReef")


# Order survey datasets
dataset_levels <- c("nsu11_esa", "dca17_esa", "dca17", "tt21", "tt23", "drm24")
dataset_labels <- c("2011 / NSU ESA", "2017 / DCA ESA", "2017 / DCA Recon", "2021 / Tetra Tech", "2023 / Tetra Tech", "2024 / Shedd")
names(dataset_labels) <- dataset_levels
```

# Import data

## Coral survey data
### 2011 NSU ESA Survey
```{r}
# Import data
nsu11_esa0 <- readxl::read_xlsx("data/2011_nsu_esa/Port Everglades_NSU 2011and DCA 2017_ESA surveys.xlsx",
                           sheet = "2011_NSU_ESA survey") %>%
  janitor::clean_names()


# Site metadata
nsu11_esa_sitemd <- nsu11_esa0 %>%
  select(site = ident, latitude = lat, longitude = long) %>%
  mutate(site = as.character(site))



# ESA coral count data
## DO NOT KEEP M.FEROX DATA -- ALL OTHER SURVEYS ALL MYCETOPHYLLIA ARE ALICIAE, so cannot combine at 'MYCE' (genus) level
nsu11_esa_counts <- nsu11_esa0 %>%
  select(site = ident,
         ACER = a_cervic_1, OANN = m_annula_1, OFAV = m_faveol_1, OFRA = m_franks_1, DSTO = d_stokes_1) %>%
  pivot_longer(-site, names_to = "taxon", values_to = "n") %>%
  # Assume all were >4cm since no sizes are reported
  mutate(class = ">4cm") %>%
  mutate(site = as.character(site))

# Aggregate taxa (multiple orbicella observed --> ORBI)
nsu11_esa_counts_ag <- nsu11_esa_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop") %>%
  mutate(tier = "t1")
```

### 2017 DCA ESA Survey
```{r}
# Site metadata
dca17_esa_sitemd0 <- readxl::read_xlsx("data/2017_dca_esa/Port Everglades_NSU 2011and DCA 2017_ESA surveys.xlsx",
                                       sheet = "2017_DCA_ESA survey") %>% janitor::clean_names()

dca17_esa_sitemd <- dca17_esa_sitemd0 %>%
  select(site = id, longitude, latitude) %>%
  mutate(site = as.character(site))


# Coral data
# Appendix D -- contains individual colony sizes for observed corals
dca17_esa0 <- readxl::read_xlsx("data/2017_dca_esa/Appendix D_ESA_listed_coral_Plotted_Locations.xlsx") %>%
  janitor::clean_names() %>%
  select(site = site_id, taxon = species, length_cm, width_cm, height_cm, m2_of_habi, density) %>%
  mutate(across(ends_with("cm"), as.numeric))

# Assign size classes
dca17_esa <- dca17_esa0 %>%
  mutate(max_dim_cm = pmax(length_cm, width_cm, height_cm, na.rm = TRUE),
         class = if_else(max_dim_cm >= 4, ">4cm", "<4cm"))

# Count taxon and size class per site
dca17_esa_counts <- dca17_esa %>%
  count(site, taxon, class) %>%
  mutate(site = as.character(site))

# Aggregate taxa (OFAV -> ORBI)
dca17_esa_counts_ag <- dca17_esa_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")


# Merge with site metadata to get zero counts
## Define all taxon-class combos to include
all_taxon_class <- expand_grid(
  taxon = c("ACER", "ORBI"),  # example taxa
  class = c("<4cm", ">4cm")
)
# Get all site IDs from the site metadata
all_sites <- dca17_esa_sitemd %>%
  distinct(site)
# Create full site × taxon × class combinations
full_grid <- expand_grid(
  site = as.character(all_sites$site),
  all_taxon_class
)
# Left join with observed counts and fill missing with 0
dca17_esa_counts_ag_full <- full_grid %>%
  left_join(dca17_esa_counts_ag, by = c("site", "taxon", "class")) %>%
  mutate(n = replace_na(n, 0))
```


### 2017 DCA Recon Survey

```{r 2017_DCA_recon_data}
# Site metadata
# Read in site coordinates
dca17_sitemd0 <- readxl::read_xlsx("data/2017_dca_recon/Recon_Site_Coordinates_Extracted.xlsx") %>%
  janitor::clean_names()

# All sites have start and end coordinates...
# Tidy and Calculate midpoint per transect
dca17_sitemd <- dca17_sitemd0 %>%
  mutate(
    depth = abs(as.numeric(depth)),
    across(c(latitude, longitude), as.numeric)
  ) %>%
  group_by(site = transect) %>%
  summarize(
    latitude = mean(latitude, na.rm = TRUE),
    longitude = mean(longitude, na.rm = TRUE),
    depth = mean(depth, na.rm = TRUE),
    .groups = "drop"
  )


# Read in survey data
dca170 <- readxl::read_xlsx("data/2017_dca_recon/Compiled_DCA_RECON_Belt_data.xlsx") %>%
  janitor::clean_names()

dca17 <- dca170 %>%
  dplyr::select(1:18) %>%
  rename(site = site_name) %>%
  mutate(site = factor(site)) %>%
  dplyr::select(site, taxon = coral_species, max_width_cm = max_size_cm)

# Adjust/corrects species IDs
sort(unique(dca17$taxon))
dca17 <- dca17 %>%
  mutate(taxon = case_when(
    taxon == "AGA SP" ~ "AGAR",
    taxon == "LCUC" ~ "HCUC",
    taxon %in% c("MYCSP", "Mycetophyllia spp.") ~ "MYCE",
    taxon == "OFAV\\" ~ "OFAV",
    taxon %in% c("MAD SP", "MADSP") ~ "MADR",
    taxon == "Scolymia Spp" ~ "SCOL",
    taxon %in% c("SIDSP", "Sid SP", "SID SP.", "SID SP") ~ "SIDE",
    TRUE ~ taxon
  ))
sort(unique(dca17$taxon))

# Filter out unidentified corals
dca17 <- dca17 %>%
  filter(!taxon %in% c("CORAL", "Cup Coral"))

# Convert to count data
# Add explicit zeros for any taxon/size class missing at any site
dca17_counts <- dca17 %>%
  mutate(class = ifelse(max_width_cm >= 4, ">4cm", "<4cm")) %>%
  count(site, taxon, class) %>%
  complete(site, taxon, class = c(">4cm", "<4cm"), fill = list(n = 0)) %>%
  # # Don't create zeros for MEAN/MUSS/FAVI adults, since these IDs only applied to juv
  filter(!(taxon %in% c("MEAN", "MUSS", "FAVI") & class == ">4cm" & n == 0))

# Aggregate count data based on taxonomic groups defined above
dca17_counts_ag <- dca17_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

dca17_counts_ag %>%
  filter(taxon == "DSTO") %>%
  group_by(class) %>%
  summarize(tot = sum(n))
# 100% of observed DSTO were >4cm

# Further aggregate juvenile counts to family (following DRM methods)
dca17_counts_ag <- dca17_counts_ag %>%
  left_join(taxon_lookup_juv, by = "taxon") %>%
  mutate(
    taxon = if_else(class == "<4cm" & !is.na(taxon_group), taxon_group, taxon)
  ) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")
```

### 2021 TT Recon & ESA Survey

```{r tt21_site_metadata}
# Recon site metadata
tt21_sitemd0 <- read_csv("data/2021_tt_recon_esa/midpoints_latlon.csv") %>%
  janitor::clean_names()

tt21_sitemd <- tt21_sitemd0 %>%
  mutate(name = str_remove(name, "A$")) %>%
  select(site = name, longitude = lon, latitude = lat)

# There was a lot of sand in these transects that was quantified in final RECON report (though these were the same transects for the ESA and RECON datasets). Extracted this data from RECON report, Table 2:
tt21_sand <- read_csv("data/2021_tt_recon_esa/Table_2_Port_Everglades_RECON.csv") %>%
  janitor::clean_names()

tt21_m_nosand <- tt21_sand %>%
  mutate(area_m2 = 30 - meters_of_sc_sp) %>%
  mutate(site = as.character(site))

# Exclude sites that were 100% sand
allsand <- tt21_m_nosand %>% filter(percent_cover_sc_sp == "100%")

tt21_sitemd <- tt21_sitemd %>% filter(!site %in% allsand$site)

# TT21 ESA Survey Site MD
tt21_esa_sitemd0 <- readxl::read_xlsx("data/2021_tt_recon_esa/ESA Transect Sed Line-Intercept_RAW-Revised.xlsx",
                                      skip = 1) %>%
  select(18:ncol(.)) %>%
  janitor::clean_names() %>%
  rename(site = row_labels)

tt21_esa_sitemd <- tt21_esa_sitemd0 %>%
  # total sum transect length * length of recorded sediment * 4m width - 16m2 overlap (crossed design)
  mutate(area = ((200 - sum_of_no_rb_sed_segment_cover) * 4) - 16) %>%
  select(site, area)




# Coral data - recon belt transects
tt21recon0 <- readxl::read_xlsx("data/2021_tt_recon_esa/Recon 30x1m Coral Belt Transect.xlsx") %>%
  janitor::clean_names()

tt21recon <- tt21recon0 %>%
  select(site, taxon = id_abbrev, coral_length_cm, coral_width_cm) %>%
  mutate(taxon = toupper(taxon), site = factor(site)) %>%
  mutate(across(c(coral_length_cm, coral_width_cm), as.numeric)) %>%
  mutate(max_width_cm = pmax(coral_length_cm, coral_width_cm)) %>%
  select(site, taxon, max_width_cm)

# ESA survey data
tt21esa0 <- readxl::read_xlsx("data/2021_tt_recon_esa/ESA Coral Belt Transect.xlsx") %>%
  janitor::clean_names()

sort(unique(tt21esa0$esa_id))

tt21esa <- tt21esa0 %>%
  mutate(site = factor(site),
         taxon = case_when(
           esa_id == "Orbicella franksi" ~ "OFRA",
           esa_id == "Orbicella faveolata" ~ "OFAV",
           esa_id == "Acropora cervicornis" ~ "ACER")) %>%
  filter(!is.na(taxon)) %>%
  mutate(max_width_cm = pmax(coral_length_cm, coral_width_cm)) %>%
  select(site, taxon, max_width_cm)

# Combine Recon and ESA survey data
tt21 <- bind_rows(tt21recon, tt21esa)


# Check taxa names
sort(unique(tt21recon$taxon))

# Filter out unidentified OR NON-CORAL taxa
tt21 <- tt21 %>%
  filter(!taxon %in% c("0", "JUVENILE-UNIDENTIFIABLE", "XESTO", "MALC"))

# Adjust/corrects species IDs
tt21 <- tt21 %>%
  mutate(taxon = case_when(
    taxon == "AFRAG" ~ "AFRA",
    taxon == "FFRAG" ~ "FFRA",
    taxon == "MYALI" ~ "MALI",
    taxon == "MYFER" ~ "MFER",
    taxon == "MYLAM" ~ "MLAM",
    taxon == "ODIF/OROB" ~ "OCUL",
    taxon == "PDCLIV" ~ "PCLI",
    taxon == "PDSTR" ~ "PSTR",
    taxon == "PHYLLANGIA AMERICANA" ~ "PAME",
    taxon == "SCOLYMIA CUBENSIS" ~ "SCUB",
    taxon == "SCOLYMIA LACERA" ~ "SLAC",
    TRUE ~ taxon
  ))
sort(unique(tt21$taxon))


# Count
# Add explicit zeros for any taxon/size class missing at any site
tt21_counts <- tt21 %>%
  mutate(class = ifelse(max_width_cm >= 4, ">4cm", "<4cm")) %>%
  count(site, taxon, class) %>%
  complete(site, taxon, class = c(">4cm", "<4cm"), fill = list(n = 0)) %>%
  # Don't create zeros for MEAN/MUSS/FAVI adults, since these IDs only applied to juv
  filter(!(taxon %in% c("MEAN", "MUSS", "FAVI") & class == ">4cm" & n == 0))


# Aggregate count data based on taxonomic groups defined above
tt21_counts_ag <- tt21_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  dplyr::select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

tt21_counts_ag %>%
  filter(taxon == "DSTO") %>%
  group_by(class) %>%
  summarize(tot = sum(n))
## 18/22 DSTO are >4cm

# Further aggregate juvenile counts to family (following DRM methods)
tt21_counts_ag <- tt21_counts_ag %>%
  left_join(taxon_lookup_juv, by = "taxon") %>%
  mutate(
    taxon = if_else(class == "<4cm" & !is.na(taxon_group), taxon_group, taxon)
  ) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

# Exclude data from sites that were recorded as 100% sand
tt21_counts_ag <- tt21_counts_ag %>% filter(site %in% tt21_sitemd$site)
```

### 2023 TT Impact Survey

```{r 2023_tt_data}
# Site metadata
tt23_sitemd <- readxl::read_xlsx("data/2023_tt_impact/Impact site tracking.xlsx", skip = 1) %>%
  janitor::clean_names()

tt23_sitemd <- tt23_sitemd %>%
  mutate(site = tolower(transect_name),
         latitude = as.numeric(actual_start_y),
         longitude = as.numeric(actual_start_x)) %>%
  select(site, latitude, longitude) 

tt23_sitemd <- drop_na(tt23_sitemd, longitude)


# vertical wall transects
tt23v_sitemd <- readxl::read_xlsx("data/2023_tt_impact/Impact site tracking.xlsx", sheet = "Vertical Wall") %>%
  janitor::clean_names()

tt23v_sitemd <- tt23v_sitemd %>%
  mutate(
    longitude = (actual_start_x + actual_end_x) / 2,
    latitude = (actual_start_y + actual_end_y) / 2
  ) %>%
  mutate(site = tolower(str_remove_all(name, "[[:space:][:punct:]]"))) %>%
  select(site, latitude, longitude) %>%
  drop_na(site)

# change "cpss" transect names to "cpsse" because this is how they are coded in the coral data (etc.)
tt23v_sitemd <- tt23v_sitemd %>%
  mutate(site = gsub("cpss", "cpsse", site),
         site = gsub("lrnw", "lrmnw", site),
         site = gsub("lrsw", "lrmsw", site))

tt23_sitemd <- bind_rows(
  tt23_sitemd,
  tt23v_sitemd
)



# Coral data
tt230 <- readxl::read_xlsx("data/2023_tt_impact/Impact Raw Data 05 31 2024.xlsx") %>%
  janitor::clean_names() 

tt23 <- tt230 %>%
  mutate(transect_name = tolower(str_remove_all(transect_name, "[[:space:][:punct:]]"))) %>%
  select(site = transect_name, depth_ft_start,
         taxon = id_abbrev, coral_length_cm, coral_width_cm) %>%
  filter(taxon != "Xesto") %>%
  mutate(taxon = toupper(taxon)) %>%
  mutate(across(c(coral_length_cm, coral_width_cm), as.numeric)) %>%
  mutate(site = factor(site, levels = sort(unique(site))))

tt23 <- tt23 %>%
  mutate(max_width_cm = pmax(coral_length_cm, coral_width_cm)) %>%
  select(site, taxon, max_width_cm)

tt23 %>%
  filter(taxon == "SLAC") %>%
  print(n = nrow(.))

# Filter to only impact survey and vertical sites (exclude tire reef surveys etc)
sort(unique(tt23$site))
sort(unique(tt23_sitemd$site))
tt23 <- tt23 %>% filter(site %in% tt23_sitemd$site) %>% 
  mutate(site = factor(site, levels = unique(tt23_sitemd$site)))

# Check taxa names
sort(unique(tt23$taxon))

# Filter out unidentified taxa
tt23 <- tt23 %>%
  filter(!taxon %in% c("?", "ID-ABBREV", "NONE", "MHEARD"))

# Adjust/corrects species IDs
tt23 <- tt23 %>%
  mutate(taxon = case_when(
    taxon == "AFRAG" ~ "AFRA",
    taxon %in% c("ASP", "ASP.") ~ "AGAR",
    taxon == "MCAV?" ~ "MCAV",
    taxon == "MSP." ~ "MADR",
    taxon == "MUSSID" ~ "MUSS",
    taxon == "MYALI" ~ "MALI",
    taxon == "MYFER" ~ "MFER",
    taxon == "MYLAM" ~ "MLAM",
    taxon == "OFR" ~ "OFRA",
    taxon == "PCLI?" ~ "PCLI",
    taxon %in% c("PSP", "PSP.") ~ "PORI",
    taxon == "SSP." ~ "SIDE",
    taxon == "STOK" ~ "DSTO",
    TRUE ~ taxon
  ))
sort(unique(tt23$taxon))
tt23 %>% filter(taxon == "MFER")

# Filter out one coral with unmeasured size
tt23 %>% filter(is.na(max_width_cm))
tt23 <- tt23 %>% filter(!is.na(max_width_cm))


# Count
# Add explicit zeros for any taxon/size class missing at any site
tt23_counts <- tt23 %>%
  mutate(class = ifelse(max_width_cm >= 4, ">4cm", "<4cm")) %>%
  count(site, taxon, class) %>%
  complete(site, taxon, class = c(">4cm", "<4cm"), fill = list(n = 0)) %>%
  # Don't create zeros for MEAN/MUSS/FAVI adults, since these IDs only applied to juv
  filter(!(taxon %in% c("MEAN", "MUSS", "FAVI") & class == ">4cm" & n == 0))



# Aggregate count data based on taxonomic groups defined above
tt23_counts_ag <- tt23_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  dplyr::select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")

tt23_counts_ag %>%
  filter(taxon == "DSTO") %>%
  group_by(taxon, class) %>%
  summarize(tot = sum(n))

# Further aggregate juvenile counts to family (following DRM methods)
tt23_counts_ag2 <- tt23_counts_ag %>%
  left_join(taxon_lookup_juv, by = "taxon") %>%
  mutate(
    taxon = if_else(class == "<4cm" & !is.na(taxon_group), taxon_group, taxon)
  ) %>%
  select(-taxon_group) %>%
  group_by(site, taxon, class) %>%
  summarize(n = sum(n), .groups = "drop")
```


### 2024 DRM/Shedd Survey

```{r 2024_shedd_data}
# Site metadata
drm24_sitemd <- readxl::read_xlsx("data/2024_shedd_drm/site_metadata.xlsx") %>%
  janitor::clean_names() %>%
  mutate(site = as.character(drm_site_id)) %>%
  select(site, latitude = lat, longitude = lon) %>%
  mutate(depth = NA)



# Adult coral data from main DRM surveys
alldrm2024 <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_RawCoralDataTransect1and2_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  distinct(site, team, date, subregion)

shedddrm2024 <- alldrm2024 %>% filter(team == "Shedd Aquarium")


# Most sites were included in main DRM database for 2024 -- Import these
adultst1t2 <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_RawCoralDataTransect1and2_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  filter(subregion == "Broward-Miami", team == "Shedd Aquarium") %>%
  select(site, transect_num, species, width, height)

adultst3t4 <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_RawCoralDataTransect3and4_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  filter(subregion == "Broward-Miami", team == "Shedd Aquarium") %>%
  select(site, transect_num, species, width, height)

# 9 of our PEV sites were removed from DRM database to avoid oversaturating the ares -- Import these separately
removedt1t2 <- readxl::read_xlsx(
  "data/2024_shedd_drm/2024_DRM_Broward_RemovedSites_T1-T4_Shedd.xlsx", sheet = "Removed Sites T1-T2") %>%
  janitor::clean_names() %>%
  select(site, transect_num, species, width, height)
removedt3t4 <- readxl::read_xlsx(
  "data/2024_shedd_drm/2024_DRM_Broward_RemovedSites_T1-T4_Shedd.xlsx", sheet = "Removed Sites T3-T4") %>%
  janitor::clean_names() %>%
  select(site, transect_num, species, width, height)

# Combine all adult coral data for Shedd DRM surveys at PEV
adults0 <- bind_rows(adultst1t2, adultst3t4, removedt1t2, removedt3t4)
# Convert adult data to long format
adults_long <- adults0 %>%
  mutate(max_width_cm = pmax(width, height, na.rm = TRUE)) %>%
  mutate(max_width_cm = as.character(max_width_cm)) %>%
  mutate(site = str_remove(site, "^AA")) %>%
  select(site, transect_num, taxon = species, max_width_cm) %>%
  drop_na(taxon)     # DROPS when taxon is blank, this is when no corals >4cm were observed

# Import juvenile counts from main DRM dataset
juv <- readxl::read_xlsx("data/2024_shedd_drm/2024ANU_JuvenileCoralData_Shedd.xlsx") %>%
  janitor::clean_names() %>%
  filter(subregion == "Broward-Miami", team == "Shedd Aquarium")

# Import juvenile counts from sites that were removed from main DRM dataset
removed_juv <- readxl::read_xlsx("data/2024_shedd_drm/Shedd_removed_sites_Juveniles_2024.xlsx") %>%
  janitor::clean_names() %>%
  # Missing values in count data should be zero counts (unique to this datasheet from FWC)
  mutate(across(ends_with("_ct"), ~replace_na(., 0)))

# Combine juvenile data
juv0 <- bind_rows(juv, removed_juv) %>%
  mutate(site = str_remove(site, "^AA")) %>%
  select(site, transect_num, ends_with("ct")) %>%
  rename(MCAV = montastraea_ct, MUSS = mussinae_ct, FAVI = faviinae_ct, MEAN = meandrinidae_ct)

# Convert juvenile data to long format
juv_long <- juv0 %>%
  pivot_longer(c(MUSS, FAVI, MEAN, MCAV), names_to = "taxon", values_to = "n") %>%
  mutate(max_width_cm = "<4") %>%
  uncount(n)



# Other juvenile taxa counts from Transects 1 and 2 (DRM 'bonus data')
t1t2bonus <- read_csv("data/2024_shedd_drm/T1_T2_bonus_data.csv") %>%
  janitor::clean_names() %>%
  mutate(site = replace_na(site, "NA")) %>%    # Because one site is called "NA"
  mutate(transect_num = parse_number(transect))
t1t2juv <- t1t2bonus %>%
  select(site, transect_num, starts_with("small")) %>%
  rename_with(~ toupper(gsub("^small_", "", .x)), starts_with("small_"))
t1t2juv_long <- t1t2juv %>%
  pivot_longer(3:10, names_to = "taxon", values_to = "n") %>%
  mutate(max_width_cm = "<4") %>%
  uncount(n)
# Replace site names in t1t2 bonus data with the correct DRM site ID
penipsites <- readxl::read_xlsx("data/2024_shedd_drm/site_metadata.xlsx") %>%
  janitor::clean_names()
t1t2juv_long_updated <- t1t2juv_long %>%
  left_join(penipsites %>% select(site, drm_site_id), by = "site") %>%
  mutate(site = as.character(drm_site_id)) %>%
  select(-drm_site_id)







# Combine all data
drm24_long <- bind_rows(adults_long, juv_long, t1t2juv_long_updated) %>%
  mutate(team = "Shedd Aquarium")

# Check species names
sort(unique(drm24_long$taxon))


# COUNT based on rules
# 
# Juvenile taxa (searched for in <4cm size class only):  "MEAN", "MUSS", "FAVI"
#    → these should only ever appear in <4cm, never >4cm, and should not be zero-filled for adults.
# Other adult and juvenile taxa: "MCAV", "SSID", "SRAD", "PAST", "PPOR", "SINT", "SBOU", "AAGA", "MAUR"
#    → these can be counted in both >4cm and <4cm, but only in <4cm if juveniles were searched on that transect.
# Transect-based search rules:
# Transects 1 & 2: all adult taxa always searched, and all juvenile taxa searched
# Transects 3 & 4:
#    only subset of adult taxa searched (adult_taxa_t3t4)
#    only subset of juveniles: MEAN, MUSS, FAVI, MCAV

# Step 1: Define size classes
drm24_classed <- drm24_long %>%
  mutate(class = case_when(as.numeric(max_width_cm) >= 4 ~ ">4cm",
                           max_width_cm == "<4" ~ "<4cm"))

# Step 2: Define species sets
all_taxa <- unique(drm24_classed$taxon)
adult_taxa_t3t4 <- c("CNAT", "DSTO", "DLAB", "MMEA", "MANG", "MALI", 
                     "MFER", "MLAM", "PCLI", "PSTR")
juv_only_taxa <- c("MEAN", "MUSS", "FAVI")
juv_both_taxa <- c("MCAV", "SSID", "SRAD", "PAST", "PPOR", "SINT", "SBOU", "AAGA", "MAUR")
all_juv_taxa <- c(juv_only_taxa, juv_both_taxa)

# Step 3: Build search grid per site × transect × team
search_grid <- drm24_classed %>%
  distinct(site, team) %>%    # if multiple teams in data, remove value for team
  expand_grid(transect_num = 1:4) %>%  # creates search grid for all transects even if no corals observed (bc absent from drm24_classed)
  mutate(
    searched_taxa_class = pmap(list(transect_num, team), function(transect, team) {
      # Helper: define juv taxa allowed for this transect/team
      juv_taxa <- if (transect %in% c(1, 2)) {
        if (team == "Shedd Aquarium") {     
          all_juv_taxa
        } else {
          c(juv_only_taxa, "MCAV")
        }
      } else {
        c(juv_only_taxa, "MCAV")
      }
      
      # Adults always searched in 1 & 2, subset in 3 & 4
      adult_taxa <- if (transect %in% c(1, 2)) {
        setdiff(all_taxa, juv_only_taxa)  # exclude juv-only taxa
      } else {
        adult_taxa_t3t4
      }

      # Build grid
      bind_rows(
        expand_grid(taxon = adult_taxa, class = ">4cm"),
        expand_grid(taxon = juv_taxa, class = "<4cm")
      )
    })
  ) %>%
  unnest(searched_taxa_class)

# Step 4: Count observations
counts <- drm24_classed %>%
  group_by(site, transect_num, team, taxon, class) %>%
  summarize(n = n(), .groups = "drop")


# Step 5: Join with grid and fill in zeros where appropriate
final_counts <- search_grid %>%
  left_join(counts, by = c("site", "transect_num", "team", "taxon", "class")) %>%
  mutate(n = replace_na(n, 0))


# AGGREGATE COUNT DATA
# Aggregate taxa
drm24_counts_ag <- final_counts %>%
  left_join(taxon_lookup, by = "taxon") %>%
  mutate(taxon = coalesce(taxon_group, taxon)) %>%
  select(-taxon_group) %>%
  group_by(across(-n)) %>%
  summarize(n = sum(n), .groups = "drop")


# Modify DRM2024 dataset to code as one pseudo-transect per site, since all other datasets have only one transect per site. We need the structure to be uniform across datasets for count modeling -- cannot include random effect for site to account for multiple transects per site while all other datasets only have one transect per site, because then there's no variability associated with site and its essentially treated as a fixed effect, which we don't want. Thus, we need to aggregate across transects in the DRM 2024 dataset. But since different taxa were searched for on different numbers of transects (i.e., different total area searched) we need to do this carefully and have the appropriate total area searched for each taxon for the pseudo-transect.

# Assign uniform transect area
drm24_counts_ag <- drm24_counts_ag %>%
  mutate(transect_area_m2 = 10)

# Aggregate to pseudo-transect per site × taxon × class
drm24_counts_agg <- drm24_counts_ag %>%
  group_by(site, taxon, class) %>%
  summarise(
    n = sum(n, na.rm = TRUE),
    transect_area_m2 = sum(transect_area_m2),
    .groups = "drop"
  )


# add counts of ACER and OFAV from t3t4 bonus data
t3t4bonus <- read_csv("data/2024_shedd_drm/T3_T4_bonus_data.csv") %>%
  janitor::clean_names() %>%
  mutate(
    site = as.character(site),
    site = replace_na(site, "NA")
  )

t3t4bonus <- t3t4bonus %>% 
  left_join(penipsites %>% select(site, drm_site_id), by = "site") %>%
  mutate(site = as.character(drm_site_id)) %>%
  select(site, transect, acer, orbi = ofav) %>%
  mutate(acer = as.numeric(acer)) %>%
  pivot_longer(c(acer, orbi), names_to = "taxon", values_to = "n") %>%
  mutate(taxon = toupper(taxon), class = ">4cm") %>%
  group_by(site, taxon, class) %>%
  summarize(n = sum(n),
            transect_area_m2 = 10 * n()) %>%
  ungroup()


# add t3t4 bonus acer/ofav counts to the rest of the data
drm24_counts_combined <- bind_rows(
  drm24_counts_agg,
  t3t4bonus
) %>%
  group_by(site, taxon, class) %>%
  summarise(
    n = sum(n, na.rm = TRUE),
    transect_area_m2 = sum(transect_area_m2, na.rm = TRUE),
    .groups = "drop"
  )

## Exclude two sites that were selected specifically because of known ACER populations
drm24_counts_combined <- drm24_counts_combined %>%
  filter(!site %in% c("3096", "3094"))

# Update metadata
drm24_sitemd <- drm24_sitemd %>% filter(site %in% unique(drm24_counts_combined$site))
```

## Spatial data
### Habitat types
```{r habitat_maps, fig.width = 10, fig.height = 10}
# Load KML Polygons
polygons <- st_read("data/spatial/Habitat classifications.kml") 

# Extract Attributes from HTML Description
extract_attrs <- function(desc) {
  if (is.na(desc) || desc == "") {
    return(tibble(Habitat = NA, Type = NA, Modifier = NA, Region = NA, Type2 = NA))
  }
  html <- read_html(desc)
  rows <- xml_find_all(html, "//table//table//tr")
  keys <- rows %>% xml_find_all(".//td[1]") %>% xml_text(trim = TRUE)
  vals <- rows %>% xml_find_all(".//td[2]") %>% xml_text(trim = TRUE)
  n <- min(length(keys), length(vals))
  named_vals <- set_names(vals[1:n], keys[1:n])
  tibble(
    Habitat  = named_vals[["Habitat"]],
    Type     = named_vals[["Type"]],
    Modifier = named_vals[["Modifier"]],
    Region   = named_vals[["Region"]],
    Type2    = named_vals[["Type2"]]
  )
}

# Apply function and combine with spatial geometries
attrs <- map_dfr(polygons$Description, extract_attrs)
polygons_clean <- bind_cols(polygons %>% select(-Description), attrs)


###### GET RID OF OVERLAPPING SAND POLYGONS
# Set clean CRS and define area of interest
crs_clean <- st_crs(32617)

aoi_bbox <- st_as_sfc(st_bbox(c(xmin = -80.113, xmax = -80.078, ymin = 26.058, ymax = 26.112), crs = 4326))
aoi_bbox_utm <- st_transform(aoi_bbox, crs = crs_clean)

# Reproject and filter
polygons_proj <- st_transform(polygons_clean, crs = crs_clean)

sand_polygons <- polygons_proj %>%
  filter(Type == "Sand") %>%
  st_intersection(aoi_bbox_utm)

non_sand_polygons <- polygons_proj %>%
  filter(Type != "Sand") %>%
  st_intersection(aoi_bbox_utm)

# Clean geometries using WKT rebuild
sand_geom_clean <- st_sfc(
  lapply(st_as_text(st_geometry(sand_polygons)), function(wkt) st_as_sfc(wkt)[[1]]),
  crs = crs_clean
)

nonsand_union_clean <- st_as_sfc(st_as_text(st_union(st_geometry(non_sand_polygons))), crs = crs_clean)[[1]]

# Subtract all non-sand from sand polygons
cut_geoms <- lapply(seq_along(sand_geom_clean), function(i) {
  g <- sand_geom_clean[[i]]
  g_fixed <- st_buffer(g, 0)
  tryCatch(
    st_difference(g_fixed, nonsand_union_clean),
    error = function(e) {
      message("Skipping geometry ", i, " due to error: ", e$message)
      st_geometrycollection()
    }
  )
})

# Rebuild sand_cut sf object and drop empty geometries
sand_cut <- sand_polygons
st_geometry(sand_cut) <- st_sfc(cut_geoms, crs = crs_clean)
sand_cut <- sand_cut[!st_is_empty(sand_cut), ]

# Combine everything
combined <- bind_rows(sand_cut, non_sand_polygons)

# Reproject to WGS84 for plotting
polygons_final <- st_transform(combined, crs = 4326)

# Remove tiny polygons of Acropora cervicornis -- not really a habitat
polygons_final <- polygons_final %>%
  filter(Type != "Acropora cervicornis")
```

#### Assign survey sites to habitats
```{r}
# Combine site metadata, and assign north and south
allsitemd <- bind_rows(.id = "dataset",
  nsu11_esa = nsu11_esa_sitemd,
  dca17_esa = dca17_esa_sitemd,
  dca17 = dca17_sitemd,
  tt21 = tt21_sitemd,
  tt23 = tt23_sitemd,
  drm24 = drm24_sitemd
) %>%
  mutate(dir = if_else(latitude > 26.093570, "N", "S"))

# Get lat/lon of all sites
points <- st_as_sf(allsitemd, coords = c("longitude", "latitude"), crs = 4326)

# Validate Geometry and Match CRS
polygons_final <- polygons_final %>%
  st_zm(drop = TRUE, what = "ZM") %>%
  st_make_valid() %>%
  st_transform(st_crs(points))

sf_use_s2(FALSE)  # prevent s2 geometry issues

# Spatial Join survey sites with habitat polygons
joined <- st_join(points, polygons_final, join = st_within)

joined_df <- joined %>%
  mutate(longitude = st_coordinates(.)[,1],
         latitude = st_coordinates(.)[,2]) %>%
  st_drop_geometry()

allsitemd <- joined_df

# Add factor if survey was ESA coral species only
allsitemd <- allsitemd %>%
  mutate(ESAonly = if_else(dataset %in% c("nsu11_esa", "dca17_esa"), "ESA only", "All corals"))

# Get manual habitat Type fill colors
typecols <- RColorBrewer::brewer.pal(nlevels(factor(polygons_final$Type)) + 1, "Set3")[-1]
names(typecols) <- levels(factor(polygons_final$Type))

# # Visualize habitat classifications
polyplot <- polygons_final %>%
  ggplot() +
  geom_sf(aes(fill = Type), color = NA, size = 0.1, alpha = 0.5) +
  scale_fill_manual(values = typecols, na.value = "gray80") +
  theme_minimal(base_size = 8) +
  labs(fill = NULL, shape = NULL, x = NULL, y = NULL) +
  theme(legend.position = "right") +
  coord_sf(
    xlim = c(-80.113, -80.078),
    ylim = c(26.058, 26.112),
    expand = FALSE
  ) +
  scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +
  scale_x_continuous(breaks = seq(-80.11, -80.08, by = 0.01),
                     labels = scales::number_format(accuracy = 0.01))
```

### Impact zones
```{r}
# Impact zone Scenario 2 and NMFS consideration areas
# Define the extraction function once
extract_placemark_info <- function(kml_file, source_label) {
  ns <- c(kml = "http://www.opengis.net/kml/2.2")
  kml <- read_xml(kml_file)
  placemarks <- xml_find_all(kml, ".//kml:Placemark", ns)

  map(placemarks, function(pm) {
    name <- xml_text(xml_find_first(pm, ".//kml:name", ns))

    folder_node <- xml_parent(xml_parent(pm))
    folder_name <- xml_text(xml_find_first(folder_node, ".//kml:name", ns))
    if (is.na(folder_name) || folder_name == "") folder_name <- "Top Level"

    coord_nodes <- xml_find_all(pm, ".//kml:coordinates", ns)

    # Extract all coordinate rings
    rings <- lapply(coord_nodes, function(cn) {
      coords_text <- xml_text(cn)
      coords <- strsplit(trimws(coords_text), "\\s+")[[1]]
      coords_mat <- do.call(rbind, lapply(coords, function(x) {
        as.numeric(strsplit(x, ",")[[1]][1:2])
      }))
      if (nrow(coords_mat) >= 3) coords_mat else NULL
    })

    rings <- compact(rings)
    if (length(rings) == 0) return(NULL)

    # Group into separate polygon parts based on breaks (every outer ring followed by 0+ inner rings)
    # For now, assume all are outer rings (no holes), so wrap each as its own polygon
    multipoly <- st_multipolygon(lapply(rings, function(r) list(r)))

    tibble(
      folder = folder_name,
      name = name,
      geometry = st_sfc(multipoly, crs = 4326),
      source = source_label
    )
  }) %>%
    compact() %>%
    bind_rows() %>%
    st_as_sf()
}

# File paths
impact_kml <- "data/spatial/Impact_zones_Scenario 2.kml"
nmfs_kml <- "data/spatial/Scenario2_NMFSConsiderationAreas.kml"

# Extract and label
impact_zones_sf <- extract_placemark_info(impact_kml, "Impact Zone")
nmfs_sf <- extract_placemark_info(nmfs_kml, "NMFS Consideration Area")

# Combine
all_zones_sf <- bind_rows(impact_zones_sf, nmfs_sf)

# Rename polygons based on zone folder
all_zones_sf <- all_zones_sf %>%
  mutate(
    name = if_else(
      is.na(name) | name == "",
      str_remove(str_remove(folder, "^Scenario_2_"), "\\.shp$"),
      name
    ),
    scenario = if_else(name %in% c("North", "South", "East", "Nearshore"), "NMFS Consideration", "Scenario 2")
  )



### Create new polygon covering Rest of Monitoring Area, from 1.2 km N to 1.2 km S of the channel

# Extract the 'Channel' polygon
channel_poly <- all_zones_sf %>%
  filter(str_detect(tolower(name), "channel"))

# Transform all relevant layers to UTM (meters) for buffering
utm_crs <- 32617  # UTM Zone 17N — suitable for SE Florida

if (st_is_longlat(channel_poly)) {
  channel_poly <- st_transform(channel_poly, utm_crs)
  polygons_clean_m <- st_transform(polygons_clean, utm_crs)
  all_zones_sf_m <- st_transform(all_zones_sf, utm_crs)
} else {
  polygons_clean_m <- polygons_clean
  all_zones_sf_m <- all_zones_sf
}

# Get bounds of channel (north-south)
bbox_channel <- st_bbox(channel_poly)

# Define rectangular box: full E-W extent of reef habitat, ±1.2 km N/S of channel
ew_range <- st_bbox(polygons_clean_m)[c("xmin", "xmax")]
ns_range <- c(bbox_channel["ymin"] - 1200, bbox_channel["ymax"] + 1200)
names(ns_range) <- c("ymin", "ymax")

new_box <- st_as_sfc(st_bbox(c(
  xmin = ew_range[[1]],
  xmax = ew_range[[2]],
  ymin = ns_range[[1]],
  ymax = ns_range[[2]]
), crs = st_crs(polygons_clean_m)))

# Clip the box to reef habitat
intersected_box <- st_union(st_intersection(new_box, st_union(polygons_clean_m)))

# Subtract all existing zones (Impact + NMFS) by taking concave hull
# Create a tight, shrink-wrapped outer boundary around all existing zones
existing_zone_hull <- all_zones_sf_m %>%
  st_make_valid() %>% 
  st_union() %>%
  st_buffer(20) %>%     # Buffer OUTWARD 40 meters to close gaps
  st_union() %>%
  st_buffer(-20)        # Buffer INWARD to return to approximate original size

# Subtract existing zones from monitoring area
new_zone_geom <- st_difference(intersected_box, existing_zone_hull)

# Build the new polygon row
new_zone <- st_sf(
  folder = "Generated",
  name = "Rest of Monitoring Area",
  scenario = "Rest of Monitoring Area",
  geometry = st_sfc(new_zone_geom),
  source = "Impact Zone",
  crs = st_crs(polygons_clean_m)
)

# Transform back to match original CRS
if (st_crs(new_zone) != st_crs(all_zones_sf)) {
  new_zone <- st_transform(new_zone, st_crs(all_zones_sf))
}

# Add the new zone to the combined zones object
all_zones_sf <- bind_rows(all_zones_sf, new_zone)
zone_levels <- c("Channel", "Side Slopes", "Depth_10cm", "Depth_5cm", "Depth_1cm", "Depth_0_5cm", "Depth_0_1cm",
                 "Nearshore", "North", "East", "South", "Rest of Monitoring Area")
all_zones_sf$name <- factor(all_zones_sf$name, levels = zone_levels)



#### MERGE CONTIGUOUS POLYGONS OF SAME ZONE TYPE/NAME

# Ensure individual polygons (not MULTIPOLYGONs)
zones_split <- all_zones_sf %>%
  st_cast("POLYGON") %>%
  mutate(row_id = row_number())  # unique ID to track rows

# Group and merge contiguous polygons with the same name
zones_merged <- zones_split %>%
  group_by(name) %>%
  group_split() %>%
  map_dfr(function(df) {
    # Build adjacency graph for touching polygons
    touch_mat <- st_touches(df)
    g <- graph_from_adj_list(touch_mat)

    # Find connected components
    comps <- components(g)$membership

    # Merge by component
    df %>%
      mutate(component = comps) %>%
      group_by(name, component) %>%
      summarise(
        geometry = st_union(geometry),
        scenario = first(scenario),
        source = first(source),
        .groups = "drop"
      )
  }) %>%
  select(name, scenario, source, geometry) %>%
  st_as_sf()


#### PLOT
# Transform to UTM Zone 17N for proper distance in meters
utm_crs <- 32617
zones_utm <- st_transform(zones_merged, utm_crs)
channel_utm <- st_transform(channel_poly, utm_crs)

# Get Y coordinate of channel centroid
channel_centroid_y <- st_coordinates(st_centroid(channel_utm))[,"Y"]

# Compute distance from channel (north/south) in meters
zones_with_dist <- zones_utm %>%
  mutate(
    is_channel = name == "Channel",
    centroid = st_centroid(geometry),
    centroid_y = st_coordinates(centroid)[,"Y"],
    dist_from_channel = if_else(
      is_channel,
      0,
      abs(centroid_y - channel_centroid_y)
    )
  )

# Define a gradient color palette
distance_palette <- c(
  "#B2182B",  # deep red
  "#EF8A62",  # reddish-orange
  "#FDB863",  # orange
  "#FFFFBF"  # yellow
)

distance_palette <- c(
  "#67001F",  # very deep red/burgundy
  "#B2182B",  # strong red
  "#EF8A62",  # reddish-orange
  "#FDB863",  # orange
  "#FFFFBF"   # pale yellow
)

# Plot
p <- ggplot() +
  # Habitat polygons
  geom_sf(data = polygons_clean, aes(fill = Type),
          color = NA, size = 0.1, alpha = 0.25, show.legend = FALSE) +
  #scale_fill_brewer(palette = "Set3", na.value = "gray80") +
  scale_fill_manual(values = typecols, na.value = "white") +
  ggnewscale::new_scale_fill() +
  # Zones 
  geom_sf(data = zones_with_dist %>% filter(!is_channel),
          aes(fill = dist_from_channel), color = "black", alpha = 0.5, linewidth = 0.075) +
  geom_sf(data = zones_with_dist %>% filter(is_channel),
          fill = "#67001F", color = "black", linewidth = 0.075, alpha = 0.5) +  # Red for Channel
  scale_fill_gradientn(
    colors = distance_palette,
    name = "Distance from Channel (m)"
  ) +
  theme_minimal() +
  theme(legend.position = "none") +
  coord_sf(
    xlim = c(-80.113, -80.078),
    ylim = c(26.075, 26.11),
    expand = FALSE, clip = "off"
  ) +
  scale_y_continuous(labels = scales::number_format(accuracy = 0.001)) +
  scale_x_continuous(breaks = seq(-80.11, -80.08, by = 0.01),
                     labels = scales::number_format(accuracy = 0.01))

# Zone labels
zone_labels <- tribble(
  ~name,                   ~label_x, ~label_y,
  "Channel",               -80.085,  26.0938,
  "Side Slopes",           -80.104,  26.08,
  ">10 cm",            -80.103,  26.078,
  "5–10 cm",             -80.102,  26.076,
  "1–5 cm",             -80.101,  26.074,
  "0.5–1 cm",           -80.100,  26.072,
  "0.1–0.5 cm",           -80.099,  26.070,
  "Nearshore",             -80.106,  26.094,
  "North",                 -80.0794,  26.097,
  "East",                  -80.080, 26.0938,
  "South",                 -80.0792,  26.091,
  "Impact Monitoring Area",       -80.0815, 26.083
)

zone_segments <- tribble(
  ~name,                   ~segment_x, ~segment_y,
  "Channel",               -80.085,  26.0938,
  "Side Slopes",           -80.102,    26.0945,
  "Side Slopes",           -80.1027,    26.093,
  ">10 cm",            -80.1007,   26.0947,
  ">10 cm",            -80.1014,   26.09285,
  "5–10 cm",             -80.0995,    26.0949,
  "5–10 cm",             -80.1003,    26.0926,
  "1–5 cm",             -80.0983,   26.0957,
  "1–5 cm",             -80.0992,   26.092,
  "0.5–1 cm",           -80.097,   26.0968,
  "0.5–1 cm",           -80.0981,   26.091,
  "0.1–0.5 cm",           -80.0954,   26.098,
  "0.1–0.5 cm",           -80.097,   26.0897,
  "Nearshore",             -80.106,    26.09,
  "North",                 -80.0794,  26.097,
  "East",                  -80.080, 26.0938,
  "South",                 -80.0792,  26.091,
  "Impact Monitoring Area",       -80.0815, 26.083
)

label_segments <- zone_segments %>%
  left_join(zone_labels, by = "name")

# iz_plot <- p +
#   geom_segment(data = label_segments,
#                aes(x = segment_x, y = segment_y,
#                    xend = label_x, yend = label_y),
#                color = "black", linewidth = 0.2) +
#   geom_text(data = zone_labels,
#             aes(x = label_x, y = label_y, label = name),
#             size = 2, hjust = 1) +
#   coord_sf(
#     xlim = c(-80.113, -80.077),
#     ylim = c(26.058, 26.112),
#     expand = FALSE
#   ) +
#   labs(x = "", y = "") +
#   scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +
#   scale_x_continuous(breaks = seq(-80.11, -80.08, by = 0.01),
#                      labels = scales::number_format(accuracy = 0.01))


###### SCALE BAR
# Distances (m) for ticks
tick_offsets <- c(300, 600, 1200)

# X position for the scale bar (longitude)
x_lon <- -80.077

# Convert X-position to UTM (using midpoint latitude just for reference)
x_pos_utm <- st_transform(
  st_sfc(st_point(c(x_lon, (bbox_channel["ymin"] + bbox_channel["ymax"]) / 2 / 111320)), crs = 4326),
  32617
) %>%
  st_coordinates() %>%
  .[,"X"]

# Create tick positions in UTM
ticks_utm <- data.frame(
  x = rep(x_pos_utm, 2 * length(tick_offsets) + 2),
  y = c(
    bbox_channel["ymin"] - rev(tick_offsets),  # ticks below ymin
    bbox_channel["ymin"],                      # ymin tick
    bbox_channel["ymax"],                      # ymax tick
    bbox_channel["ymax"] + tick_offsets        # ticks above ymax
  ),
  dist_m = c(
    -rev(tick_offsets),
    0,
    0,
    tick_offsets
  )
)

# Convert tick positions to WGS84 (lat/lon)
ticks_latlon <- st_as_sf(ticks_utm, coords = c("x", "y"), crs = 32617) %>%
  st_transform(4326) %>%
  st_coordinates() %>%
  as.data.frame() %>%
  mutate(dist_m = ticks_utm$dist_m)

# Convert ymin and ymax to lat/lon for the two scale bar segments
bbox_channel_latlon <- st_as_sf(
  data.frame(
    x = rep(x_pos_utm, 2),
    y = c(bbox_channel["ymin"], bbox_channel["ymax"])
  ),
  coords = c("x", "y"),
  crs = 32617
) %>%
  st_transform(4326) %>%
  st_coordinates()

ymin_lat <- bbox_channel_latlon[1, "Y"]
ymax_lat <- bbox_channel_latlon[2, "Y"]

# Two scale bar segments: from ymin down and ymax up
scale_lines <- data.frame(
  x = c(x_lon, x_lon),
  xend = c(x_lon, x_lon),
  y = c(ymax_lat, ymin_lat),
  yend = c(max(ticks_latlon$Y), min(ticks_latlon$Y))
)

# Tick marks (short horizontal segments)
tick_length <- 0.0005
ticks_segments <- data.frame(
  x = x_lon - tick_length,
  xend = x_lon + tick_length,
  y = ticks_latlon$Y,
  yend = ticks_latlon$Y
)

# Tick labels
tick_labels <- data.frame(
  x = x_lon - 0.0004,
  y = ticks_latlon$Y,
  label = ifelse(
    ticks_latlon$dist_m == 0,
    "",
    paste0(abs(ticks_latlon$dist_m), "m")
  )
)
# 
# # Add to plot
# iz_plot +
#   geom_segment(
#     data = scale_lines,
#     aes(x = x, y = y, xend = xend, yend = yend),
#     inherit.aes = FALSE,
#     color = "black",
#     linewidth = 0.4
#   ) +
#   geom_segment(
#     data = ticks_segments,
#     aes(x = x, y = y, xend = xend, yend = yend),
#     color = "black",
#     linewidth = 0.3
#   ) +
#   geom_text(
#     data = tick_labels,
#     aes(x = x, y = y, label = label),
#     hjust = 1,
#     vjust = c(rep(1.5, 4), rep(-0.5, 4)),
#     size = 1.5
#   )
```

#### Area of habitats in impact zones
```{r}
# Make sure 'Artificial' is changed to 'Nearshore Ridge Complex' in habitat polygons, and that Aggregated Patch Reef is changed to Outer Reef
polygons_filtered <- polygons_final %>%
  mutate(Type = if_else(Type == "Artificial", "Nearshore Ridge Complex", Type)) %>%
  mutate(Type = if_else(Type == "Aggregated Patch Reef", "Outer Reef", Type)) %>%
  filter(Type %in% type_levels)

# Clean any invalid geometry
polygons_filtered <- st_make_valid(polygons_filtered)
all_zones_sf <- st_make_valid(all_zones_sf)
# Intersect with habitat polygons
habitat_in_zones <- st_intersection(polygons_filtered, all_zones_sf)

# Project for accurate area
habitat_in_zones_proj <- habitat_in_zones %>%
  st_transform(32617) %>%
  mutate(area_m2 = st_area(geometry))

# Summarize area by habitat type and zone name
area_summary <- habitat_in_zones_proj %>%
  st_drop_geometry() %>%
  mutate(name = factor(name, levels = zone_levels),
         Type = factor(Type, levels = type_levels)) %>%
  group_by(Type, name) %>%
  summarize(total_area_m2 = sum(as.numeric(area_m2)), .groups = "drop") %>%
  arrange(name)

# Print total area of each habitat in each impact zone
area_summary %>% 
  pivot_wider(names_from = name, values_from = total_area_m2, names_sort = FALSE)

# Combine for full Scenario2+NMFS, and Rest of Monitoring Area
area_summary2 <- habitat_in_zones_proj %>%
  st_drop_geometry() %>%
  mutate(Type = factor(Type, levels = type_levels)) %>%
  group_by(Type, scenario) %>%
  summarize(total_area_m2 = sum(as.numeric(area_m2)), .groups = "drop")

area_summary2 %>% 
  pivot_wider(names_from = scenario, values_from = total_area_m2)


area_summary_acres <- area_summary %>%
  pivot_wider(
    names_from = Type,
    values_from = total_area_m2,
    names_glue = "{Type}_m2",
    values_fill = 0
  ) %>%
  # Create acres columns from m² columns
  mutate(across(
    ends_with("_m2"),
    ~ .x / 4046.86,
    .names = "{sub('_m2$', '_acres', .col)}"
  )) %>%
  # Round m² columns to the nearest m²
  mutate(across(ends_with("_m2"), ~ round(.x, 0))) %>%
  # Round acres columns to 3 decimal places
  mutate(across(ends_with("_acres"), ~ round(.x, 3)))

write_csv(area_summary_acres, file = "outputs/TableA1.csv")

area_summary_acres
```

# Combine and filter data

## Combine surveys datasets
```{r combine_data}
# Combine all aggregated count data
df <- bind_rows(.id = "dataset",
  nsu11_esa = nsu11_esa_counts_ag,
  dca17_esa = dca17_esa_counts_ag_full,
  dca17 = dca17_counts_ag,
  tt21 = tt21_counts_ag,
  tt23 = tt23_counts_ag2,
  drm24 = drm24_counts_combined     # use data aggregated to 1 pseudo-transect - already has transect_area_m2
)

# Justify decision to class all NSU observations (ACER/DSTO/ORBI) as >4cm
df %>%
  filter(taxon %in% c("ORBI", "ACER", "DSTO"), dataset != "nsu11_esa") %>%
  group_by(taxon, class) %>%
  summarize(tot = sum(n))
### In all other datasets, percent of all observed colonies that were >4cm:
### ACER: 3629 / (3629 + 12) = 99.7%
### DSTO: 169 (100%) but these were already switched to MEAN
### ORBI: 70/(70+4) = 94.6%
```

## Filter out rare taxa
```{r}
# Filter out taxa with very few observations
# Drop taxa with very few observations
sppcounts <- df %>%
  group_by(taxon) %>%
  summarize(total = sum(n), .groups = "drop") %>%
  arrange(total) 
sppcounts 

df <- df %>%
  filter(taxon %in% filter(sppcounts, total >= 5)$taxon)
# Taxa with less than 5 total observations were filtered out, which included: FFRA, HCUC, PAME, SCOL, OCUL


# Ensure explicit zeros are included for all taxa searched for but not observed (e.g., ACER never recorded in TT23 dataset)
# Step 1: Get taxon:class combos from the full df (i.e., all combos ever observed anywhere)
taxon_class_combos <- df %>%
  distinct(taxon, class)

# Step 2: Split df into those to complete vs those to leave untouched
df_base <- df %>% filter(dataset %in% c("nsu11_esa", "dca17_esa"))
df_to_complete <- df %>% filter(!dataset %in% c("nsu11_esa", "dca17_esa"))

# Step 3: Get all site × dataset combinations to complete
site_info <- df_to_complete %>%
  distinct(dataset, site)

# Step 4: Create full grid for these datasets only
full_grid <- site_info %>%
  tidyr::crossing(taxon_class_combos)

# Step 5: Join and fill in zeros
df_completed_part <- full_grid %>%
  left_join(df_to_complete, by = c("dataset", "site", "taxon", "class")) %>%
  mutate(n = coalesce(n, 0)) %>%
  select(dataset, site, taxon, class, n)

# Step 6: Combine with the untouched ESA datasets
df_completed <- bind_rows(df_base, df_completed_part)


# Add transect area information
## Bring back in DRM24 dataset taxon:class-specific transect areas searched
df_completed <- df_completed %>% 
  left_join(distinct(drm24_counts_combined, taxon, class, transect_area_m2) %>%
              mutate(dataset = "drm24"), 
            by = c("dataset", "taxon", "class")) %>%
  select(-transect_area_m2.x, transect_area_m2 = transect_area_m2.y)

## ACER and ORBI <4cm didn't get assigned areas because were never observed -- these would have been searched in 20 m2 (T1 and T2)
df_completed %>% filter(is.na(transect_area_m2), dataset == "drm24") %>%
  distinct(taxon, class)
df_completed <- df_completed %>%
  mutate(transect_area_m2 = case_when(
    dataset == "drm24" & is.na(transect_area_m2) ~ 20,
    TRUE ~ transect_area_m2
  ))



## Add transect area information for other datasets
## TT21: Site-specific areas for tt21 (since there was sand in transects)
# (Adjust if needed) define which taxa are ESA in your dataset
esa_taxa <- c("ACER", "ORBI")  # update to your ESA list
df_completed <- df_completed %>%
  mutate(is_esa = taxon %in% esa_taxa)

# Prepare tt21 area lookups
tt21_areas <- tt21_m_nosand %>%
  mutate(dataset = "tt21") %>%
  distinct(dataset, site, transect_area_m2 = area_m2) %>%
  rename(transect_area_m2_non_esa = transect_area_m2)

tt21_esa_areas <- tt21_esa_sitemd %>%
  mutate(dataset = "tt21") %>%
  rename(transect_area_m2_esa = area)

# Join both area lookups (tt21 only) and set area conditionally
df_completed <- df_completed %>%
  left_join(tt21_areas,    by = c("dataset", "site")) %>%
  left_join(tt21_esa_areas, by = c("dataset", "site")) %>%
  mutate(
    transect_area_m2 = dplyr::case_when(
      dataset == "tt21" & is_esa  ~ dplyr::coalesce(transect_area_m2_esa, transect_area_m2),
      dataset == "tt21" & !is_esa ~ dplyr::coalesce(transect_area_m2_non_esa, transect_area_m2),
      TRUE                        ~ transect_area_m2
    )
  ) %>%
  select(-transect_area_m2_non_esa, -transect_area_m2_esa, -is_esa)

# # check if worked
# df_completed %>% 
#   filter(dataset == "tt21", taxon %in% c("ACER", "ORBI", "SIDE")) %>% arrange(site, taxon)


## Other datasets had fixed transect areas
df_completed <- df_completed %>%
  mutate(transect_area_m2 = case_when(
    dataset == "nsu11_esa" ~ 3600,
    dataset == "dca17_esa" ~ 784,
    dataset == "dca17" ~ 30,     # DCA belt transects were 30m
    dataset == "tt23" & site %in% tt23v_sitemd$site ~ 10,  # vertical wall sites
    dataset == "tt23" ~ 20,                                # all other tt23 sites
    TRUE ~ transect_area_m2))
```

## Filter by habitat

```{r select_habitats, fig.width = 10, fig.height = 10}
allsitemd %>% count(Type)

# Select sites in Nearshore Ridge Complex, Inner Reef, and Middle Reef, Outer Reef and Aggregated Patch Reef
selected <- allsitemd %>%
  filter(Type %in% c("Nearshore Ridge Complex", "Inner Reef", "Middle Reef", 
                     "Artificial", "Outer Reef", "Aggregated Patch Reef"))

# Which sites were excluded?
excluded <- anti_join(allsitemd, selected) 

excluded %>%
  count(dataset, Type)


# Filter dataset to just selected sites
dff0 <- df_completed %>% inner_join(selected)
dff <- df_completed %>% inner_join(selected)
```

Shedd dataset has some sites in the NRC south that are further from the channel relative to other datasets. Are these similar enough to the NRC south sites that are closer to the channel that they can be reasonably included?

First, look at total coral density between the nearer vs. farther sites

```{r NRCS_density}
drm24_NRCS <- drm24_counts_ag %>%
  left_join(allsitemd) %>%
  filter(Type == "Nearshore Ridge Complex", dir == "S")

drm24_NRCS <- drm24_NRCS %>%
  mutate(grp = if_else(latitude > 26.08, "near", "far"))

# Fit a Negative Binomial GLM
mod_nb <- MASS::glm.nb(n ~ grp, data = drm24_NRCS)

# Generate prediction grid for far/near sites
newdata_1 <- drm24_NRCS %>%
  distinct(grp)

# Get predicted values & standard errors (log scale)
preds_nb <- predict(mod_nb, newdata_1, type = "link", se.fit = TRUE)

# Compute total coral density 
results_nb <- newdata_1 %>%
  mutate(
    fit = exp(preds_nb$fit),                    # Convert fitted values to response scale
    fit_se = exp(preds_nb$fit) * preds_nb$se.fit,   # Convert SE using the Delta Method
    fit_var = (fit * preds_nb$se.fit)^2,         # Variance propagation
    fit_lower = exp(preds_nb$fit - 1.96 * preds_nb$se.fit),  # Lower CI
    fit_upper = exp(preds_nb$fit + 1.96 * preds_nb$se.fit)   # Upper CI
  )

# Compute total coral density + confidence intervals
total_ci_nb <- results_nb %>%
  group_by(grp) %>%
  summarize(
    total_density = sum(fit),
    total_se = sqrt(sum(fit_var)),
    lower_95CI = exp(log(total_density) - 1.96 * (total_se / total_density)),
    upper_95CI = exp(log(total_density) + 1.96 * (total_se / total_density))
  )

knitr::kable(total_ci_nb)
```

Next, look at community composition between the nearer vs. farther sites
```{r NRCS_community_composition}
# Create a wide community matrix: rows = site x grp, columns = taxa
comm_matrix <- drm24_NRCS %>%
  group_by(site, grp, taxon) %>%
  summarize(total_n = sum(n), .groups = "drop") %>%
  pivot_wider(names_from = taxon, values_from = total_n, values_fill = 0)

# Extract community matrix and metadata
comm_data <- comm_matrix %>% select(-site, -grp)
site_info <- comm_matrix %>% select(site, grp)

# Run NMDS
set.seed(123) 
nmds <- metaMDS(comm_data, distance = "bray", k = 2, trymax = 100)

# Prepare data for plotting
scores_df <- scores(nmds)$sites %>%
  bind_cols(site_info)

# Plot NMDS
ggplot(scores_df, aes(x = NMDS1, y = NMDS2, color = grp)) +
  geom_point(size = 3, alpha = 0.8) +
  theme_minimal() +
  labs(title = "NMDS of Coral Community Structure\nby Dist from Channel in NRC South",
       color = "Dist from channel")
```

Density and community composition are not different in the NRC S sites that are nearer vs. farther from the channel. So, no need to exclude the farther sites.

DCA dataset has the most sites in the "Artificial" habitat classification. (Some in other datasets too, but DCA has most). Can 'Artificial' be aggregated with 'Nearshore Ridge Complex'?

'Artificial' is only present in DCA and minorly in TT -- but absent from Shedd.   
It is in close spatial proximity to Nearshore Ridge Complex -- can these be combined?

Test for differences in coral density in DCA survey between habitat types
```{r artificial_vs_nrc_density}
# Subset DCA data
dcadf <- dca17_counts_ag %>%
  left_join(allsitemd)

# Fit a Negative Binomial GLM
mod_nb <- MASS::glm.nb(n ~ Type, data = dcadf)

# Generate new data only for existing habitats
newdata_1 <- dcadf %>%
  distinct(Type)

# Get predicted values & standard errors (log scale)
preds_nb <- predict(mod_nb, newdata_1, type = "link", se.fit = TRUE)

# Compute total coral density per habitat
results_nb <- newdata_1 %>%
  mutate(
    fit = exp(preds_nb$fit),                    # Convert fitted values to response scale
    fit_se = exp(preds_nb$fit) * preds_nb$se.fit,   # Convert SE using the Delta Method
    fit_var = (fit * preds_nb$se.fit)^2,         # Variance propagation
    fit_lower = exp(preds_nb$fit - 1.96 * preds_nb$se.fit),  # Lower CI
    fit_upper = exp(preds_nb$fit + 1.96 * preds_nb$se.fit)   # Upper CI
  )

# Compute total coral density + confidence intervals
total_ci_nb <- results_nb %>%
  group_by(Type) %>%
  summarize(
    total_density = sum(fit),
    total_se = sqrt(sum(fit_var)),
    lower_95CI = exp(log(total_density) - 1.96 * (total_se / total_density)),
    upper_95CI = exp(log(total_density) + 1.96 * (total_se / total_density))
  )

knitr::kable(total_ci_nb)
```
Highly overlapping confidence intervals for Artifical and Nearshore Ridge Complex, so no difference in coral density.

Test for differences in community composition in DCA survey
```{r artificial_vs_nrc_nmds}
# Create a wide community matrix: rows = site x Type, columns = taxa
comm_matrix <- dcadf %>%
  group_by(site, Type, taxon) %>%
  summarize(total_n = sum(n), .groups = "drop") %>%
  pivot_wider(names_from = taxon, values_from = total_n, values_fill = 0)

# Extract community matrix and metadata
comm_data <- comm_matrix %>% select(-site, -Type)
site_info <- comm_matrix %>% select(site, Type)

# Run NMDS
set.seed(123)
nmds <- metaMDS(comm_data, distance = "bray", k = 2, trymax = 100)

# Prepare data for plotting
scores_df <- scores(nmds)$sites %>%
  bind_cols(site_info)

# Plot NMDS
ggplot(scores_df, aes(x = NMDS1, y = NMDS2, color = Type)) +
  geom_point(size = 3, alpha = 0.8) +
  theme_minimal() +
  labs(title = "NMDS of Coral Community Structure by Habitat Type",
       color = "Habitat Type")
```

High degree of similarity between Artificial and Nearshore Ridge Complex coral communities.

Combine 'Artificial' with 'Nearshore Ridge Complex'
```{r combine_artificial_nrc}
# Based on these results, combine "Artificial" with "Nearshore Ridge Complex"
dff[dff$Type == "Artificial", "Type"] <- "Nearshore Ridge Complex"
```


Combine 'Aggregated Patch Reef' with 'Outer Reef', following previous studies (DCA)
```{r}
dff[dff$Type == "Aggregated Patch Reef", "Type"] <- "Outer Reef"

dff <- dff %>% mutate(Type = factor(Type, levels = type_levels))
```

Remove ACER (zeros) from tt23 dataset
```{r}
dstax <- dff %>%
  filter(!dataset %in% c("nsu11_esa", "dca17_esa")) %>%
  filter(n > 0) %>%
  distinct(dataset, taxon)

dstax %>%
  count(dataset) %>%
  print(n = nrow(.))

dstax %>%
  count(taxon)

# CNAT not observed in TT21 (super rare)
# ACER not observed in TT23 (known habitat distribution was NOT SURVEYED)

## remove ACER from tt23 dff
dff <- dff %>%
  filter(!(taxon == "ACER" & dataset == "tt23"))
```



# Summarize combined dataset
```{r}
# Count number of sites per habitat
nsites <- dff %>%
  group_by(dataset, Type) %>%
  summarize(n = n_distinct(site)) %>%
  mutate(Type = factor(Type, levels = type_levels)) %>%
  arrange(Type) %>%
  pivot_wider(names_from = Type, values_from = n, values_fill = 0) %>%
  janitor::adorn_totals(where = "col", name = "Total Sites")

# Get area surveyed per transect and total area surveyed
area_per_site <- dff %>%
  group_by(dataset) %>%
  summarise(
    area_per_site = {
      r <- range(transect_area_m2)
      if (r[1] == r[2]) as.character(r[1]) else paste(r, collapse = " — ")})

total_area <- dff %>%
  group_by(dataset, site) %>%
  summarize(max_area = max(transect_area_m2)) %>%
  summarize(total_area = round(sum(max_area), 0))

# Get total number of corals counted
total_corals <- dff %>%
  group_by(dataset) %>%
  summarize(total_n = sum(n))

survey_summary <- reduce(
  list(nsites, area_per_site, total_area, total_corals),
  full_join,
  by = "dataset"
) %>%
  mutate(dataset = factor(dataset, levels = dataset_levels)) %>%
  arrange(dataset) %>% 
  janitor::adorn_totals(where = "row") %>%
  mutate(dataset2 = c(dataset_labels, "Total"))

write_csv(survey_summary, file = "outputs/Table1.csv")

survey_summary %>% knitr::kable()




# Summarize count data
# Just get columns we need for modeling
dfftaxon <- dff %>% select(dataset, Type, dir, site, transect_area_m2, taxon, class, n)
write_csv(dfftaxon, file = "data/processed/all_coral_counts_processed.csv")

# Number of observations/counts
nrow(dfftaxon)

# Number of colonies counted
sum(dfftaxon$n)

# Number of taxa observed
n_distinct(dfftaxon$taxon)

# Number of sites surveyed
n_distinct(interaction(dfftaxon$dataset, dfftaxon$site))



# Zero-inflation / Number of zeros
table(dfftaxon$n == 0)

# Overdispersion
mean_count <- mean(dfftaxon$n)
var_count <- var(dfftaxon$n)
var_count / mean_count

# Data are highly zero-inflated and overdispersed -- use zero-inflated negative binomial models. 
```

# Map surveys & impact zones
```{r}
# High-resolution SE Florida coastline with GSHHG (no counties), plus ports & study box
# ------------------------------------------------------------------------------------
# Install if needed:
# install.packages(c("sf","dplyr","ggplot2"))
# (No special geofabrik/overpass/hires packages required)

library(sf)
library(dplyr)
library(ggplot2)

# 1) Define your exact view bbox (SE Florida)
bbox_view <- st_bbox(c(
  xmin = -80.4, ymin = 25.60,
  xmax = -79.85, ymax = 26.50
), crs = st_crs(4326))

# Slight pad for safety when cropping
pad <- 0.05
bbox_pad <- bbox_view
bbox_pad["xmin"] <- bbox_view["xmin"] - pad
bbox_pad["ymin"] <- bbox_view["ymin"] - pad
bbox_pad["xmax"] <- bbox_view["xmax"] + pad
bbox_pad["ymax"] <- bbox_view["ymax"] + pad

# 2) Download GSHHG high-resolution shapefiles (once) and read coast polygons
#    (URL version may update; if it 404s, search "gshhg shapefile download")
gshhg_url <- "https://www.ngdc.noaa.gov/mgg/shorelines/data/gshhg/latest/gshhg-shp-2.3.7.zip"
td <- tempdir()
zipfile <- file.path(td, "gshhg.zip")
if (!file.exists(zipfile)) utils::download.file(gshhg_url, zipfile, mode = "wb")
unz_dir <- file.path(td, "gshhg")
if (!dir.exists(unz_dir)) unzip(zipfile, exdir = unz_dir)

# High-res coastline polygons (level 1 = coastlines; 'h' = high resolution)
# Path inside the zip: GSHHS_shp/h/GSHHS_h_L1.shp
gshhg_coast <- st_read(file.path(unz_dir, "GSHHS_shp", "f", "GSHHS_f_L1.shp"), quiet = TRUE) |>
  st_transform(4326)

# 3) Crop to your SE Florida view and convert to outlines (boundaries)
# 3) Validate, crop with s2 off, then take boundaries
bbox_pad_sfc <- st_as_sfc(bbox_pad)

# save current s2 setting and turn it off just for the clip
old_s2 <- sf::sf_use_s2()
sf::sf_use_s2(FALSE)
on.exit(sf::sf_use_s2(old_s2), add = TRUE)

# fix invalid rings, then clip to bbox
gshhg_valid <- sf::st_make_valid(gshhg_coast)
coast_crop  <- suppressWarnings(st_intersection(gshhg_valid, bbox_pad_sfc))

# optional: keep only polygons (in case multiparts/lines slipped in)
coast_crop  <- st_collection_extract(coast_crop, "POLYGON")

coast_line <- st_boundary(coast_crop)  # draw only the outline (crisp line map)

# 4) Annotations: ports + your detailed study box
ports <- tibble::tibble(
  name = c("Port Everglades", "Port of Miami"),
  lon  = c(-80.118, -80.133),
  lat  = c(26.090, 25.770)
)
cities <- tibble::tibble(
  name = c("Miami", "Fort Lauderdale"),
  lon = c(-80.1918, -80.1373),
  lat = c(25.7617, 26.1224)
)

study_box <- st_as_sfc(st_bbox(
  c(xmin = -80.1116, xmax = -80.078, ymin = 26.058, ymax = 26.112),
  crs = 4326
))

# 5) Plot: ultra-clean coastline outline + study box + ports
p_sef_gshhg <- ggplot() +
  geom_sf(data = coast_crop, fill = "gray90", color = "black", linewidth = 0.1) +
  geom_sf(data = study_box, fill = NA, color = "#D7301F", linewidth = 0.9) +
  geom_text_repel(data = ports, aes(lon, lat, label = name), hjust = 0, size = 2, nudge_y = -0.06,
                  xlim = c(-80.05, NA), segment.size = 0.2) +
  geom_point(data = cities, aes(lon, lat), size = 1) +
  geom_text(data = cities, aes(lon, lat, label = name), hjust = 1, vjust = 0, size = 2, nudge_x = -0.01) +
  coord_sf(xlim = c(bbox_view["xmin"], bbox_view["xmax"]),
           ylim = c(bbox_view["ymin"], bbox_view["ymax"]),
           expand = FALSE) +
  theme_void()

p_sef_gshhg



# KJ Coral Reef ECA
kj_eca <- st_read("data/spatial/KJ_Coral_Aquatic_Preserve.gpkg", quiet = TRUE)

# Add to your existing map (choose fill/line to taste)
p_sef_map <- p_sef_gshhg +   # or p_sef_gshhg / p_sef_hi, etc.
  geom_sf(data = kj_eca, fill = NA, color = "#4B6CB7", linewidth = 0.6) +
  # or with a subtle transparent fill:
  # geom_sf(data = kj_eca, fill = scales::alpha("#4B6CB7", 0.08), color = "#4B6CB7", linewidth = 0.4)
    coord_sf(xlim = c(bbox_view["xmin"], bbox_view["xmax"]),
           ylim = c(bbox_view["ymin"], bbox_view["ymax"]),
           expand = FALSE) +
  annotate("text", x = -80.05, y = 25.9, label = "Kristin Jacobs\nCoral Reef Ecosystem\nConservation Area",
           color = "#4B6CB7", hjust = 0, size = 2)

#p_sef_map



#####
library(rnaturalearth)
library(rnaturalearthdata)

# 1) Get a simple USA states outline
usa_states <- ne_states(country = "United States of America", returnclass = "sf")
fl_outline <- usa_states %>% filter(name == "Florida")

# 2) Define a Florida-wide bbox for inset
fl_bbox <- st_bbox(c(
  xmin = -87.8, ymin = 24.0,
  xmax = -79.5, ymax = 31.0
), crs = st_crs(4326))
fl_bbox_sfc <- st_as_sfc(fl_bbox)

# 3) Build inset plot with simple Florida outline + red box for SE FL extent
p_inset_simple <- ggplot() +
  geom_sf(data = fl_outline, fill = "grey92", color = "black", linewidth = 0.1) +
  geom_sf(data = st_as_sfc(bbox_view), fill = NA, color = "#D7301F", linewidth = 0.6) +
  coord_sf(xlim = c(fl_bbox["xmin"], fl_bbox["xmax"]),
           ylim = c(fl_bbox["ymin"], fl_bbox["ymax"]),
           expand = FALSE) +
  theme_void() +
  theme(
    panel.border = element_rect(color = "black", fill = NA, linewidth = 0.25), # <-- border
    panel.background = element_rect(color = "black", fill = "white", linewidth = 0) # <-- border
  )

# 4) Add inset to your detailed SE Florida map
p_final_with_inset <- p_sef_map +
  theme(plot.margin = margin(0,-10,0,0)) +
  # theme(
  #   plot.background = element_rect(
  #     color = "black",   # border color
  #     fill  = "white",   # background fill
  #     linewidth = 1      # thickness of the border
  #   )
  # ) +
  inset_element(p_inset_simple,
                left = 0.05, bottom = 0.6, right = 0.5, top = 1.1,
                align_to = "panel")

p_final_with_inset
```


```{r plot_maps, fig.width = 10, fig.height = 10}
# Define shared coordinate limits
coord_limits <- coord_sf(
  xlim = c(-80.1116, -80.078),
  ylim = c(26.058, 26.112),
  expand = FALSE#, clip = "off"#,
  #datum = NA  # avoid graticule
)

# Simplified base theme for clean layout
base_theme <- theme_minimal(base_size = 8) +
  theme(
    axis.title = element_blank(),
    axis.text = element_blank(),
    #axis.ticks = element_blank(),
    panel.grid = element_blank(),
    plot.margin = margin(t = 12, r = 5, b = 5, l = 5),
  )

# Reorder survey datasets
selected <- selected %>% mutate(dataset = factor(dataset, levels = c("nsu11_esa", "dca17_esa", "dca17", "tt21", "tt23", "drm24")))









# Left panel: faceted survey locations
pp2 <- ggplot(polygons_final) +
  # LAND background (from NOAA GSHHG)
  #geom_sf(data = land_zoom, fill = "grey90", color = "grey65", linewidth = 0.15) +

  geom_sf(aes(fill = Type), color = NA, size = 0.1, alpha = 0.5) +
  geom_point(
    data = selected,
    aes(x = longitude, y = latitude),
    pch = 4, alpha = 0.6, size = 0.65, stroke = 0.3, inherit.aes = FALSE
  ) +
  #scale_fill_brewer(palette = "Set3", na.value = "gray80") +
  scale_fill_manual(values = typecols, na.value = "gray80") +
  facet_wrap(~ dataset, ncol = 3,
               labeller = as_labeller(c(
    "nsu11_esa" = "2011 – NSU ESA Survey",
    "dca17_esa" = "2017 – DCA ESA Survey",
    "dca17"     = "2017 – DCA Recon Survey",
    "tt21"      = "2021 – Tetra Tech Survey",
    "tt23"      = "2023 – Tetra Tech Survey",
    "drm24"     = "2024 – Shedd Survey"
  ))) +
  coord_limits +
  scale_x_continuous(breaks = c(-80.11, -80.10, -80.09, -80.08)) +
  labs(title = NULL, fill = NULL) +
  base_theme +
  theme(
    legend.position = "none",
    strip.text = element_text(size = 6),
    panel.spacing = unit(0.5, "lines"),
    plot.margin = margin(2,0,0,-10)
  )

# Right panel: impact zones
iz_plot_clean <- p +
  geom_segment(data = label_segments,
               aes(x = segment_x, y = segment_y,
                   xend = label_x, yend = label_y),
               color = "black", linewidth = 0.2) +
  geom_text(data = zone_labels,
            aes(x = label_x, y = label_y, label = name),
            size = 2, hjust = 1) +
  coord_sf(xlim = c(-80.1116, -80.077), ylim = c(26.058, 26.112), expand = FALSE) +
  base_theme +
  theme(legend.position = "none") +
  geom_segment(
    data = scale_lines,
    aes(x = x, y = y, xend = xend, yend = yend),
    inherit.aes = FALSE,
    color = "black",
    linewidth = 0.4
  ) +
  geom_segment(
    data = ticks_segments,
    aes(x = x, y = y, xend = xend, yend = yend),
    color = "black",
    linewidth = 0.3
  ) +
  geom_text(
    data = tick_labels,
    aes(x = x, y = y, label = label),
    hjust = 1,
    vjust = c(rep(1.5, 4), rep(-0.5, 4)),
    size = 1.5
  ) +
  theme(plot.margin = margin(0,0,0,0))

# # Set y tick positions and labels manually
# y_breaks <- c(26.06, 26.07, 26.08, 26.11)  # adjust to match your plot extent
# x_right_label <- -80.08  # just outside your xlim max
# 
# right_axis_labels <- tibble(
#   x = x_right_label,
#   y = y_breaks,
#   label = scales::number(y_breaks, accuracy = 0.01)
# )
# 
# x_breaks <- c(-80.09, -80.10, -80.11)
# y_bottom_label <- 26.06 
# bottom_axis_labels <- tibble(x = x_breaks, y = y_bottom_label,
#                              label = scales::number(x_breaks, accuracy = 0.01))

# iz_plot_clean <- iz_plot_clean + 
#   geom_text(data = right_axis_labels,
#             aes(x = x, y = y, label = label),
#             size = 2, hjust = 1, vjust = 0, fontface = "italic", color = "gray") +
#   geom_text(data = bottom_axis_labels,
#             aes(x = x, y = y, label = label),
#             size = 2, hjust = 0, vjust = 1, fontface = "italic", color = "gray")



# Combine with cowplot
final_fig <- plot_grid(
  p_final_with_inset, 
  pp2,
  iz_plot_clean,
  nrow = 1,
  align = "hv",
  axis = "tb",
  labels = c("A", "B", "C"), hjust = 0, label_size = 11,
  rel_widths = c(0.24, 0.36, 0.24)  # adjust until panel areas are visually aligned
)
final_fig


# Extract fill legend from habitat polygon plot
legend_plot <- polyplot +
  scale_fill_manual(values = typecols, na.value = "gray80") +
  guides(shape = "none", color = "none", fill = guide_legend(nrow = 2)) +
  base_theme +
  theme(
    legend.position = "bottom",
    legend.key.size = unit(0.3, "cm"),  # Reduce square size
    legend.text = element_text(size = 6),  # Optional: smaller legend text
    legend.title = element_text(size = 7)  # Optional: smaller legend title
  )
grob <- ggplotGrob(legend_plot)
fill_legend <- gtable::gtable_filter(grob, "guide-box")

bottom_row <- plot_grid(NULL, fill_legend, ncol = 2, rel_widths = c(0.2, 0.6))
final_final_fig <- plot_grid(final_fig, bottom_row, ncol = 1, rel_heights = c(0.92, 0.08))

# Save output
ggsave(
  filename = "outputs/Fig1.png",
  plot = final_final_fig,
  width = 220,
  height = 125,
  units = "mm",
  dpi = 300,
  bg = "white"
)

```








# Statistical modeling 

## Generate data-informed priors
```{r}
# Generate some data-informed priors to use in ZINB models

# Filter for valid, non-zero counts for count model summaries
df_pos <- dfftaxon %>%
  filter(n > 0) %>%
  mutate(density = n / transect_area_m2,
         log_density = log(density))

# PRIOR FOR INTERCEPT (count model log mean density, class = "Intercept")
summary_log_density <- summary(df_pos$log_density)
summary_log_density
# Output: 
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # -8.189  -3.401  -2.708  -2.781  -1.609   2.046 

# Prior choice:
# Center at ~mean or median (e.g., -2.8 ≈ exp(-2.8) ≈ 0.06/m²)
# SD wide enough to cover most observed log densities
# => normal(-2.8, 1.8)
# This covers ~log densities from -6.5 to 1.5 => densities from ~0.0015 to ~4.5

# PRIOR FOR FIXED EFFECTS (class = "b")
group_effects <- df_pos %>%
  group_by(taxon, class, Type) %>%
  summarize(mean_log_density = mean(log_density), .groups = "drop")

sd_group_effects <- sd(group_effects$mean_log_density)
sd_group_effects
summary(group_effects$mean_log_density)

# Prior choice:
# Effects likely centered near 0 (mean difference from Intercept)
# Use a bit wider SD to regularize: normal(0, 2.0)

# PRIOR FOR ZERO-INFLATION (logit of zero probability)
zi_est <- dfftaxon %>%
  group_by(taxon, class, Type) %>%
  summarize(p_zero = mean(n == 0), .groups = "drop") %>%
  mutate(logit_p_zero = qlogis(pmin(pmax(p_zero, 1e-4), 1 - 1e-4)))

mean_logit_zi <- mean(zi_est$logit_p_zero)
sd_logit_zi <- sd(zi_est$logit_p_zero)
# Prior choice:
# Centered at mean with reasonable spread => normal(1.5, 2.5)

# PRIOR FOR SHAPE PARAMETER (dispersion)
vmr_summary <- dfftaxon %>%
  mutate(dens = n / transect_area_m2) %>%
  group_by(taxon, class, Type) %>%
  filter(sum(dens > 0, na.rm = TRUE) > 5) %>%     # filter for well-observed taxa for prior estimation
  mutate(
    dens_min = min(dens[dens > 0], na.rm = TRUE),  # min nonzero density
    pseudo_n = round(dens / dens_min)
  ) %>%
  summarize(
    mean_n = mean(pseudo_n),
    var_n  = var(pseudo_n),
    .groups = "drop"
  ) %>%
  mutate(
    vmr      = var_n / mean_n,
    phi_est  = ifelse(vmr > 1, mean_n / (vmr - 1), NA_real_),
    log_phi  = log(phi_est)
  )

# Summary
summary(vmr_summary$log_phi)
sd(vmr_summary$log_phi, na.rm = TRUE)

# Prior choice:
# normal(-0.9, 1)
```

## Fit model
```{r}
# mod_nb3.7 <- brm(
#   bf(
#     n ~ taxon:class * Type +
#       (1 + Type | dataset) +                     # temporal/dataset intercept, varies by habitat
#       (1 | dataset:taxon:class) +                       # taxon-specific dataset offsets
#       (1 | taxon:class:Type:dir) +               # taxon × class × Type × dir (shared geography)
#       offset(log(transect_area_m2)),
#     zi ~ taxon:class * Type,
#     shape ~ taxon:class * Type
#   ),
#   data = dfftaxon,
#   family = zero_inflated_negbinomial(),
#   prior = c(
#     # Effects on log density (taxon:class * Type)
#     prior(normal(0, 2), class = "b"),
#     # Centered on global mean log-density
#     prior(normal(-2.8, 1.8), class = "Intercept"),
#     # Informed by logit(p_zero) distribution
#     prior(normal(1.5, 2.5), class = "b", dpar = "zi"),
#     # Matches empirical shape estimates
#     prior(normal(-0.9, 1), class = "b", dpar = "shape"),
#     # Regularize random effects to prevent overfitting (important for PPP)
#     prior(exponential(4), class = "sd")     # shrinks dataset/site/dir SDs toward 0 if not supported
#   ),
#   chains = 4, cores = 4, threads = threading(5),
#   iter = 6000, warmup = 3000, thin = 1,
#   backend = "cmdstanr",
#   control = list(adapt_delta = 0.99),
#   seed = 20240717
# )
# saveRDS(mod_nb3.7, file = "data/processed/mod_nb3.7.rds")
mod_nb3.7 <- readRDS("data/processed/mod_nb3.7.rds")
```


## Model evaluation

```{r, eval = F}
# Convergence check
#summary(mod_nb3.7)  # confirm Rhat ≈ 1.00, no divergences

# R²
bayes_R2(mod_nb3.7)
```

### Posterior predictive checks

#### Global PPP
```{r, eval = F}

# GLOBAL POSTERIOR PREDICTIVE PLOTS ------------------------------------
# Extract observed data and predicted draws
area <- mod_nb3.7$data$transect_area_m2

y <- mod_nb3.7$data$n / area
set.seed(124)
yrep  <- posterior_predict(mod_nb3.7, ndraws = 1000)
yrep <- sweep(yrep, 2, area, FUN = "/")
set.seed(124)
mu    <- posterior_epred(mod_nb3.7, ndraws = 1000)  # matrix: draws x observations
mu   <- sweep(mu,   2, area, FUN = "/")




# Example discrepancy statistics
discrepancy_stats <- list(
  mean        = apply(yrep, 1, mean),
  variance    = apply(yrep, 1, var),
  zero_prop   = apply(yrep, 1, function(x) mean(x == 0)),
  skewness    = apply(yrep, 1, function(x) moments::skewness(x)),
  chi_squared = map_dbl(1:nrow(yrep), ~ {
    mu_row <- mu[.x, ]
    yrep_row <- yrep[.x, ]
    valid <- mu_row > 0
    sum((yrep_row[valid] - mu_row[valid])^2 / mu_row[valid])
  })
)

# Observed statistics
T_obs <- list(
  mean        = mean(y),
  variance    = var(y),
  zero_prop   = mean(y == 0),
  skewness    = moments::skewness(y),
  chi_squared = {
    mu_mean <- colMeans(mu)
    valid <- mu_mean > 0
    sum((y[valid] - mu_mean[valid])^2 / mu_mean[valid])
  }
)

# Compute PPP values
ppp_vals <- map2_dbl(discrepancy_stats, T_obs, ~ mean(.x >= .y))
ppp_vals

# Assemble plots
stat_names <- names(discrepancy_stats)

plot_list <- map(stat_names, function(stat) {
  df <- tibble(T_rep = discrepancy_stats[[stat]])
  ggplot(df, aes(x = T_rep)) +
    geom_histogram(bins = 50, fill = "gray80", color = "black") +
    geom_vline(xintercept = T_obs[[stat]], color = "red", linetype = "dashed", linewidth = 1) +
    labs(
      title = glue::glue("{stat} (PPP = {round(ppp_vals[stat], 3)})"),
      x = "Replicated Statistic",
      y = "Frequency"
    ) +
    theme_minimal()
})

# Display in grid
plot_grid(plotlist = plot_list, ncol = 1)
```

#### Grouped PPP
```{r, eval = F}
# GROUPED POSTERIOR PREDICTIVE PLOTS ------------------------------------

# Create taxon_class column
dfftaxon <- dfftaxon %>%
  mutate(taxon_class = paste(taxon, class, sep = "_"))

# Draw predicted counts
ppreds <- add_predicted_draws(mod_nb3.7, newdata = dfftaxon, ndraws = 1000) %>%
  mutate(.prediction = .prediction / transect_area_m2)    # CONVERT TO DENSITY

# Summarize predicted statistics by taxon_class and draw
pp_stats <- ppreds %>%
  group_by(taxon_class, Type, .draw) %>%
  summarize(
    mean_pred = mean(.prediction),
    sd_pred = sd(.prediction),
    p_zero_pred = mean(.prediction == 0),
    skew_pred = e1071::skewness(.prediction),
    .groups = "drop"
  )

# Summarize observed statistics
obs_stats <- dfftaxon %>%
  mutate(n = n / transect_area_m2) %>%     # convert to density
  group_by(taxon_class, Type) %>%
  summarize(
    mean_obs = mean(n),
    sd_obs = sd(n),
    p_zero_obs = mean(n == 0),
    skew_obs = e1071::skewness(n),
    .groups = "drop"
  )

# Plot function
plot_stat2 <- function(stat_name, stat_label) {
  ggplot(pp_stats, aes_string(x = "Type", y = paste0(stat_name, "_pred"))) +
    stat_halfeye(fill = "orange", alpha = 0.6) +
    facet_wrap(~taxon_class, scales = "free_y") +
    geom_point(data = obs_stats, aes_string(y = paste0(stat_name, "_obs")), color = "red", size = 1) +
    labs(
      y = stat_label,
      x = "Taxon and size class",
      title = paste("Observed vs predicted", tolower(stat_label), "by taxon:class")
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
}


# Generate plots
plot_stat2("mean", "Mean") 
plot_stat2("sd", "Standard Deviation")
plot_stat2("p_zero", "Proportion Zeros")
plot_stat2("skew", "Skewness")



### grouped ppps

# Compute PPP per stat per group
compute_ppp <- function(pred_col, obs_col) {
  pp_stats %>%
    select(taxon_class, Type, .draw, !!sym(pred_col)) %>%
    left_join(
      obs_stats %>%
        select(taxon_class, Type, obs = !!sym(obs_col)),
      by = c("taxon_class", "Type")
    ) %>%
    group_by(taxon_class, Type) %>%
    summarize(
      ppp = mean(!!sym(pred_col) >= obs),
      .groups = "drop"
    ) %>%
    mutate(statistic = obs_col)
}

ppp_mean <- compute_ppp("mean_pred", "mean_obs")
ppp_sd <- compute_ppp("sd_pred", "sd_obs")
ppp_zero <- compute_ppp("p_zero_pred", "p_zero_obs")
ppp_skew <- compute_ppp("skew_pred", "skew_obs")

# Combine
ppp_summary_grouped <- bind_rows(ppp_mean, ppp_sd, ppp_zero, ppp_skew) 

# Compare observed to predicted values for taxon-class-habitat groups that were actually observed
observed_combos <- dfftaxon %>% filter(n > 0) %>% distinct(taxon, class, Type) %>%
  mutate(taxon_class = paste(taxon, class, sep = "_"))

ppp_summary_grouped_obs <- ppp_summary_grouped %>%
  semi_join(observed_combos, by = c("taxon_class", "Type"))

ppp_summary_grouped_obs_ext <- ppp_summary_grouped_obs %>%
  filter(ppp < 0.05 | ppp > 0.95) %>%
  pivot_wider(names_from = statistic, values_from = ppp)

ppp_summary_grouped_obs_ex
nrow(ppp_summary_grouped_obs)
```


### Final density estimates

#### Datasets equal-weighted

```{r}
# Equal weighting datasets

# Create newdata for prediction — dataset level only (site & dir not needed)
newdata <- dfftaxon %>% 
  distinct(dataset, taxon, class, Type) %>%
  mutate(transect_area_m2 = 1)

# Get predictions from the model
# - Dataset RE included
# - Dir RE marginalized out
preds <- add_epred_draws(
  mod_nb3.7,
  newdata = newdata,
  re_formula = ~(1 + Type | dataset) + (1 | dataset:taxon:class)
)

# Equal-weight datasets so no dataset dominates
draws_equal_weighted <- preds %>%
  group_by(.draw, taxon, class, Type) %>%
  summarize(n_m2 = mean(.epred), .groups = "drop")

# Summarize posterior draws
summary_equal_weighted_new <- draws_equal_weighted %>%
  group_by(taxon, class, Type) %>%
  mean_qi(n_m2, .width = 0.95)


draws_equal_weighted_combined <- preds %>%
  group_by(.draw, taxon, dataset, Type, class) %>%
  summarize(n_m2 = mean(.epred), .groups = "drop") %>%
  
  # Average across datasets for each class
  group_by(.draw, taxon, class, Type) %>%
  summarize(n_m2 = mean(n_m2), .groups = "drop") %>%
  
  # Compute "All" after averaging across datasets
  group_by(.draw, taxon, Type) %>%
  mutate(total_n_m2 = sum(n_m2[class != "All"])) %>%
  ungroup() %>%
  pivot_longer(
    cols = c("n_m2", "total_n_m2"),
    names_to = "class_source",
    values_to = "n_m2"
  ) %>%
  mutate(class = ifelse(class_source == "total_n_m2", "All", class)) %>%
  select(-class_source) %>%
  
  # Remove redundant "All" for single-class taxa
  group_by(taxon) %>%
  mutate(n_classes = n_distinct(class[class != "All"])) %>%
  ungroup() %>%
  filter(class != "All" | n_classes > 1) %>%
  select(-n_classes)



summary_equal_weighted_combined <- draws_equal_weighted_combined %>%
  group_by(taxon, class, Type) %>%
  mean_qi(n_m2, .width = 0.95)


# Set taxon order for plotting
# Order taxa by overall abundance for plotting
taxorder <- summary_equal_weighted_combined %>%
  group_by(taxon) %>%
  mutate(
    n_classes = n_distinct(class[class != "All"])
  ) %>%
  ungroup() %>%
  filter((n_classes > 1 & class == "All") | (n_classes == 1 & class != "All")) %>%
  group_by(taxon) %>%
  summarize(maxdens = max(n_m2), .groups = "drop") %>%
  mutate(taxon = fct_reorder(taxon, -maxdens))

summary_equal_weighted_combined <- summary_equal_weighted_combined %>%
  mutate(taxon = factor(taxon, levels = levels(taxorder$taxon)),
         class = factor(class, levels = c("<4cm", "All", ">4cm")))
```

#### 2024-specific estimates
```{r}
newdata_drm24 <- dfftaxon %>%
  distinct(taxon, class, Type) %>% 
  mutate(transect_area_m2 = 1)  %>%
  complete(Type = unique(dfftaxon$Type),  # add all habitat Types
           fill = list(transect_area_m2 = 1)) %>%
  mutate(dataset = "drm24")

preds_drm24 <- add_epred_draws(
  mod_nb3.7,
  newdata = newdata_drm24,
  re_formula = ~(1 + Type | dataset) + (1 | dataset:taxon:class)
)

summary_drm24 <- preds_drm24 %>%
  group_by(taxon, class, Type) %>%
  mean_qi(.epred, .width = 0.95) %>%
  rename(n_m2 = .epred)

draws_drm24_combined <- preds_drm24 %>%
  group_by(.draw, taxon, class, Type) %>%
  summarize(n_m2 = mean(.epred), .groups = "drop") %>%

  # Compute "All" class
  group_by(.draw, taxon, Type) %>%
  mutate(total_n_m2 = sum(n_m2[class != "All"])) %>%
  ungroup() %>%
  pivot_longer(
    cols = c("n_m2", "total_n_m2"),
    names_to = "class_source",
    values_to = "n_m2"
  ) %>%
  mutate(class = ifelse(class_source == "total_n_m2", "All", class)) %>%
  select(-class_source) %>%

  # Remove redundant "All" for single-class taxa
  group_by(taxon) %>%
  mutate(n_classes = n_distinct(class[class != "All"])) %>%
  ungroup() %>%
  filter(class != "All" | n_classes > 1) %>%
  select(-n_classes)

summary_drm24_combined <- draws_drm24_combined %>%
  group_by(taxon, class, Type) %>%
  mean_qi(n_m2, .width = 0.95)


summary_drm24_combined <- summary_drm24_combined %>%
  mutate(taxon = factor(taxon, levels = levels(taxorder$taxon)),
         class = factor(class, levels = c("<4cm", "All", ">4cm")))

```

# Results

## Densities

### Taxon densities
```{r, fig.width = 10, fig.height = 10}
##### Function to plot densities of all taxon:class:habitat combinations with provided data frame

make_taxon_density_plot <- function(densities, output_path, width, height) {
  
  # Create base plot
  taxdens <- ggplot(densities, aes(x = Type, y = n_m2, color = class)) +
    geom_errorbar(aes(ymin = .lower, ymax = .upper), width = 0, linewidth = 0.4,
                  position = position_dodge(width = 0.2), alpha = 0.6) +
    geom_line(aes(group = class), position = position_dodge(width = 0.2)) +
    geom_point(size = 1.5, alpha = 0.6, position = position_dodge(width = 0.2)) +
    facet_wrap(~taxon, labeller = labeller(taxon = as_labeller(taxon_labels, label_parsed)),
               scales = "free_y", ncol = 4) +
    scale_x_discrete(labels = type_labels) +
    scale_color_manual(
      values = c("<4cm" = "#d95f02", ">4cm" = "#1b9e77", "All" = "#7570b3"),
      labels = c("<4cm", "≥4cm", "All"),
      breaks = c("<4cm", ">4cm", "All")
    ) +
    labs(
      x = "Habitat Type",
      y = bquote("Density (colonies m"^-2*")"),
      color = "Size class"
    ) +
    theme_minimal()
  
  # Generate taxon group annotations
  taxon_group_df <- bind_rows(lapply(names(taxon_groups_juv), function(group) {
    tibble(taxon = taxon_groups_juv[[group]], group = group)
  })) %>%
    filter(taxon != group)
  
  annotation_df <- densities %>%
    distinct(taxon) %>%
    left_join(taxon_group_df, by = "taxon") %>%
    filter(!is.na(group)) %>%
    mutate(
      group2 = case_when(
        group == "FAVI" ~ "Faviinae",
        group == "MUSS" ~ "Mussinae",
        group == "MEAN" ~ "Meandrinidae",
        TRUE ~ group
      ),
      taxon = factor(taxon, levels = taxorder$taxon),
      label = paste0("<4cm = ", group2),
      x = 2.5,
      y = Inf
    )
  
  # Final figure with annotations
  fig <- taxdens +
    geom_text(data = annotation_df, aes(x = x, y = y, label = label),
              inherit.aes = FALSE, hjust = 0.5, size = 2.5, color = "#d95f02") +
    theme(
      panel.background = element_rect(fill = "white", color = NA),
      plot.background = element_rect(fill = "white", color = NA),
      legend.position = "bottom",
      legend.key.width = unit(2, "lines"),
      legend.margin = margin(t = -5, b = 0)
    ) +
    coord_cartesian(clip = "off") +
    scale_y_continuous(limits = c(0, NA))
  
  # Save and return the plot
  ggsave(filename = output_path, plot = fig, 
         width = width, height = height, 
         units = "mm", dpi = 300)
  return(fig)
}


# Create plot for dataset-averaged densities
make_taxon_density_plot(densities = summary_equal_weighted_combined, 
                        output_path = "outputs/Fig2.png",
                        width = 170, height = 170)

# Create plot for current/2024 densities
make_taxon_density_plot(densities = summary_drm24_combined, 
                        output_path = "outputs/FigA2.png",
                        width = 170, height = 170)



#### TABLE version

make_taxon_density_table <- function(densities, output_path) {
  
  # Set display order
  type_order <- unique(densities$Type)  # preserves appearance order
  class_order <- c("<4cm", ">4cm", "All")
  taxon_levels <- taxorder$taxon  # assumed available
  
  # Format and reshape
  table_out <- densities %>%
    mutate(
      taxon = factor(taxon, levels = taxon_levels),
      class = factor(class, levels = class_order),
      Type = factor(Type, levels = type_order),
      mean_ci = sprintf(
        "%s [%s–%s]",  # en-dash
        formatC(n_m2, format = "fg", digits = 2, flag = "#"),
        formatC(.lower, format = "fg", digits = 2, flag = "#"),
        formatC(.upper, format = "fg", digits = 2, flag = "#")
      )
    ) %>%
    select(taxon, class, Type, mean_ci) %>%
    pivot_wider(names_from = Type, values_from = mean_ci) %>%
    arrange(taxon, class)
  
  # Save to CSV
  write_csv(table_out, file = output_path)
  
  return(table_out)
}

# Create table for dataset-averaged densities
make_taxon_density_table(densities = summary_equal_weighted_combined, 
                         output_path = "outputs/TableA2.csv")

# Create table for current/2024 densities
make_taxon_density_table(densities = summary_drm24_combined, 
                         output_path = "outputs/TableA3.csv")
```

### Raw vs. modeled taxon densities

```{r}
# Average density per dataset-taxon-class-Type group
raw_density_summary <- dfftaxon %>%
  mutate(density = n / transect_area_m2) %>%
  group_by(dataset, taxon, class, Type) %>%
  summarize(
    raw_density_mean = mean(density, na.rm = TRUE),
    raw_density_sd   = sd(density, na.rm = TRUE),
    raw_density_n    = n(),
    .groups = "drop"
  ) %>%
  mutate(
    raw_density_se = raw_density_sd / sqrt(raw_density_n),
    t_crit = qt(0.975, df = raw_density_n - 1),
    raw_density_lower = pmax(0, raw_density_mean - t_crit * raw_density_se),
    raw_density_upper = raw_density_mean + t_crit * raw_density_se
  )

all <- raw_density_summary %>% left_join(summary_equal_weighted_combined) %>%
  mutate(taxon_class = paste(taxon, class))

all_long <- all %>%
  select(dataset, taxon, class, Type, raw_density_mean, raw_density_lower, raw_density_upper,
         n_m2, .lower, .upper, taxon_class) %>%
  pivot_longer(
    cols = c(raw_density_mean, n_m2),
    names_to = "source",
    values_to = "density"
  ) %>%
  mutate(
    lower = ifelse(source == "raw_density_mean", raw_density_lower, .lower),
    upper = ifelse(source == "raw_density_mean", raw_density_upper, .upper),
    source = ifelse(source == "raw_density_mean", dataset, "modeled")
  )

raw_vs_mod <- ggplot(all_long, aes(x = Type, y = density)) +
  geom_point(
    aes(shape = source, color = source),
    size = 2,
    position = position_dodge(width = 0.75),
    alpha = 0.5
  ) +
  geom_errorbar(
    aes(ymin = lower, ymax = upper, color = source),
    position = position_dodge(width = 0.75),
    width = 0,
    alpha = 0.5
  ) +
  facet_wrap(~ taxon_class, scales = "free", ncol = 5) +
  scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, 0))) +
  coord_cartesian(clip = "off") +
  scale_x_discrete(labels = c("NRC", "IR", "MR", "OR")) +
  scale_color_manual(
    name = "",
    values = c(
      "nsu11_esa" = "#1b9e77",
      "dca17_esa" = "#d95f02",
      "dca17"     = "#7570b3",
      "tt21"      = "#e7298a",
      "tt23"      = "#66a61e",
      "drm24"     = "#e6ab02",
      "modeled"   = "black"
    ),
    breaks = c("nsu11_esa", "dca17_esa", "dca17", "tt21", "tt23", "drm24", "modeled"),
    labels = c(
      "nsu11_esa" = "2011 – NSU ESA Survey",
      "dca17_esa" = "2017 – DCA ESA Survey",
      "dca17"     = "2017 – DCA Recon Survey",
      "tt21"      = "2021 – Tetra Tech Survey",
      "tt23"      = "2023 – Tetra Tech Survey",
      "drm24"     = "2024 – Shedd Survey",
      "modeled"   = "Modeled density"
    )
  ) +
  scale_shape_manual(
    name = "",
    values = c(
      "nsu11_esa" = 15,
      "dca17_esa" = 16,
      "dca17"     = 17,
      "tt21"      = 18,
      "tt23"      = 3,
      "drm24"     = 4,
      "modeled"   = 5
    ),
    breaks = c("nsu11_esa", "dca17_esa", "dca17", "tt21", "tt23", "drm24", "modeled"),
    labels = c(
      "nsu11_esa" = "2011 – NSU ESA Survey",
      "dca17_esa" = "2017 – DCA ESA Survey",
      "dca17"     = "2017 – DCA Recon Survey",
      "tt21"      = "2021 – Tetra Tech Survey",
      "tt23"      = "2023 – Tetra Tech Survey",
      "drm24"     = "2024 – Shedd Survey",
      "modeled"   = "Modeled density"
    )
  ) +
  guides(
    color = guide_legend(order = 1),
    shape = guide_legend(order = 1)
  )


figA1 <- raw_vs_mod + theme_minimal() +
  theme_minimal() +
  theme(
    legend.position = "bottom", 
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA),
    panel.grid = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, linewidth = 0.2),
    axis.ticks = element_line(color = "black", linewidth = 0.2),
    axis.ticks.length = unit(2, "pt"),
    axis.line = element_blank() # keep ticks but don't draw duplicate axis lines
  )

ggsave(filename = "outputs/FigA1.png", width = 190, height = 250, units = "mm")
```

### Total densities by size and SCTLD-susceptibility

```{r}
make_combined_density_figure <- function(draws, table = FALSE,
                                         output_path,
                                         y_limits = c(0, 2.8)) {
  draws <- draws %>% filter(class != "All")
  type_order <- unique(draws$Type)
  y_breaks <- seq(y_limits[1], y_limits[2] - 0.3, 0.5)
  y_minor_breaks <- seq(y_limits[1], y_limits[2] - 0.05, 0.25)
  
  # -- Total density summary --
  summary_total <- draws %>%
    group_by(.draw, Type) %>%
    summarize(total_density = sum(n_m2), .groups = "drop") %>%
    group_by(Type) %>%
    summarize(
      mean = mean(total_density),
      lower = quantile(total_density, 0.025),
      upper = quantile(total_density, 0.975),
      .groups = "drop"
    )
  
  plot_total <- ggplot(summary_total, aes(x = Type, y = mean)) +
    geom_col(fill = "#7570b3") +
    geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2, linewidth = 0.25) +
    scale_x_discrete(labels = type_labels2) +
    scale_y_continuous(
      limits = y_limits,
      breaks = y_breaks,
      minor_breaks = y_minor_breaks,
      expand = expansion(mult = c(0.02, 0))
    ) +
    labs(
      x = "Habitat Type",
      y = bquote("Density (colonies m"^-2*")")
    ) +
    theme_minimal(base_size = 8) +
    theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5),
      panel.background = element_rect(fill = "white", color = NA),
      plot.background = element_rect(fill = "white", color = NA)
    )
  
  # -- Size class summary --
  summary_class <- draws %>%
    group_by(.draw, Type, class) %>%
    summarize(total_epred = sum(n_m2), .groups = "drop") %>%
    group_by(Type, class) %>%
    mean_qi(total_epred, .width = 0.95) %>%
    mutate(
      class = factor(class, levels = c("<4cm", ">4cm")),
      label = sprintf("%.2f", total_epred)
    )
  
  plot_class <- ggplot(summary_class, aes(x = Type, y = total_epred, fill = class)) +
    geom_col(position = position_dodge(width = 0.8), width = 0.8) +
    geom_errorbar(aes(ymin = .lower, ymax = .upper),
                  position = position_dodge(width = 0.8), width = 0.2, linewidth = 0.25) +
    scale_fill_manual(values = c(">4cm" = "#1b9e77", "<4cm" = "#d95f02")) +
    scale_x_discrete(labels = type_labels2) +
    scale_y_continuous(
      limits = y_limits,
      breaks = y_breaks,
      minor_breaks = y_minor_breaks,
      expand = expansion(mult = c(0.02, 0))
    ) +
    labs(
      x = "Habitat Type",
      y = "",
      fill = "Size Class"
    ) +
    theme_minimal(base_size = 8) +
    theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5),
      legend.key.size = unit(4, "mm"),
      legend.background = element_rect(fill = "white", color = "black", linewidth = 0.25),
      legend.position = c(0.75, 0.85),
      panel.background = element_rect(fill = "white", color = NA),
      plot.background = element_rect(fill = "white", color = NA)
    )
  
  # -- SCTLD susceptibility summary --
  summary_sus <- draws %>%
    left_join(group_definitions, by = "taxon") %>%
    group_by(.draw, Type, sus_group) %>%
    summarize(total_epred = sum(n_m2), .groups = "drop") %>%
    group_by(Type, sus_group) %>%
    mean_qi(total_epred, .width = 0.95) %>%
    mutate(
      taxon_group = factor(sus_group, levels = c("high_sus", "mod_sus", "low_sus")),
      label = sprintf("%.2f", total_epred)
    )
  
  plot_sus <- ggplot(summary_sus, aes(x = Type, y = total_epred, fill = sus_group)) +
    geom_col(position = position_dodge(width = 0.8), width = 0.8) +
    geom_errorbar(aes(ymin = .lower, ymax = .upper),
                  position = position_dodge(width = 0.8), width = 0.2, linewidth = 0.25) +
    scale_fill_manual(
      values = c(
        "high_sus" = darken("#7570b3", 0.5),
        "mod_sus"  = "#7570b3",
        "low_sus"  = lighten("#7570b3", 0.5)
      ),
      labels = c(
        "high_sus" = "High",
        "mod_sus"  = "Moderate",
        "low_sus"  = "Low"
      )
    ) +
    scale_x_discrete(labels = type_labels2) +
    scale_y_continuous(
      limits = y_limits,
      breaks = y_breaks,
      minor_breaks = y_minor_breaks,
      expand = expansion(mult = c(0.02, 0))
    ) +
    labs(
      x = "Habitat Type",
      y = "",
      fill = "SCTLD\nSusceptibility"
    ) +
    theme_minimal(base_size = 8) +
    theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5),
      legend.key.size = unit(4, "mm"),
      legend.background = element_rect(fill = "white", color = "black", linewidth = 0.25),
      legend.position = c(0.75, 0.85),
      panel.background = element_rect(fill = "white", color = NA),
      plot.background = element_rect(fill = "white", color = NA)
    )
  
  # -- Combine all panels --
  combined_plot <- cowplot::plot_grid(
    plot_total, plot_class, plot_sus,
    ncol = 3,
    labels = c("A", "B", "C"),
    label_size = 10,
    align = "hv"
  )
  
  if (table == FALSE) {
    ggsave(filename = output_path, plot = combined_plot, width = 180, height = 80, units = "mm", dpi = 300)
    return(combined_plot)
  } else {
    return(list(summary_sus, summary_class, summary_total))
  }
}

make_combined_density_figure(draws = draws_equal_weighted,
                             output_path = "outputs/Fig3.png")
make_combined_density_figure(draws = draws_equal_weighted, table = TRUE)

make_combined_density_figure(draws = draws_drm24_combined,
                             y_limits = c(0, 5.2),
                             output_path = "outputs/FigA3.png")



# Size class overall averages
post_summ <- draws_equal_weighted %>%
  group_by(.draw, Type, class) %>%
  summarise(total_epred = sum(n_m2), .groups = "drop") %>%
  group_by(.draw, class) %>%
  summarise(avg_total_epred = mean(total_epred), .groups = "drop") %>%
  group_by(class) %>%
  summarise(
    mean = mean(avg_total_epred),
    sd_post = sd(avg_total_epred),          # posterior SD of the mean
    # optional: 95% CrI if you still want it for comparison
    lower = quantile(avg_total_epred, 0.025),
    upper = quantile(avg_total_epred, 0.975),
    n_draws = dplyr::n()
  )
post_summ


```

## Temporal trends

```{r}
# Prediction grid
newdata <- dfftaxon %>%     
  distinct(dataset, Type, taxon, class) %>%
  mutate(transect_area_m2 = 1) %>%
  #### Add missing habitat Type (Outer Reef) for drm24 dataset (will be imputed)
  group_by(dataset, taxon, class) %>%
  complete(Type = unique(dfftaxon$Type),  # add all habitat Types
           fill = list(transect_area_m2 = 1)) %>%
  ungroup()

# Predictions (same as before)
preds <- add_epred_draws(
  mod_nb3.7,
  ndraws = 2000,
  newdata = newdata,
  re_formula = ~(1 + Type | dataset) + (1 | dataset:taxon:class)
)

# Average across habitat types per draw
preds_avg <- preds %>%
  group_by(.draw, dataset, taxon, class) %>%
  summarize(mean_epred = mean(.epred), .groups = "drop") %>%
  mutate(year = parse_number(as.character(dataset)))

# Helper function for slopes + modeled changes
compute_trends <- function(data, group_vars, value_col) {
  data %>%
    filter(year >= 17) %>%
    group_by(across(all_of(group_vars)), .draw) %>%
    summarise(
      fit = list(lm(reformulate("year", value_col))),
      .groups = "drop"
    ) %>%
    mutate(
      intercept  = map_dbl(fit, ~ coef(.x)[1]),
      slope      = map_dbl(fit, ~ coef(.x)[2]),
      pred_17    = intercept + slope * 17,
      pred_24    = intercept + slope * 24,
      abs_change = pred_24 - pred_17,
      pct_change = ifelse(pred_17 > 0, (pred_24 - pred_17) / pred_17 * 100, NA_real_)
    ) %>%
    select(-fit)
}

# Taxon × class
trends_taxon_class <- compute_trends(preds_avg, c("taxon", "class"), "mean_epred")

trends_taxon_class_preds <- trends_taxon_class %>%
  crossing(year = 17:24) %>%                     # add year range
  mutate(pred_density = intercept + slope * year) %>%
  group_by(taxon, class, year) %>%
  mean_qi(pred_density, .width = 0.95) 

# Taxon totals
trends_taxon <- preds_avg %>%
  group_by(taxon) %>%
  filter(n_distinct(class) > 1) %>%   # keep only taxa with multiple size classes
  ungroup() %>%
  group_by(.draw, dataset, taxon, year) %>%
  summarise(total_epred = sum(mean_epred), .groups = "drop") %>%
  compute_trends(c("taxon"), "total_epred") %>%
  mutate(class = "All")

trends_taxon_preds <- trends_taxon %>%
  crossing(year = 17:24) %>%                     # add year range
  mutate(pred_density = intercept + slope * year) %>%
  group_by(taxon, year) %>%
  mean_qi(pred_density, .width = 0.95) %>%
  mutate(class = "All")

# All corals (overall)
trends_all_totals <- preds_avg %>%
  # Totals cannot be derived from the ESA-only surveys
  filter(dataset %in% c("dca17", "tt21", "tt23", "drm24")) %>%
  group_by(.draw, dataset, year) %>%
  summarise(total_epred = sum(mean_epred), .groups = "drop") %>%
  compute_trends(character(0), "total_epred") %>%
  mutate(taxon = "All", class = "All")

# All corals by size class
trends_all_by_class <- preds_avg %>%
  # Totals cannot be derived from the ESA-only surveys
  filter(dataset %in% c("dca17", "tt21", "tt23", "drm24")) %>%
  group_by(.draw, dataset, year, class) %>%
  summarise(total_epred = sum(mean_epred), .groups = "drop") %>%
  compute_trends("class", "total_epred") %>%
  mutate(taxon = "All")

# Combine
trends_all <- bind_rows(trends_all_totals, trends_all_by_class)

trends_all_preds <- trends_all %>%
  crossing(year = 17:24) %>%                     # add year range
  mutate(pred_density = intercept + slope * year) %>%
  group_by(class, year) %>%
  mean_qi(pred_density, .width = 0.95) %>%
  mutate(taxon = "All")

# Combine results
trends_combined <- bind_rows(
  trends_taxon_class %>% mutate(level = "taxon_class"),
  trends_taxon %>% mutate(level = "taxon"),
  trends_all %>% mutate(level = "all")
)

preds_combined <- bind_rows(
  trends_taxon_class_preds %>% mutate(level = "taxon_class"),
  trends_taxon_preds %>% mutate(level = "taxon"),
  trends_all_preds %>% mutate(level = "all")
)

# Summarize posterior distributions
trends_summary <- trends_combined %>%
  group_by(level, taxon, class) %>%
  mean_qi(slope, abs_change, pct_change, .width = 0.95, na.rm = TRUE) %>%
  as_tibble()

# Identify significant changes (interval not overlapping zero)
preds_combined <- preds_combined %>%
  left_join(
    trends_summary %>%
      mutate(sig_trend = sign(slope.lower) == sign(slope.upper)) %>%
      select(taxon, class, sig_trend),
    by = c("taxon", "class")
  )

preds_combined <- preds_combined %>%
  mutate(taxon = factor(taxon, levels = levels(trends_summary_subset$taxon)))

trends_summary <- trends_summary %>%
  mutate(taxon = factor(taxon, levels = levels(trends_summary_subset$taxon)))





# Taxon × class summary
summary_taxon_class <- preds_avg %>%
  group_by(dataset, taxon, class) %>%
  mean_qi(mean_epred, .width = 0.95) %>%
  mutate(level = "taxon_class")

# Taxon totals (sum over classes)
summary_taxon <- preds_avg %>%
  group_by(taxon) %>%
  filter(n_distinct(class) > 1) %>%   # keep only taxa with multiple size classes
  ungroup() %>%
  group_by(.draw, dataset, taxon) %>%
  summarise(mean_epred = sum(mean_epred), .groups = "drop") %>%
  group_by(dataset, taxon) %>%
  mean_qi(mean_epred, .width = 0.95) %>%
  mutate(class = "All", level = "taxon")

# All corals combined (sum over taxa and classes)
summary_all <- preds_avg %>%
  # Totals cannot be derived from the ESA-only surveys
  filter(dataset %in% c("dca17", "tt21", "tt23", "drm24")) %>%
  group_by(.draw, dataset) %>%
  summarise(mean_epred = sum(mean_epred), .groups = "drop") %>%
  group_by(dataset) %>%
  mean_qi(mean_epred, .width = 0.95) %>%
  mutate(taxon = "All", class = "All", level = "all")

# All corals combined by size class (sum over taxa)
summary_all_by_class <- preds_avg %>%
  # Totals cannot be derived from the ESA-only surveys
  filter(dataset %in% c("dca17", "tt21", "tt23", "drm24")) %>%
  group_by(.draw, dataset, class) %>%
  summarise(mean_epred = sum(mean_epred), .groups = "drop") %>%
  group_by(dataset, class) %>%
  mean_qi(mean_epred, .width = 0.95) %>%
  mutate(taxon = "All", level = "all_by_class")

# Combine all summaries
summary_datasets <- bind_rows(
  summary_taxon_class,
  summary_taxon,
  summary_all,
  summary_all_by_class
) %>%
  mutate(year = parse_number(dataset)) %>%
  mutate(taxon = factor(taxon, levels = levels(trends_summary_subset$taxon)))


trends_summary <- trends_summary %>%
  group_by(taxon) %>%
  mutate(
    y_max = max(summary_datasets$.upper[summary_datasets$taxon == unique(taxon)], na.rm = TRUE),
    n_classes = n_distinct(class),
    y_label = case_when(
      n_classes == 1 ~ y_max * 1.02,  # single class at top
      n_classes == 2 & class %in% c("All", ">4cm") ~ y_max * 1.02,  # top position for first
      n_classes == 2 & class == "<4cm" ~ y_max * 0.87,              # middle position for second
      n_classes == 3 & class == "All" ~ y_max * 1.02,
      n_classes == 3 & class == ">4cm" ~ y_max * 0.87,
      n_classes == 3 & class == "<4cm" ~ y_max * 0.72,
      TRUE ~ y_max * 1.02  # fallback
    ),
    sig_trend = sign(slope.lower) == sign(slope.upper),
    abs_change
  ) %>%
  ungroup()


# trends_summary %>% filter(taxon == "PSTR")
# trends_summary %>% filter(taxon == "MYCE")
# trends_summary %>% select(taxon, class, abs_change, pct_change) %>%
#   filter(taxon %in% c("PORI", "SIDE", "MCAV"))
# trends_summary %>% select(taxon, class, abs_change, pct_change) %>%
#   filter(taxon %in% c("SOLE", "AGAR"))
# trends_summary %>% select(taxon, class, abs_change, pct_change) %>%
#   filter(taxon %in% c("MMEA", "EFAS", "ORBI"))
# trends_summary %>% select(taxon, class, abs_change, pct_change) %>%
#   filter(taxon %in% c("FAVI", "MEAN"))
# trends_summary %>% select(taxon, class, abs_change, pct_change) %>%
#   filter(taxon %in% c("PSTR", "MYCE"))
# 
```

### Plot trajectories
```{r}
# Final Figure 5 trends plot

alltax <- ggplot(summary_datasets %>% filter(taxon == "All"), aes(x = year, y = mean_epred)) +
  geom_point(aes(color = class), alpha = 0.4, size = 2) +
  geom_errorbar(aes(color = class, ymin = .lower, ymax = .upper), width = 0, linewidth = 0.2) +
  geom_line(data = preds_combined %>% filter(taxon == "All"), linewidth = 0.4,
            aes(color = class, y = pred_density, linetype = sig_trend)) +
  geom_text(data = trends_summary %>% filter(taxon == "All"),
            aes(x = -Inf, y = Inf,
                label = paste0(ifelse(abs_change > 0,
                        paste0("+", signif(abs_change, 2)),
                        as.character(signif(abs_change, 2))),
                        c(" colonies <4 cm", " colonies ≥4 cm", " total colonies   ")),
                color = class, fontface = ifelse(sig_trend, "bold", "plain")),
            inherit.aes = FALSE, size = 3, hjust = -0.15, vjust = c(4.0, 2.5, 1.0)) +
  facet_wrap(~taxon, scales = "free",
             labeller = labeller(taxon = as_labeller(taxon_labels, label_parsed))) +
  labs(y = expression("Colonies m"^-2)) +
  scale_y_continuous(limits = c(0, NA)) +
  scale_linetype_manual(values = c(`FALSE` = 3, `TRUE` = 1)) +
  scale_color_manual(values = c('#d95f02', '#1b9e77', '#7570b3')) +
  scale_x_continuous(breaks = c(11, 17, 21, 23, 24),
                     labels = c(
                       str_pad("2011", width = 4, side = "right"),
                       str_pad("2017", width = 4, side = "right"),
                       str_pad("2021", width = 4, side = "right"),
                       str_pad("2023", width = 7, side = "right"),
                       str_pad("2024", width = 4, side = "left")))+
  theme_minimal(base_size = 11) +
  theme(plot.background = element_rect(fill = "white", color = NA),
        axis.title.x = element_blank(),
        legend.position = "none",
        panel.grid.minor.x = element_blank(),
        axis.text.y = element_text(margin = margin(r = -2)),
        axis.title.y = element_text(margin = margin(r = -14)),
        axis.text.x = element_text(margin = margin(t = -1)),
        plot.margin = margin(t = 3, r = 3, b = 3, l = 3)) +
  coord_cartesian(clip = "off")

taxa_other <- levels(summary_datasets$taxon)[-1]
p_others <- map(taxa_other, function(taxon) {
  ggplot(summary_datasets %>% 
           filter(taxon == !!taxon) %>%
           mutate(class = factor(class, levels = c(">4cm", "<4cm", "All"))), 
         aes(x = year, y = mean_epred)) +
  geom_point(aes(color = class), alpha = 0.4) +
  geom_errorbar(aes(color = class, ymin = .lower, ymax = .upper), width = 0, linewidth = 0.2) +
  geom_line(data = preds_combined %>% 
           filter(taxon == !!taxon) %>%
           mutate(class = factor(class, levels = c(">4cm", "<4cm", "All"))), 
           linewidth = 0.4,
            aes(color = class, y = pred_density, linetype = sig_trend)) +
  geom_text(data = trends_summary %>% 
           filter(taxon == !!taxon) %>%
           mutate(class = factor(class, levels = c(">4cm", "<4cm", "All"))),
            aes(x = -Inf, y = y_label,
               label = str_pad(
  ifelse(abs_change > 0,
         paste0("+", signif(abs_change, 2)),
         as.character(signif(abs_change, 2))),
  width = 8,
  side = "right"
),
                color = class, fontface = ifelse(sig_trend, "bold", "plain")),
            inherit.aes = FALSE, size = 2.5, hjust = -0.2, vjust = 0.2) +
  facet_wrap(~taxon, scales = "free",
              labeller = labeller(taxon = as_labeller(taxon_labels, label_parsed))) +
  scale_y_continuous(limits = c(0, NA)) +
  scale_linetype_manual(values = c("FALSE" = 3, "TRUE" = 1), drop = FALSE) +
  scale_color_manual(values = c("<4cm" = "#d95f02", ">4cm" = "#1b9e77", "All" = "#7570b3"),
                     drop = FALSE) +
  scale_x_continuous(breaks = c(11, 17, 21, 23, 24),
                     labels = c(
    str_pad("'11", width = 3, side = "left"),
    str_pad("'17", width = 3, side = "left"),
    str_pad("'21", width = 3, side = "right"), "",
    #str_pad("'23", width = 6, side = "right"),
    str_pad("'24", width = 3, side = "left")))+
  theme_minimal(base_size = 11) +
  theme(plot.background = element_rect(fill = "white", color = NA),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_text(margin = margin(r = -2)),
        axis.text.x = element_text(margin = margin(t = -1)),
        legend.position = "none",
        panel.grid.minor.x = element_blank(),
        plot.margin = margin(t = 3, r = 3, b = 3, l = 3)) +
  coord_cartesian(clip = "off") +
    labs(x = "", y = "")
})


# MAKE STANDALONE LEGEND
# Dummy data for legend creation
legend_data <- data.frame(
  x = 1:2,
  y = 1:2,
  trend = factor(c("credible", "uncertain"), levels = c("credible", "uncertain"))
)

# Build dummy plot for legend
legend_plot <- ggplot(legend_data, aes(x = x, y = y, linetype = trend)) +
  geom_line(linewidth = 0.4) +
  scale_linetype_manual(
    name = "Trend",
    values = c("credible" = "solid", "uncertain" = "dotted"),
    labels = c("<b>≠ 0</b>", "≈ 0"),
  ) +
  theme_void(base_size = 10) +
  theme(
    legend.position = "right",       # vertical legend
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 10),
    theme(legend.key.width = unit(3, "cm"))
  ) +
  guides(linetype = guide_legend(override.aes = list(size = 0.6),
                                 label.theme = element_markdown()),
         color = "none") +
  theme(legend.key.width = unit(1.5, "cm"))

# Extract just the legend
legend_only <- cowplot::get_legend(legend_plot)

# Show legend-only plot
legplot <- cowplot::ggdraw(legend_only)


# Define the layout
layout <- c(
  area(t = 1, l = 1, b = 2, r = 2),  # 'alltax' spans top-left 2×2
  area(t = 1, l = 3, b = 1, r = 3),  # plot 1
  area(t = 1, l = 4, b = 1, r = 4),  # plot 2
  area(t = 1, l = 5, b = 1, r = 5),  # plot 3
  area(t = 2, l = 3, b = 2, r = 3),  # plot 4
  area(t = 2, l = 4, b = 2, r = 4),  # plot 5
  area(t = 2, l = 5, b = 2, r = 5),  # plot 6
  area(t = 3, l = 1, b = 3, r = 1),  # plot 7
  area(t = 3, l = 2, b = 3, r = 2),  # plot 8
  area(t = 3, l = 3, b = 3, r = 3),  # plot 9
  area(t = 3, l = 4, b = 3, r = 4),  # plot 10
  area(t = 3, l = 5, b = 3, r = 5),  # plot 11
  area(t = 4, l = 1, b = 4, r = 1),  # plot 12
  area(t = 4, l = 2, b = 4, r = 2),  # plot 13
  area(t = 4, l = 3, b = 4, r = 3),  # plot 14
  area(t = 4, l = 4, b = 4, r = 4),  # plot 15
  area(t = 4, l = 5, b = 4, r = 5),  # plot 16
  area(t = 5, l = 1, b = 5, r = 1),  # plot 17
  area(t = 5, l = 2, b = 5, r = 2),  # plot 18
  area(t = 5, l = 3, b = 5, r = 3),  # plot 19
  area(t = 5, l = 4, b = 5, r = 4),  # plot 20
  area(t = 5, l = 5, b = 5, r = 5)   # plot 21
)

# Combine plots
final_plot <- alltax + p_others[[1]] + p_others[[2]] + p_others[[3]] +
  p_others[[4]] + p_others[[5]] + p_others[[6]] + p_others[[7]] +
  p_others[[8]] + p_others[[9]] + p_others[[10]] + p_others[[11]] +
  p_others[[12]] + p_others[[13]] + p_others[[14]] + p_others[[15]] +
  p_others[[16]] + p_others[[17]] + p_others[[18]] + p_others[[19]] +
  p_others[[20]] + legplot +
  plot_layout(design = layout)

final_plot

ggsave(filename = "outputs/Fig4.png", width = 180, height = 180, units = "mm", dpi = 300)


figz <- (alltax + theme(axis.title.y = element_text(margin = margin(r = 0)))) +
  p_others[[which(taxa_other == "ACER")]] +
  p_others[[which(taxa_other == "ORBI")]] +
  plot_layout(ncol = 3)
ggsave(filename = "outputs/Trends_all_acer_orbi.png", width = 170, height = 70, units = "mm")
```


### Plot abs. changes
```{r}
# Final figure 6 trends plot

# Custom signed log-like transform
signed_pseudo_log <- function(x, scale = 1000) {
  sign(x) * log1p(abs(x) * scale)
}

# Transform slopes
scale_factor <- 2000
trends_summary_trans <- trends_summary %>%
  mutate(
    abs_change_trans = signed_pseudo_log(abs_change, scale = scale_factor),
    lower_trans = signed_pseudo_log(abs_change.lower, scale = scale_factor),
    upper_trans = signed_pseudo_log(abs_change.upper, scale = scale_factor),
    taxon = fct_reorder(taxon, abs_change)
  )

# Tick marks (original scale)
ticks <- c(-1, -0.5, -0.2, -0.1, -0.05, -0.02, -0.01, -0.005, -0.002, -0.001,
            -0.0005, -0.0001, 0.0001, 0.0005,
            0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1)
# Custom function to format tick labels
format_ticks <- function(x) {
  sapply(x, function(v) {
    if (v == 0) {
      "0"
    } else {
      sub("\\.?0+$", "", format(v, scientific = FALSE, trim = TRUE))
    }
  })
}

xmax <- max(trends_summary_trans$upper_trans)
xmin <- min(trends_summary_trans$lower_trans)

# Plot
ggplot(trends_summary_trans, aes(x = abs_change_trans, y = taxon)) +
  geom_point(aes(color = class, size = class), position = position_dodge(width = 0.5),
             alpha = 0.5) +
  geom_errorbarh(aes(color = class, xmin = lower_trans, xmax = upper_trans), 
                 position = position_dodge(width = 0.5), height = 0, linewidth = 0.4) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray40") +
  scale_x_continuous(
    breaks = signed_pseudo_log(ticks, scale = scale_factor),      # positions in transformed space
    minor_breaks = NULL, 
    labels = format_ticks(ticks),       # labels in original space
    limits = c(xmin, xmax),
    expand = expansion(mult = c(0, 0))
  ) +
  scale_y_discrete(
    labels = function(x) parse(text = taxon_labels[x])  # now safe with proper levels
  )  +
  scale_color_manual(values = c("<4cm" = "#d95f02", ">4cm" = "#1b9e77", "All" = "#7570b3"))+
  scale_size_manual(values = c(1,3,5)) +
  labs(
    x = expression("Change in density (colonies m"^{-2}*") 2017–2024"),
    y = "",
    color = "Size class",
    size = "Size class"
  ) +
  theme_minimal() +
  coord_cartesian(clip = "off") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 8),
        plot.background = element_rect(fill = "white", color = NA),
        legend.position = c(0.86, 0.22),
        legend.background = element_rect(fill = "white", linewidth = 0.2),
        legend.spacing.y = unit(0.1, "cm"),    # vertical space between items
        legend.spacing.x = unit(0.1, "cm"))    # horizontal space between items)

ggsave(filename = "outputs/Fig5.png", width = 140, height = 120, units = "mm", dpi = 300)
```

## Totals in impact zones

### Equal-weighted estimates
```{r}
# TOTAL COLONIES IN EACH IMPACT ZONE
densities_tot <- summary_equal_weighted_combined %>% filter(class != "All")

# Calculate total per taxclass per habitat Type and impact zone
tot1 <- left_join(densities_tot, area_summary, by = "Type") %>%
  mutate(tot = n_m2 * total_area_m2,
         tot_lower = n_m2 * total_area_m2,
         tot_upper = n_m2 * total_area_m2)

# Calculate total per taxclass per impact zone (sum all habitat Types)
tot2 <- tot1 %>%
  group_by(taxon, class, name) %>%
  summarize(tot = round(sum(tot))) %>%
  arrange(name)

tab2 <- tot2 %>% ungroup() %>%
  pivot_wider(names_from = name, values_from = tot, names_sort = FALSE) %>%
  janitor::adorn_totals(where = c("row", "col")) %>%
  mutate(across(where(is.numeric), scales::comma))

tab2 %>%
  knitr::kable(caption = "Total number of colonies in each impact zone - surveys (years) equal-weighted")

write_csv(tab2, file = "outputs/TableA4.csv")


# Calculate total ESA and non-ESA corals per impact zone
tot3 <- tot2 %>%
  mutate(ESA = case_when(!taxon %in% c("ACER", "ORBI") ~ "non-ESA",
                         TRUE ~ taxon)) %>%
  group_by(name, ESA) %>%
  summarize(tot = sum(tot), .groups = "drop") %>%
  pivot_wider(names_from = ESA, values_from = tot) %>%
  janitor::adorn_totals(where = "col") %>%
  mutate(cum_ACER = cumsum(ACER),
         cum_ORBI = cumsum(ORBI),
         cum_non_ESA = cumsum(`non-ESA`),
         cum_Total = cumsum(Total)) %>%
  mutate(across(where(is.numeric), ~ format(round(.), big.mark = ","))) 

tot3 %>%
  knitr::kable(caption = "Total coral colonies in all impact zones")

write_csv(tot3, file = "outputs/Table2.csv")
```


#### Treemap plot - Scenario2+NMFS
```{r working_treemap1}
# Aggregate total abundance by taxon + class
tot4 <- tot2 %>%
  filter(name != "Rest of Monitoring Area") %>%
  group_by(taxon, class) %>%
  summarize(tot = sum(tot), .groups = "drop")

# Assign a base color per taxon
set.seed(3)
base_colors <- sample(ggsci::pal_d3("category20")(20), 20)
names(base_colors) <- unique(tot4$taxon)

# Define shading function
get_shades <- function(base_col, class, all_classes) {
  if (length(all_classes) == 2) {
    if (class == "<4cm") colorspace::lighten(base_col, 0.1)
    else colorspace::darken(base_col, 0.1)
  } else {
    base_col
  }
}

# Build taxon_class and corresponding shades
shade_map <- tot4 %>%
  distinct(taxon, class) %>%
  rowwise() %>%
  mutate(
    base_col = base_colors[[taxon]],
    all_classes = list(tot4$class[tot4$taxon == taxon]),
    shade = get_shades(base_col, class, all_classes),
    taxon_class = paste(taxon, class, sep = "_")
  ) %>%
  ungroup()

# Final color map
fill_colors <- setNames(shade_map$shade, shade_map$taxon_class)

# Add taxon_class to original data
tot4 <- tot4 %>%
  mutate(taxon_class = paste(taxon, class, sep = "_"))

# Plot with taxon labels only
p <- ggplot(tot4, aes(area = tot, fill = taxon_class, subgroup = taxon)) +
  geom_treemap(color = NA)+#, layout = "srow") +
  geom_treemap_subgroup_border(colour = "white", size = 1)+#, layout = "srow") +
  # geom_treemap_subgroup_text(place = "topleft", grow = TRUE, 
  #                             alpha = 0.8, colour = "black", size = 8) +
  scale_fill_manual(values = fill_colors) +
  theme(legend.position = "none")


# Get tile layout and attach taxon_class
tile_layout <- treemapify(tot4, area = "tot",#, layout = "srow",
                          fill = "taxon_class", subgroup = "taxon")

# Flag small boxes (aggregate size classes)
tile_layout_ag <- tile_layout %>%
  group_by(taxon) %>%
  summarize(xmin = min(xmin), xmax = max(xmax),
            ymin = min(ymin), ymax = max(ymax),
            area = (xmax - xmin) * (ymax - ymin),
            center_x = (xmin + xmax) / 2,
            center_y = (ymin + ymax) / 2)
area_threshold <- 0.001
internal_labels <- tile_layout_ag %>% 
  filter(area >= area_threshold)
external_labels <- tile_layout_ag %>% 
  filter(area < area_threshold)

# Create labels with taxontotals
taxtots <- tot4 %>%
  group_by(taxon) %>%
  summarize(tot = scales::comma(sum(tot)))

internal_labels <- left_join(internal_labels, taxtots) %>%
  mutate(label = paste0(taxon, "\n", tot))

external_labels <- left_join(external_labels, taxtots) %>%
  mutate(label = paste0(taxon, "\n", tot))

# Final plot
p + 
  scale_x_continuous(limits = c(0, 1), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
  coord_cartesian(clip = "off") +
  geom_text(data = internal_labels,
            aes(x = xmin, y = ymax-0.00001,
                label = label, size = area), inherit.aes = FALSE,
            hjust = 0, vjust = 1, lineheight = 0.7,
            nudge_x = 0.001, nudge_y = -0.005) +
  scale_size_continuous(range = c(1.5, 15)) +
  geom_text_repel(data = external_labels,
             aes(x = center_x, y = center_y, 
                 label = label), inherit.aes = FALSE,
             max.overlaps = Inf,
             box.padding = 0.18,
             xlim = c(1, NA),
             force = 3,
             lineheight = 0.7,
             min.segment.length = 0.1,
             segment.size = 0.2,
             hjust = 0,
             size = 1.7, seed = 123) +
  theme_void() +
  theme(
    legend.position = "none",
    plot.margin = margin(t = 0, r = 20, b = 10, l = 10),
    plot.background = element_rect(fill = "white", color = NA),
  ) +
  labs(title = "Total corals in scenario 2 zones + NMFS areas, surveys (all years) equal-weighted")
  
ggsave(filename = "outputs/Fig6.png", width = 180, height = 130, units = "mm", dpi = 600)
```

#### Treemap plot - Full monitoring area
```{r working_treemap2}
# Aggregate total abundance by taxon + class
tot4 <- tot2 %>%
  group_by(taxon, class) %>%
  summarize(tot = sum(tot), .groups = "drop")

# Assign a base color per taxon
set.seed(3)
base_colors <- sample(ggsci::pal_d3("category20")(20), 20)
names(base_colors) <- unique(tot4$taxon)

# Define shading function
get_shades <- function(base_col, class, all_classes) {
  if (length(all_classes) == 2) {
    if (class == "<4cm") colorspace::lighten(base_col, 0.1)
    else colorspace::darken(base_col, 0.1)
  } else {
    base_col
  }
}

# Build taxon_class and corresponding shades
shade_map <- tot4 %>%
  distinct(taxon, class) %>%
  rowwise() %>%
  mutate(
    base_col = base_colors[[taxon]],
    all_classes = list(tot4$class[tot4$taxon == taxon]),
    shade = get_shades(base_col, class, all_classes),
    taxon_class = paste(taxon, class, sep = "_")
  ) %>%
  ungroup()

# Final color map
fill_colors <- setNames(shade_map$shade, shade_map$taxon_class)

# Add taxon_class to original data
tot4 <- tot4 %>%
  mutate(taxon_class = paste(taxon, class, sep = "_"))

# Plot with taxon labels only
p <- ggplot(tot4, aes(area = tot, fill = taxon_class, subgroup = taxon)) +
  geom_treemap(color = NA) +
  geom_treemap_subgroup_border(colour = "white", size = 1) +
  # geom_treemap_subgroup_text(place = "topleft", grow = TRUE, 
  #                             alpha = 0.8, colour = "black", size = 8) +
  scale_fill_manual(values = fill_colors) +
  theme(legend.position = "none")


# Get tile layout and attach taxon_class
tile_layout <- treemapify(tot4, area = "tot", 
                          fill = "taxon_class", subgroup = "taxon")

# Flag small boxes (aggregate size classes)
tile_layout_ag <- tile_layout %>%
  group_by(taxon) %>%
  summarize(xmin = min(xmin), xmax = max(xmax),
            ymin = min(ymin), ymax = max(ymax),
            area = (xmax - xmin) * (ymax - ymin),
            center_x = (xmin + xmax) / 2,
            center_y = (ymin + ymax) / 2)
area_threshold <- 0.001
internal_labels <- tile_layout_ag %>% 
  filter(area >= area_threshold)
external_labels <- tile_layout_ag %>% 
  filter(area < area_threshold)

# Create labels with taxontotals
taxtots <- tot4 %>%
  group_by(taxon) %>%
  summarize(tot = scales::comma(sum(tot)))

internal_labels <- left_join(internal_labels, taxtots) %>%
  mutate(label = paste0(taxon, "\n", tot))

external_labels <- left_join(external_labels, taxtots) %>%
  mutate(label = paste0(taxon, "\n", tot))

# Final plot
p + 
  scale_x_continuous(limits = c(0, 1), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
  coord_cartesian(clip = "off") +
  geom_text(data = internal_labels,
            aes(x = xmin, y = ymax-0.00001,
                label = label, size = area), inherit.aes = FALSE,
            hjust = 0, vjust = 1, lineheight = 0.7,
            nudge_x = 0.005, nudge_y = -0.005) +
  scale_size_continuous(range = c(1.5, 15)) +
  geom_text_repel(data = external_labels,
             aes(x = center_x, y = center_y, 
                 label = label), inherit.aes = FALSE,
             max.overlaps = Inf,
             xlim = c(1, NA),
             force = 5,
             min.segment.length = 0.1,
             segment.size = 0.2,
             hjust = 0, seed = 123,
             size = 2) +
  theme_void() +
  theme(
    legend.position = "none",
    plot.margin = margin(t = 0, r = 20, b = 10, l = 10),
    plot.background = element_rect(fill = "white", color = NA),
  ) +
  labs(title = "Total corals in full impact monitoring area, surveys (all years) equal-weighted")
  
ggsave(filename = "outputs/FigA4.png", width = 180, height = 130, units = "mm", dpi = 600)
```


### 2024 estimates

```{r}
# TOTAL COLONIES IN EACH IMPACT ZONE
densities_tot_2024 <- summary_drm24_combined %>% filter(class != "All")


# Calculate total per taxclass per habitat Type and impact zone
tot1_2024 <- left_join(densities_tot_2024, area_summary, by = "Type") %>%
  mutate(tot = n_m2 * total_area_m2,
         tot_lower = n_m2 * total_area_m2,
         tot_upper = n_m2 * total_area_m2)

# Calculate total per taxclass per impact zone (sum all habitat Types)
tot2_2024 <- tot1_2024 %>%
  group_by(taxon, class, name) %>%
  summarize(tot = round(sum(tot))) %>%
  arrange(name)

tab2_2024 <- tot2_2024 %>% ungroup() %>%
  pivot_wider(names_from = name, values_from = tot, names_sort = FALSE) %>%
  janitor::adorn_totals(where = c("row", "col")) %>%
  mutate(across(where(is.numeric), scales::comma))

tab2_2024 %>%
  knitr::kable(caption = "Total number of colonies in each impact zone - 2024 estimates")

write_csv(tab2_2024, file = "outputs/TableA5.csv")


## SUM ESA and non-ESA corals
# Calculate total ESA and non-ESA corals per impact zone
tot3_2024 <- tot2_2024 %>%
  mutate(ESA = case_when(!taxon %in% c("ACER", "ORBI") ~ "non-ESA",
                         TRUE ~ taxon)) %>%
  group_by(name, ESA) %>%
  summarize(tot = sum(tot), .groups = "drop") %>%
  pivot_wider(names_from = ESA, values_from = tot) %>%
  janitor::adorn_totals(where = "col") %>%
  mutate(cum_ACER = cumsum(ACER),
         cum_ORBI = cumsum(ORBI),
         cum_non_ESA = cumsum(`non-ESA`),
         cum_Total = cumsum(Total)) %>%
  mutate(across(where(is.numeric), ~ format(round(.), big.mark = ","))) 

tot3_2024 %>%
  knitr::kable(caption = "Total coral colonies in all impact zones, 2024 estimates")

write_csv(tot3_2024, file = "outputs/TableA6.csv")
```

#### Treemap plot - Scenario2+NMFS
```{r}
# Aggregate total abundance by taxon + class
tot4_2024 <- tot2_2024 %>%
  filter(name != "Rest of Monitoring Area") %>%
  group_by(taxon, class) %>%
  summarize(tot = sum(tot), .groups = "drop")

# Add taxon_class to original data
tot4_2024 <- tot4_2024 %>%
  mutate(taxon_class = paste(taxon, class, sep = "_"))

# Plot with taxon labels only
p <- ggplot(tot4_2024, aes(area = tot, fill = taxon_class, subgroup = taxon)) +
  geom_treemap(color = NA)+#, layout = "srow") +
  geom_treemap_subgroup_border(colour = "white", size = 1)+#, layout = "srow") +
  # geom_treemap_subgroup_text(place = "topleft", grow = TRUE, 
  #                             alpha = 0.8, colour = "black", size = 8) +
  scale_fill_manual(values = fill_colors) +
  theme(legend.position = "none")


# Get tile layout and attach taxon_class
tile_layout <- treemapify(tot4_2024, area = "tot",#, layout = "srow",
                          fill = "taxon_class", subgroup = "taxon")

# Flag small boxes (aggregate size classes)
tile_layout_ag <- tile_layout %>%
  group_by(taxon) %>%
  summarize(xmin = min(xmin), xmax = max(xmax),
            ymin = min(ymin), ymax = max(ymax),
            area = (xmax - xmin) * (ymax - ymin),
            center_x = (xmin + xmax) / 2,
            center_y = (ymin + ymax) / 2)
area_threshold <- 0.0009
internal_labels <- tile_layout_ag %>% 
  filter(area >= area_threshold)
external_labels <- tile_layout_ag %>% 
  filter(area < area_threshold)

# Create labels with taxontotals
taxtots <- tot4_2024 %>%
  group_by(taxon) %>%
  summarize(tot = scales::comma(sum(tot)))

internal_labels <- left_join(internal_labels, taxtots) %>%
  mutate(label = paste0(taxon, "\n", tot))

external_labels <- left_join(external_labels, taxtots) %>%
  mutate(label = paste0(taxon, "\n", tot))

# Final plot
p + 
  scale_x_continuous(limits = c(0, 1), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
  coord_cartesian(clip = "off") +
  geom_text(data = internal_labels,
            aes(x = xmin, y = ymax-0.00001,
                label = label, size = area), inherit.aes = FALSE,
            hjust = 0, vjust = 1, lineheight = 0.7,
            nudge_x = 0.001, nudge_y = -0.005) +
  scale_size_continuous(range = c(1.3, 10)) +
  geom_text_repel(data = external_labels,
             aes(x = center_x, y = center_y, 
                 label = label), inherit.aes = FALSE,
             max.overlaps = Inf,
             box.padding = 0.18,
             xlim = c(1, NA),
             force = 3,
             lineheight = 0.7,
             min.segment.length = 0.1,
             segment.size = 0.2,
             hjust = 0,
             size = 1.5, seed = 123) +
  theme_void() +
  theme(
    legend.position = "none",
    plot.margin = margin(t = 0, r = 20, b = 10, l = 10),
    plot.background = element_rect(fill = "white", color = NA),
  ) +
  labs(title = "Total corals in scenario 2 zones + NMFS areas, 2024 estimates")
  
ggsave(filename = "outputs/FigA5.png", width = 180, height = 130, units = "mm", dpi = 600)
```


#### Treemap plot - Full monitoring area
```{r}
# TOTAL COLONIES IN EACH IMPACT ZONE
densities_tot_2024 <- summary_drm24_combined %>% filter(class != "All")


# Calculate total per taxclass per habitat Type and impact zone
tot1_2024 <- left_join(densities_tot_2024, area_summary, by = "Type") %>%
  mutate(tot = n_m2 * total_area_m2,
         tot_lower = n_m2 * total_area_m2,
         tot_upper = n_m2 * total_area_m2)

# Calculate total per taxclass per impact zone (sum all habitat Types)
tot2_2024 <- tot1_2024 %>%
  group_by(taxon, class, name) %>%
  summarize(tot = round(sum(tot))) %>%
  arrange(name)

# Aggregate total abundance by taxon + class
tot4_2024 <- tot2_2024 %>%
  group_by(taxon, class) %>%
  summarize(tot = sum(tot), .groups = "drop")

# Add taxon_class to original data
tot4_2024 <- tot4_2024 %>%
  mutate(taxon_class = paste(taxon, class, sep = "_"))

# Plot with taxon labels only
p <- ggplot(tot4_2024, aes(area = tot, fill = taxon_class, subgroup = taxon)) +
  geom_treemap(color = NA)+#, layout = "srow") +
  geom_treemap_subgroup_border(colour = "white", size = 1)+#, layout = "srow") +
  # geom_treemap_subgroup_text(place = "topleft", grow = TRUE, 
  #                             alpha = 0.8, colour = "black", size = 8) +
  scale_fill_manual(values = fill_colors) +
  theme(legend.position = "none")


# Get tile layout and attach taxon_class
tile_layout <- treemapify(tot4_2024, area = "tot",#, layout = "srow",
                          fill = "taxon_class", subgroup = "taxon")

# Flag small boxes (aggregate size classes)
tile_layout_ag <- tile_layout %>%
  group_by(taxon) %>%
  summarize(xmin = min(xmin), xmax = max(xmax),
            ymin = min(ymin), ymax = max(ymax),
            area = (xmax - xmin) * (ymax - ymin),
            center_x = (xmin + xmax) / 2,
            center_y = (ymin + ymax) / 2)
area_threshold <- 0.0009
internal_labels <- tile_layout_ag %>% 
  filter(area >= area_threshold)
external_labels <- tile_layout_ag %>% 
  filter(area < area_threshold)

# Create labels with taxontotals
taxtots <- tot4_2024 %>%
  group_by(taxon) %>%
  summarize(tot = scales::comma(sum(tot)))

internal_labels <- left_join(internal_labels, taxtots) %>%
  mutate(label = paste0(taxon, "\n", tot))

external_labels <- left_join(external_labels, taxtots) %>%
  mutate(label = paste0(taxon, "\n", tot))

# Final plot
p + 
  scale_x_continuous(limits = c(0, 1), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +
  coord_cartesian(clip = "off") +
  geom_text(data = internal_labels,
            aes(x = xmin, y = ymax-0.00001,
                label = label, size = area), inherit.aes = FALSE,
            hjust = 0, vjust = 1, lineheight = 0.7,
            nudge_x = 0.001, nudge_y = -0.005) +
  scale_size_continuous(range = c(1.3, 10)) +
  geom_text_repel(data = external_labels,
             aes(x = center_x, y = center_y, 
                 label = label), inherit.aes = FALSE,
             max.overlaps = Inf,
             box.padding = 0.18,
             xlim = c(1, NA),
             force = 3,
             lineheight = 0.7,
             min.segment.length = 0.1,
             segment.size = 0.2,
             hjust = 0,
             size = 1.5, seed = 123) +
  theme_void() +
  theme(
    legend.position = "none",
    plot.margin = margin(t = 0, r = 20, b = 10, l = 10),
    plot.background = element_rect(fill = "white", color = NA),
  ) +
  labs(title = "Total corals in full impact monitoring area, 2024 estimates")
  
ggsave(filename = "outputs/FigA6.png", width = 180, height = 130, units = "mm", dpi = 600)


#ggsave(filename = "outputs/FigA62.png", width = 180, height = 90, units = "mm", dpi = 600)

```

# Extra figures
```{r extra_figures}
pp3 <- ggplot(polygons_final) +
    geom_sf(aes(fill = Type), color = NA, size = 0.1, alpha = 0.5) +
    geom_point(
        data = selected,
        aes(x = longitude, y = latitude),
        pch = 4, alpha = 0.6, size = 1, stroke = 0.4, inherit.aes = FALSE
    ) +
    scale_fill_manual(values = typecols, na.value = "gray80") +
    facet_wrap(~ dataset, ncol = 3,
               labeller = as_labeller(c(
                   "nsu11_esa" = "2011 – NSU ESA Survey",
                   "dca17_esa" = "2017 – DCA ESA Survey",
                   "dca17"     = "2017 – DCA Recon Survey",
                   "tt21"      = "2021 – Tetra Tech Survey",
                   "tt23"      = "2023 – Tetra Tech Survey",
                   "drm24"     = "2024 – Shedd Survey"
               ))) +
    #coord_limits +
    labs(title = NULL, fill = NULL) +
    base_theme +
    theme(
        legend.position = "bottom",
        strip.text = element_text(size = 6),
        panel.spacing = unit(0.5, "lines")
    ) +
  geom_segment(
    data = scale_lines,
    aes(x = x, y = y, xend = xend, yend = yend),
    inherit.aes = FALSE,
    color = "black",
    linewidth = 0.4
  ) +
  geom_segment(
    data = ticks_segments,
    aes(x = x, y = y, xend = xend, yend = yend),
    color = "black",
    linewidth = 0.3
  ) +
  geom_text(
    data = tick_labels,
    aes(x = x, y = y, label = label),
    hjust = 1,
    #vjust = c(rep(1.5, 4), rep(-0.5, 4)),
    size = 1.7
  ) +
  theme(plot.margin = margin(0,0,0,0),
        strip.text = element_text(size = 10, margin = margin(t = 8, b = -8)),
        strip.clip = "off")


ggsave(pp3, filename = "outputs/survey_locations.png", width = 180, height = 220, units = "mm", dpi = 300, bg = "white")
```

```{r more_extrafigs}
# Create plot for just ACER/ORBI
make_taxon_density_plot(densities = summary_equal_weighted_combined %>%
                          filter(taxon %in% c("ACER", "ORBI")),
                        output_path = "outputs/ACERORBI.png",
                        width = 120, height = 70)

make_taxon_density_plot(densities = summary_drm24_combined %>%
                          filter(taxon %in% c("ACER", "ORBI")),
                        output_path = "outputs/ACERORBI_2024.png",
                        width = 120, height = 70)
```

